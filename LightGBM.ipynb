{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('pd_data_train.pkl')\n",
    "valid_data = pd.read_pickle('pd_data_valid.pkl')\n",
    "test_data = pd.read_pickle('pd_data_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def plot_features(booster, figsize):    \n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(data):\n",
    "#     data = data[data.date_block_num > 11]\n",
    "    X = data.drop(['date_block_num', 'item_cnt_month', 'shop_id', 'item_id'], axis=1)\n",
    "    y = data['item_cnt_month']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = get_X_y(train_data)\n",
    "valid_X, valid_y = get_X_y(valid_data)\n",
    "test_X, test_y = get_X_y(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data\n",
    "del valid_data\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['city_id', 'item_category_id', 'category_id', 'subcategory_id', 'subsubcategory_id', 'month', 'season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1b6e900f7c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = lgb.Dataset(train_X, label=train_y, categorical_feature=categorical_columns)\n",
    "train_data.save_binary('lgb_train_dataset.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1b6e900f3c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = lgb.Dataset(valid_X, label=valid_y, categorical_feature=categorical_columns, reference=train_data)\n",
    "valid_data.save_binary('lgb_valid_dataset.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1b6e900fa48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = lgb.Dataset(test_X, label=test_y, categorical_feature=categorical_columns)\n",
    "test_data.save_binary('lgb_test_dataset.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Use lightGBM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset('lgb_train_dataset.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = lgb.Dataset('lgb_valid_dataset.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "\n",
    "param_test = {\n",
    "    'num_leaves':  [2**5, 2**7, 2**9],\n",
    "    'subsample': [0.5, 0.7, 0.9], \n",
    "    'reg_alpha': [0, 1e-1, 1, 2, 5],\n",
    "    'reg_lambda': [0, 1e-1, 1, 2, 5],\n",
    "    'max_depth' : [3, 5, 7],\n",
    "    'metric': ['rmse'],\n",
    "    'num_threads': [4],\n",
    "    'objective': ['regression_l2', None],\n",
    "}\n",
    "\n",
    "sampler = ParameterSampler(param_test, n_iter=25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "early_stopping_rounds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_dir = 'trained_models_dir'\n",
    "trained_models_dir = trained_models_dir + '/lgb'\n",
    "if not os.path.exists(trained_models_dir):\n",
    "    os.makedirs(trained_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inner_dirs(path):\n",
    "    for file in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, file)):\n",
    "            yield file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __create_model_directory(models_dir) -> str:\n",
    "    inner_dirs = list(get_inner_dirs(models_dir))\n",
    "    folder_name = 'gs_{}'.format(len(inner_dirs))\n",
    "\n",
    "    model_dir = os.path.join(models_dir, folder_name)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    return model_dir, folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(data):\n",
    "    #     data = data[data.date_block_num > 11]\n",
    "    X = data.drop(['date_block_num', 'item_cnt_month', 'shop_id', 'item_id'], axis=1)\n",
    "    y = data['item_cnt_month']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = []\n",
    "search_results_file = os.path.join(trained_models_dir, 'search_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current parameters : {'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha': 2, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 7}\n",
      "model directory : trained_models_dir/lgb\\gs_0\n",
      "[1]\ttraining's rmse: 1.27486\tvalid_1's rmse: 1.0985\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2256\tvalid_1's rmse: 1.06527\n",
      "[3]\ttraining's rmse: 1.18356\tvalid_1's rmse: 1.0375\n",
      "[4]\ttraining's rmse: 1.14787\tvalid_1's rmse: 1.01458\n",
      "[5]\ttraining's rmse: 1.11706\tvalid_1's rmse: 0.996947\n",
      "[6]\ttraining's rmse: 1.09089\tvalid_1's rmse: 0.979421\n",
      "[7]\ttraining's rmse: 1.06901\tvalid_1's rmse: 0.967127\n",
      "[8]\ttraining's rmse: 1.04937\tvalid_1's rmse: 0.955443\n",
      "[9]\ttraining's rmse: 1.03325\tvalid_1's rmse: 0.947147\n",
      "[10]\ttraining's rmse: 1.01951\tvalid_1's rmse: 0.939646\n",
      "[11]\ttraining's rmse: 1.00778\tvalid_1's rmse: 0.933298\n",
      "[12]\ttraining's rmse: 0.997571\tvalid_1's rmse: 0.92762\n",
      "[13]\ttraining's rmse: 0.988772\tvalid_1's rmse: 0.923798\n",
      "[14]\ttraining's rmse: 0.981037\tvalid_1's rmse: 0.921109\n",
      "[15]\ttraining's rmse: 0.973496\tvalid_1's rmse: 0.918952\n",
      "[16]\ttraining's rmse: 0.967902\tvalid_1's rmse: 0.917074\n",
      "[17]\ttraining's rmse: 0.962265\tvalid_1's rmse: 0.914633\n",
      "[18]\ttraining's rmse: 0.957624\tvalid_1's rmse: 0.91271\n",
      "[19]\ttraining's rmse: 0.95346\tvalid_1's rmse: 0.91101\n",
      "[20]\ttraining's rmse: 0.949387\tvalid_1's rmse: 0.909622\n",
      "[21]\ttraining's rmse: 0.945833\tvalid_1's rmse: 0.908795\n",
      "[22]\ttraining's rmse: 0.942932\tvalid_1's rmse: 0.907674\n",
      "[23]\ttraining's rmse: 0.940186\tvalid_1's rmse: 0.906807\n",
      "[24]\ttraining's rmse: 0.937567\tvalid_1's rmse: 0.905935\n",
      "[25]\ttraining's rmse: 0.935577\tvalid_1's rmse: 0.905451\n",
      "[26]\ttraining's rmse: 0.933352\tvalid_1's rmse: 0.904967\n",
      "[27]\ttraining's rmse: 0.931333\tvalid_1's rmse: 0.90461\n",
      "[28]\ttraining's rmse: 0.929838\tvalid_1's rmse: 0.904773\n",
      "[29]\ttraining's rmse: 0.927921\tvalid_1's rmse: 0.903877\n",
      "[30]\ttraining's rmse: 0.926126\tvalid_1's rmse: 0.902234\n",
      "[31]\ttraining's rmse: 0.924623\tvalid_1's rmse: 0.902325\n",
      "[32]\ttraining's rmse: 0.922664\tvalid_1's rmse: 0.902515\n",
      "[33]\ttraining's rmse: 0.921079\tvalid_1's rmse: 0.900762\n",
      "[34]\ttraining's rmse: 0.920002\tvalid_1's rmse: 0.900519\n",
      "[35]\ttraining's rmse: 0.918987\tvalid_1's rmse: 0.900496\n",
      "[36]\ttraining's rmse: 0.917762\tvalid_1's rmse: 0.900116\n",
      "[37]\ttraining's rmse: 0.916708\tvalid_1's rmse: 0.900352\n",
      "[38]\ttraining's rmse: 0.915649\tvalid_1's rmse: 0.89998\n",
      "[39]\ttraining's rmse: 0.91449\tvalid_1's rmse: 0.899852\n",
      "[40]\ttraining's rmse: 0.913694\tvalid_1's rmse: 0.900117\n",
      "[41]\ttraining's rmse: 0.912834\tvalid_1's rmse: 0.900281\n",
      "[42]\ttraining's rmse: 0.91213\tvalid_1's rmse: 0.90003\n",
      "[43]\ttraining's rmse: 0.911287\tvalid_1's rmse: 0.899885\n",
      "[44]\ttraining's rmse: 0.910679\tvalid_1's rmse: 0.900658\n",
      "[45]\ttraining's rmse: 0.909839\tvalid_1's rmse: 0.90061\n",
      "[46]\ttraining's rmse: 0.909253\tvalid_1's rmse: 0.900921\n",
      "[47]\ttraining's rmse: 0.908378\tvalid_1's rmse: 0.900751\n",
      "[48]\ttraining's rmse: 0.907642\tvalid_1's rmse: 0.900761\n",
      "[49]\ttraining's rmse: 0.906833\tvalid_1's rmse: 0.90106\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 0.91449\tvalid_1's rmse: 0.899852\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 2, 'reg_alpha': 2, 'objective': None, 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_1\n",
      "[1]\ttraining's rmse: 1.28981\tvalid_1's rmse: 1.11\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.25363\tvalid_1's rmse: 1.08716\n",
      "[3]\ttraining's rmse: 1.22299\tvalid_1's rmse: 1.06782\n",
      "[4]\ttraining's rmse: 1.19697\tvalid_1's rmse: 1.05164\n",
      "[5]\ttraining's rmse: 1.17488\tvalid_1's rmse: 1.03827\n",
      "[6]\ttraining's rmse: 1.15544\tvalid_1's rmse: 1.02588\n",
      "[7]\ttraining's rmse: 1.13959\tvalid_1's rmse: 1.01633\n",
      "[8]\ttraining's rmse: 1.12566\tvalid_1's rmse: 1.00749\n",
      "[9]\ttraining's rmse: 1.11412\tvalid_1's rmse: 1.00098\n",
      "[10]\ttraining's rmse: 1.10379\tvalid_1's rmse: 0.99525\n",
      "[11]\ttraining's rmse: 1.09545\tvalid_1's rmse: 0.990419\n",
      "[12]\ttraining's rmse: 1.08515\tvalid_1's rmse: 0.983364\n",
      "[13]\ttraining's rmse: 1.07435\tvalid_1's rmse: 0.975221\n",
      "[14]\ttraining's rmse: 1.06869\tvalid_1's rmse: 0.972304\n",
      "[15]\ttraining's rmse: 1.06373\tvalid_1's rmse: 0.969007\n",
      "[16]\ttraining's rmse: 1.05878\tvalid_1's rmse: 0.965698\n",
      "[17]\ttraining's rmse: 1.05473\tvalid_1's rmse: 0.963348\n",
      "[18]\ttraining's rmse: 1.05058\tvalid_1's rmse: 0.960508\n",
      "[19]\ttraining's rmse: 1.04752\tvalid_1's rmse: 0.95949\n",
      "[20]\ttraining's rmse: 1.04441\tvalid_1's rmse: 0.957102\n",
      "[21]\ttraining's rmse: 1.04116\tvalid_1's rmse: 0.955168\n",
      "[22]\ttraining's rmse: 1.0375\tvalid_1's rmse: 0.953125\n",
      "[23]\ttraining's rmse: 1.03494\tvalid_1's rmse: 0.951214\n",
      "[24]\ttraining's rmse: 1.03262\tvalid_1's rmse: 0.949408\n",
      "[25]\ttraining's rmse: 1.03065\tvalid_1's rmse: 0.948636\n",
      "[26]\ttraining's rmse: 1.02859\tvalid_1's rmse: 0.947311\n",
      "[27]\ttraining's rmse: 1.02667\tvalid_1's rmse: 0.945899\n",
      "[28]\ttraining's rmse: 1.0249\tvalid_1's rmse: 0.944915\n",
      "[29]\ttraining's rmse: 1.0212\tvalid_1's rmse: 0.941737\n",
      "[30]\ttraining's rmse: 1.01994\tvalid_1's rmse: 0.941035\n",
      "[31]\ttraining's rmse: 1.01868\tvalid_1's rmse: 0.940683\n",
      "[32]\ttraining's rmse: 1.01766\tvalid_1's rmse: 0.940393\n",
      "[33]\ttraining's rmse: 1.01372\tvalid_1's rmse: 0.937979\n",
      "[34]\ttraining's rmse: 1.01051\tvalid_1's rmse: 0.935674\n",
      "[35]\ttraining's rmse: 1.00808\tvalid_1's rmse: 0.933982\n",
      "[36]\ttraining's rmse: 1.00721\tvalid_1's rmse: 0.933415\n",
      "[37]\ttraining's rmse: 1.00634\tvalid_1's rmse: 0.933314\n",
      "[38]\ttraining's rmse: 1.00522\tvalid_1's rmse: 0.932639\n",
      "[39]\ttraining's rmse: 1.00322\tvalid_1's rmse: 0.931373\n",
      "[40]\ttraining's rmse: 1.00263\tvalid_1's rmse: 0.930944\n",
      "[41]\ttraining's rmse: 1.00207\tvalid_1's rmse: 0.930814\n",
      "[42]\ttraining's rmse: 1.00115\tvalid_1's rmse: 0.930474\n",
      "[43]\ttraining's rmse: 1.00051\tvalid_1's rmse: 0.930373\n",
      "[44]\ttraining's rmse: 0.999896\tvalid_1's rmse: 0.930084\n",
      "[45]\ttraining's rmse: 0.997715\tvalid_1's rmse: 0.928299\n",
      "[46]\ttraining's rmse: 0.997311\tvalid_1's rmse: 0.928241\n",
      "[47]\ttraining's rmse: 0.996683\tvalid_1's rmse: 0.928257\n",
      "[48]\ttraining's rmse: 0.996301\tvalid_1's rmse: 0.927997\n",
      "[49]\ttraining's rmse: 0.994112\tvalid_1's rmse: 0.927027\n",
      "[50]\ttraining's rmse: 0.99318\tvalid_1's rmse: 0.927118\n",
      "[51]\ttraining's rmse: 0.992827\tvalid_1's rmse: 0.926791\n",
      "[52]\ttraining's rmse: 0.992005\tvalid_1's rmse: 0.926526\n",
      "[53]\ttraining's rmse: 0.9911\tvalid_1's rmse: 0.926666\n",
      "[54]\ttraining's rmse: 0.99056\tvalid_1's rmse: 0.926533\n",
      "[55]\ttraining's rmse: 0.989337\tvalid_1's rmse: 0.92593\n",
      "[56]\ttraining's rmse: 0.988928\tvalid_1's rmse: 0.925822\n",
      "[57]\ttraining's rmse: 0.988213\tvalid_1's rmse: 0.925874\n",
      "[58]\ttraining's rmse: 0.987949\tvalid_1's rmse: 0.925715\n",
      "[59]\ttraining's rmse: 0.987305\tvalid_1's rmse: 0.925801\n",
      "[60]\ttraining's rmse: 0.987023\tvalid_1's rmse: 0.925687\n",
      "[61]\ttraining's rmse: 0.986131\tvalid_1's rmse: 0.925249\n",
      "[62]\ttraining's rmse: 0.985824\tvalid_1's rmse: 0.925153\n",
      "[63]\ttraining's rmse: 0.985471\tvalid_1's rmse: 0.925267\n",
      "[64]\ttraining's rmse: 0.984985\tvalid_1's rmse: 0.925271\n",
      "[65]\ttraining's rmse: 0.984671\tvalid_1's rmse: 0.925176\n",
      "[66]\ttraining's rmse: 0.984397\tvalid_1's rmse: 0.92509\n",
      "[67]\ttraining's rmse: 0.983998\tvalid_1's rmse: 0.924935\n",
      "[68]\ttraining's rmse: 0.983635\tvalid_1's rmse: 0.924984\n",
      "[69]\ttraining's rmse: 0.982757\tvalid_1's rmse: 0.924653\n",
      "[70]\ttraining's rmse: 0.982485\tvalid_1's rmse: 0.924435\n",
      "[71]\ttraining's rmse: 0.981372\tvalid_1's rmse: 0.923946\n",
      "[72]\ttraining's rmse: 0.981145\tvalid_1's rmse: 0.923557\n",
      "[73]\ttraining's rmse: 0.980862\tvalid_1's rmse: 0.923491\n",
      "[74]\ttraining's rmse: 0.980481\tvalid_1's rmse: 0.923428\n",
      "[75]\ttraining's rmse: 0.980317\tvalid_1's rmse: 0.923105\n",
      "[76]\ttraining's rmse: 0.979846\tvalid_1's rmse: 0.92296\n",
      "[77]\ttraining's rmse: 0.979375\tvalid_1's rmse: 0.922612\n",
      "[78]\ttraining's rmse: 0.979032\tvalid_1's rmse: 0.923012\n",
      "[79]\ttraining's rmse: 0.978724\tvalid_1's rmse: 0.923067\n",
      "[80]\ttraining's rmse: 0.978416\tvalid_1's rmse: 0.923206\n",
      "[81]\ttraining's rmse: 0.978147\tvalid_1's rmse: 0.923093\n",
      "[82]\ttraining's rmse: 0.977816\tvalid_1's rmse: 0.923028\n",
      "[83]\ttraining's rmse: 0.977671\tvalid_1's rmse: 0.922893\n",
      "[84]\ttraining's rmse: 0.977168\tvalid_1's rmse: 0.922469\n",
      "[85]\ttraining's rmse: 0.976924\tvalid_1's rmse: 0.922458\n",
      "[86]\ttraining's rmse: 0.976398\tvalid_1's rmse: 0.922538\n",
      "[87]\ttraining's rmse: 0.97616\tvalid_1's rmse: 0.922496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88]\ttraining's rmse: 0.975801\tvalid_1's rmse: 0.922611\n",
      "[89]\ttraining's rmse: 0.975569\tvalid_1's rmse: 0.92241\n",
      "[90]\ttraining's rmse: 0.975367\tvalid_1's rmse: 0.922359\n",
      "[91]\ttraining's rmse: 0.975226\tvalid_1's rmse: 0.922371\n",
      "[92]\ttraining's rmse: 0.974831\tvalid_1's rmse: 0.921995\n",
      "[93]\ttraining's rmse: 0.974617\tvalid_1's rmse: 0.921992\n",
      "[94]\ttraining's rmse: 0.974401\tvalid_1's rmse: 0.922066\n",
      "[95]\ttraining's rmse: 0.974282\tvalid_1's rmse: 0.922066\n",
      "[96]\ttraining's rmse: 0.973902\tvalid_1's rmse: 0.922006\n",
      "[97]\ttraining's rmse: 0.973483\tvalid_1's rmse: 0.921986\n",
      "[98]\ttraining's rmse: 0.973169\tvalid_1's rmse: 0.921969\n",
      "[99]\ttraining's rmse: 0.972893\tvalid_1's rmse: 0.92174\n",
      "[100]\ttraining's rmse: 0.972698\tvalid_1's rmse: 0.921784\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972698\tvalid_1's rmse: 0.921784\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_2\n",
      "[1]\ttraining's rmse: 1.28979\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2536\tvalid_1's rmse: 1.08714\n",
      "[3]\ttraining's rmse: 1.22296\tvalid_1's rmse: 1.06779\n",
      "[4]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.05161\n",
      "[5]\ttraining's rmse: 1.17483\tvalid_1's rmse: 1.03824\n",
      "[6]\ttraining's rmse: 1.15539\tvalid_1's rmse: 1.02585\n",
      "[7]\ttraining's rmse: 1.13955\tvalid_1's rmse: 1.0163\n",
      "[8]\ttraining's rmse: 1.12562\tvalid_1's rmse: 1.00746\n",
      "[9]\ttraining's rmse: 1.11408\tvalid_1's rmse: 1.00096\n",
      "[10]\ttraining's rmse: 1.10376\tvalid_1's rmse: 0.995226\n",
      "[11]\ttraining's rmse: 1.09542\tvalid_1's rmse: 0.990395\n",
      "[12]\ttraining's rmse: 1.08511\tvalid_1's rmse: 0.983343\n",
      "[13]\ttraining's rmse: 1.07432\tvalid_1's rmse: 0.975201\n",
      "[14]\ttraining's rmse: 1.06866\tvalid_1's rmse: 0.972286\n",
      "[15]\ttraining's rmse: 1.0637\tvalid_1's rmse: 0.968991\n",
      "[16]\ttraining's rmse: 1.05876\tvalid_1's rmse: 0.965681\n",
      "[17]\ttraining's rmse: 1.05471\tvalid_1's rmse: 0.963333\n",
      "[18]\ttraining's rmse: 1.05056\tvalid_1's rmse: 0.960493\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959476\n",
      "[20]\ttraining's rmse: 1.04439\tvalid_1's rmse: 0.95709\n",
      "[21]\ttraining's rmse: 1.04114\tvalid_1's rmse: 0.955156\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953113\n",
      "[23]\ttraining's rmse: 1.03492\tvalid_1's rmse: 0.951204\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949399\n",
      "[25]\ttraining's rmse: 1.03063\tvalid_1's rmse: 0.948626\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947303\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945891\n",
      "[28]\ttraining's rmse: 1.02488\tvalid_1's rmse: 0.944907\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.941729\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.941028\n",
      "[31]\ttraining's rmse: 1.01866\tvalid_1's rmse: 0.940675\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940386\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937971\n",
      "[34]\ttraining's rmse: 1.01048\tvalid_1's rmse: 0.935667\n",
      "[35]\ttraining's rmse: 1.00806\tvalid_1's rmse: 0.933975\n",
      "[36]\ttraining's rmse: 1.00719\tvalid_1's rmse: 0.933409\n",
      "[37]\ttraining's rmse: 1.00631\tvalid_1's rmse: 0.933309\n",
      "[38]\ttraining's rmse: 1.00519\tvalid_1's rmse: 0.932635\n",
      "[39]\ttraining's rmse: 1.00319\tvalid_1's rmse: 0.93137\n",
      "[40]\ttraining's rmse: 1.00244\tvalid_1's rmse: 0.931081\n",
      "[41]\ttraining's rmse: 1.00187\tvalid_1's rmse: 0.930934\n",
      "[42]\ttraining's rmse: 1.00141\tvalid_1's rmse: 0.930771\n",
      "[43]\ttraining's rmse: 0.999171\tvalid_1's rmse: 0.928971\n",
      "[44]\ttraining's rmse: 0.998487\tvalid_1's rmse: 0.928968\n",
      "[45]\ttraining's rmse: 0.997752\tvalid_1's rmse: 0.928877\n",
      "[46]\ttraining's rmse: 0.997342\tvalid_1's rmse: 0.928663\n",
      "[47]\ttraining's rmse: 0.996915\tvalid_1's rmse: 0.928582\n",
      "[48]\ttraining's rmse: 0.996094\tvalid_1's rmse: 0.928159\n",
      "[49]\ttraining's rmse: 0.995543\tvalid_1's rmse: 0.927992\n",
      "[50]\ttraining's rmse: 0.994514\tvalid_1's rmse: 0.927969\n",
      "[51]\ttraining's rmse: 0.993931\tvalid_1's rmse: 0.927363\n",
      "[52]\ttraining's rmse: 0.992287\tvalid_1's rmse: 0.92626\n",
      "[53]\ttraining's rmse: 0.991591\tvalid_1's rmse: 0.92608\n",
      "[54]\ttraining's rmse: 0.989976\tvalid_1's rmse: 0.925467\n",
      "[55]\ttraining's rmse: 0.989286\tvalid_1's rmse: 0.924848\n",
      "[56]\ttraining's rmse: 0.988807\tvalid_1's rmse: 0.925257\n",
      "[57]\ttraining's rmse: 0.98828\tvalid_1's rmse: 0.925475\n",
      "[58]\ttraining's rmse: 0.987743\tvalid_1's rmse: 0.925459\n",
      "[59]\ttraining's rmse: 0.987428\tvalid_1's rmse: 0.925365\n",
      "[60]\ttraining's rmse: 0.987128\tvalid_1's rmse: 0.925349\n",
      "[61]\ttraining's rmse: 0.986548\tvalid_1's rmse: 0.925123\n",
      "[62]\ttraining's rmse: 0.986058\tvalid_1's rmse: 0.924911\n",
      "[63]\ttraining's rmse: 0.985572\tvalid_1's rmse: 0.924861\n",
      "[64]\ttraining's rmse: 0.984665\tvalid_1's rmse: 0.924535\n",
      "[65]\ttraining's rmse: 0.984228\tvalid_1's rmse: 0.924426\n",
      "[66]\ttraining's rmse: 0.983828\tvalid_1's rmse: 0.924184\n",
      "[67]\ttraining's rmse: 0.983501\tvalid_1's rmse: 0.923878\n",
      "[68]\ttraining's rmse: 0.983294\tvalid_1's rmse: 0.923757\n",
      "[69]\ttraining's rmse: 0.983019\tvalid_1's rmse: 0.923676\n",
      "[70]\ttraining's rmse: 0.982598\tvalid_1's rmse: 0.923629\n",
      "[71]\ttraining's rmse: 0.982356\tvalid_1's rmse: 0.923638\n",
      "[72]\ttraining's rmse: 0.981478\tvalid_1's rmse: 0.923408\n",
      "[73]\ttraining's rmse: 0.98123\tvalid_1's rmse: 0.923204\n",
      "[74]\ttraining's rmse: 0.980717\tvalid_1's rmse: 0.922666\n",
      "[75]\ttraining's rmse: 0.980444\tvalid_1's rmse: 0.922771\n",
      "[76]\ttraining's rmse: 0.980123\tvalid_1's rmse: 0.922497\n",
      "[77]\ttraining's rmse: 0.979728\tvalid_1's rmse: 0.922357\n",
      "[78]\ttraining's rmse: 0.97951\tvalid_1's rmse: 0.921968\n",
      "[79]\ttraining's rmse: 0.979243\tvalid_1's rmse: 0.92192\n",
      "[80]\ttraining's rmse: 0.978396\tvalid_1's rmse: 0.921714\n",
      "[81]\ttraining's rmse: 0.978096\tvalid_1's rmse: 0.921844\n",
      "[82]\ttraining's rmse: 0.977328\tvalid_1's rmse: 0.921662\n",
      "[83]\ttraining's rmse: 0.977088\tvalid_1's rmse: 0.921533\n",
      "[84]\ttraining's rmse: 0.976753\tvalid_1's rmse: 0.921447\n",
      "[85]\ttraining's rmse: 0.976524\tvalid_1's rmse: 0.921383\n",
      "[86]\ttraining's rmse: 0.976327\tvalid_1's rmse: 0.921241\n",
      "[87]\ttraining's rmse: 0.975943\tvalid_1's rmse: 0.920781\n",
      "[88]\ttraining's rmse: 0.975327\tvalid_1's rmse: 0.920586\n",
      "[89]\ttraining's rmse: 0.975013\tvalid_1's rmse: 0.920767\n",
      "[90]\ttraining's rmse: 0.974799\tvalid_1's rmse: 0.920746\n",
      "[91]\ttraining's rmse: 0.974527\tvalid_1's rmse: 0.920619\n",
      "[92]\ttraining's rmse: 0.974154\tvalid_1's rmse: 0.920591\n",
      "[93]\ttraining's rmse: 0.973858\tvalid_1's rmse: 0.920683\n",
      "[94]\ttraining's rmse: 0.973724\tvalid_1's rmse: 0.920582\n",
      "[95]\ttraining's rmse: 0.973511\tvalid_1's rmse: 0.920619\n",
      "[96]\ttraining's rmse: 0.973308\tvalid_1's rmse: 0.920567\n",
      "[97]\ttraining's rmse: 0.973079\tvalid_1's rmse: 0.920476\n",
      "[98]\ttraining's rmse: 0.972721\tvalid_1's rmse: 0.920364\n",
      "[99]\ttraining's rmse: 0.972527\tvalid_1's rmse: 0.920363\n",
      "[100]\ttraining's rmse: 0.972263\tvalid_1's rmse: 0.920245\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972263\tvalid_1's rmse: 0.920245\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 5, 'reg_alpha': 2, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_3\n",
      "[1]\ttraining's rmse: 1.27985\tvalid_1's rmse: 1.10105\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.23516\tvalid_1's rmse: 1.07084\n",
      "[3]\ttraining's rmse: 1.19726\tvalid_1's rmse: 1.04472\n",
      "[4]\ttraining's rmse: 1.16517\tvalid_1's rmse: 1.0241\n",
      "[5]\ttraining's rmse: 1.13821\tvalid_1's rmse: 1.00661\n",
      "[6]\ttraining's rmse: 1.11423\tvalid_1's rmse: 0.990792\n",
      "[7]\ttraining's rmse: 1.09372\tvalid_1's rmse: 0.977446\n",
      "[8]\ttraining's rmse: 1.07697\tvalid_1's rmse: 0.967381\n",
      "[9]\ttraining's rmse: 1.06266\tvalid_1's rmse: 0.959339\n",
      "[10]\ttraining's rmse: 1.05022\tvalid_1's rmse: 0.952145\n",
      "[11]\ttraining's rmse: 1.0397\tvalid_1's rmse: 0.945912\n",
      "[12]\ttraining's rmse: 1.0301\tvalid_1's rmse: 0.941031\n",
      "[13]\ttraining's rmse: 1.02192\tvalid_1's rmse: 0.93682\n",
      "[14]\ttraining's rmse: 1.01486\tvalid_1's rmse: 0.9335\n",
      "[15]\ttraining's rmse: 1.00872\tvalid_1's rmse: 0.930727\n",
      "[16]\ttraining's rmse: 1.00345\tvalid_1's rmse: 0.927973\n",
      "[17]\ttraining's rmse: 0.998821\tvalid_1's rmse: 0.92597\n",
      "[18]\ttraining's rmse: 0.994122\tvalid_1's rmse: 0.923849\n",
      "[19]\ttraining's rmse: 0.990664\tvalid_1's rmse: 0.922618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's rmse: 0.987333\tvalid_1's rmse: 0.920727\n",
      "[21]\ttraining's rmse: 0.984065\tvalid_1's rmse: 0.919543\n",
      "[22]\ttraining's rmse: 0.981012\tvalid_1's rmse: 0.918451\n",
      "[23]\ttraining's rmse: 0.978296\tvalid_1's rmse: 0.917301\n",
      "[24]\ttraining's rmse: 0.975566\tvalid_1's rmse: 0.916229\n",
      "[25]\ttraining's rmse: 0.973287\tvalid_1's rmse: 0.915935\n",
      "[26]\ttraining's rmse: 0.971639\tvalid_1's rmse: 0.915493\n",
      "[27]\ttraining's rmse: 0.969626\tvalid_1's rmse: 0.91508\n",
      "[28]\ttraining's rmse: 0.968211\tvalid_1's rmse: 0.915046\n",
      "[29]\ttraining's rmse: 0.966494\tvalid_1's rmse: 0.914246\n",
      "[30]\ttraining's rmse: 0.964831\tvalid_1's rmse: 0.913873\n",
      "[31]\ttraining's rmse: 0.96379\tvalid_1's rmse: 0.913845\n",
      "[32]\ttraining's rmse: 0.962505\tvalid_1's rmse: 0.913566\n",
      "[33]\ttraining's rmse: 0.961548\tvalid_1's rmse: 0.913375\n",
      "[34]\ttraining's rmse: 0.960317\tvalid_1's rmse: 0.913079\n",
      "[35]\ttraining's rmse: 0.959225\tvalid_1's rmse: 0.912623\n",
      "[36]\ttraining's rmse: 0.957987\tvalid_1's rmse: 0.912406\n",
      "[37]\ttraining's rmse: 0.957106\tvalid_1's rmse: 0.912326\n",
      "[38]\ttraining's rmse: 0.956353\tvalid_1's rmse: 0.911934\n",
      "[39]\ttraining's rmse: 0.955501\tvalid_1's rmse: 0.911789\n",
      "[40]\ttraining's rmse: 0.954781\tvalid_1's rmse: 0.911653\n",
      "[41]\ttraining's rmse: 0.953948\tvalid_1's rmse: 0.91138\n",
      "[42]\ttraining's rmse: 0.952515\tvalid_1's rmse: 0.910532\n",
      "[43]\ttraining's rmse: 0.951942\tvalid_1's rmse: 0.910175\n",
      "[44]\ttraining's rmse: 0.951405\tvalid_1's rmse: 0.910372\n",
      "[45]\ttraining's rmse: 0.950866\tvalid_1's rmse: 0.910245\n",
      "[46]\ttraining's rmse: 0.949722\tvalid_1's rmse: 0.909674\n",
      "[47]\ttraining's rmse: 0.948984\tvalid_1's rmse: 0.909634\n",
      "[48]\ttraining's rmse: 0.948124\tvalid_1's rmse: 0.909709\n",
      "[49]\ttraining's rmse: 0.947334\tvalid_1's rmse: 0.909372\n",
      "[50]\ttraining's rmse: 0.946343\tvalid_1's rmse: 0.909091\n",
      "[51]\ttraining's rmse: 0.945904\tvalid_1's rmse: 0.908747\n",
      "[52]\ttraining's rmse: 0.945431\tvalid_1's rmse: 0.909153\n",
      "[53]\ttraining's rmse: 0.944862\tvalid_1's rmse: 0.909197\n",
      "[54]\ttraining's rmse: 0.943961\tvalid_1's rmse: 0.908878\n",
      "[55]\ttraining's rmse: 0.943202\tvalid_1's rmse: 0.908852\n",
      "[56]\ttraining's rmse: 0.942656\tvalid_1's rmse: 0.908979\n",
      "[57]\ttraining's rmse: 0.942244\tvalid_1's rmse: 0.908893\n",
      "[58]\ttraining's rmse: 0.941767\tvalid_1's rmse: 0.908972\n",
      "[59]\ttraining's rmse: 0.941224\tvalid_1's rmse: 0.908834\n",
      "[60]\ttraining's rmse: 0.940681\tvalid_1's rmse: 0.908715\n",
      "[61]\ttraining's rmse: 0.940025\tvalid_1's rmse: 0.908384\n",
      "[62]\ttraining's rmse: 0.939626\tvalid_1's rmse: 0.908229\n",
      "[63]\ttraining's rmse: 0.93917\tvalid_1's rmse: 0.908014\n",
      "[64]\ttraining's rmse: 0.938767\tvalid_1's rmse: 0.907975\n",
      "[65]\ttraining's rmse: 0.938082\tvalid_1's rmse: 0.90801\n",
      "[66]\ttraining's rmse: 0.937679\tvalid_1's rmse: 0.907917\n",
      "[67]\ttraining's rmse: 0.937239\tvalid_1's rmse: 0.908016\n",
      "[68]\ttraining's rmse: 0.936625\tvalid_1's rmse: 0.908059\n",
      "[69]\ttraining's rmse: 0.936239\tvalid_1's rmse: 0.908321\n",
      "[70]\ttraining's rmse: 0.935989\tvalid_1's rmse: 0.908131\n",
      "[71]\ttraining's rmse: 0.935613\tvalid_1's rmse: 0.90809\n",
      "[72]\ttraining's rmse: 0.934712\tvalid_1's rmse: 0.907673\n",
      "[73]\ttraining's rmse: 0.934175\tvalid_1's rmse: 0.906875\n",
      "[74]\ttraining's rmse: 0.933845\tvalid_1's rmse: 0.907047\n",
      "[75]\ttraining's rmse: 0.933525\tvalid_1's rmse: 0.906778\n",
      "[76]\ttraining's rmse: 0.933278\tvalid_1's rmse: 0.906777\n",
      "[77]\ttraining's rmse: 0.932773\tvalid_1's rmse: 0.906401\n",
      "[78]\ttraining's rmse: 0.932333\tvalid_1's rmse: 0.905916\n",
      "[79]\ttraining's rmse: 0.931593\tvalid_1's rmse: 0.905806\n",
      "[80]\ttraining's rmse: 0.930961\tvalid_1's rmse: 0.906204\n",
      "[81]\ttraining's rmse: 0.930554\tvalid_1's rmse: 0.906085\n",
      "[82]\ttraining's rmse: 0.930249\tvalid_1's rmse: 0.905952\n",
      "[83]\ttraining's rmse: 0.930033\tvalid_1's rmse: 0.905906\n",
      "[84]\ttraining's rmse: 0.929483\tvalid_1's rmse: 0.905861\n",
      "[85]\ttraining's rmse: 0.929279\tvalid_1's rmse: 0.905765\n",
      "[86]\ttraining's rmse: 0.928996\tvalid_1's rmse: 0.905699\n",
      "[87]\ttraining's rmse: 0.928717\tvalid_1's rmse: 0.905651\n",
      "[88]\ttraining's rmse: 0.928484\tvalid_1's rmse: 0.905734\n",
      "[89]\ttraining's rmse: 0.928157\tvalid_1's rmse: 0.905796\n",
      "[90]\ttraining's rmse: 0.927785\tvalid_1's rmse: 0.905512\n",
      "[91]\ttraining's rmse: 0.927472\tvalid_1's rmse: 0.905425\n",
      "[92]\ttraining's rmse: 0.926984\tvalid_1's rmse: 0.90536\n",
      "[93]\ttraining's rmse: 0.926683\tvalid_1's rmse: 0.905528\n",
      "[94]\ttraining's rmse: 0.926329\tvalid_1's rmse: 0.905361\n",
      "[95]\ttraining's rmse: 0.926067\tvalid_1's rmse: 0.905285\n",
      "[96]\ttraining's rmse: 0.925739\tvalid_1's rmse: 0.905333\n",
      "[97]\ttraining's rmse: 0.925012\tvalid_1's rmse: 0.905142\n",
      "[98]\ttraining's rmse: 0.924733\tvalid_1's rmse: 0.905161\n",
      "[99]\ttraining's rmse: 0.924531\tvalid_1's rmse: 0.905133\n",
      "[100]\ttraining's rmse: 0.924204\tvalid_1's rmse: 0.904934\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.924204\tvalid_1's rmse: 0.904934\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'objective': None, 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_4\n",
      "[1]\ttraining's rmse: 1.27972\tvalid_1's rmse: 1.10092\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2349\tvalid_1's rmse: 1.07062\n",
      "[3]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.04446\n",
      "[4]\ttraining's rmse: 1.16482\tvalid_1's rmse: 1.02353\n",
      "[5]\ttraining's rmse: 1.13784\tvalid_1's rmse: 1.00646\n",
      "[6]\ttraining's rmse: 1.11385\tvalid_1's rmse: 0.990685\n",
      "[7]\ttraining's rmse: 1.09347\tvalid_1's rmse: 0.977182\n",
      "[8]\ttraining's rmse: 1.07671\tvalid_1's rmse: 0.967542\n",
      "[9]\ttraining's rmse: 1.06198\tvalid_1's rmse: 0.958302\n",
      "[10]\ttraining's rmse: 1.05\tvalid_1's rmse: 0.951171\n",
      "[11]\ttraining's rmse: 1.03894\tvalid_1's rmse: 0.945007\n",
      "[12]\ttraining's rmse: 1.02966\tvalid_1's rmse: 0.939906\n",
      "[13]\ttraining's rmse: 1.0213\tvalid_1's rmse: 0.935888\n",
      "[14]\ttraining's rmse: 1.01482\tvalid_1's rmse: 0.933241\n",
      "[15]\ttraining's rmse: 1.00881\tvalid_1's rmse: 0.930579\n",
      "[16]\ttraining's rmse: 1.00332\tvalid_1's rmse: 0.928085\n",
      "[17]\ttraining's rmse: 0.99887\tvalid_1's rmse: 0.926325\n",
      "[18]\ttraining's rmse: 0.994947\tvalid_1's rmse: 0.924339\n",
      "[19]\ttraining's rmse: 0.991478\tvalid_1's rmse: 0.922898\n",
      "[20]\ttraining's rmse: 0.987762\tvalid_1's rmse: 0.921588\n",
      "[21]\ttraining's rmse: 0.98402\tvalid_1's rmse: 0.919876\n",
      "[22]\ttraining's rmse: 0.98037\tvalid_1's rmse: 0.918466\n",
      "[23]\ttraining's rmse: 0.977822\tvalid_1's rmse: 0.917848\n",
      "[24]\ttraining's rmse: 0.975733\tvalid_1's rmse: 0.917087\n",
      "[25]\ttraining's rmse: 0.97322\tvalid_1's rmse: 0.916448\n",
      "[26]\ttraining's rmse: 0.971543\tvalid_1's rmse: 0.916018\n",
      "[27]\ttraining's rmse: 0.968922\tvalid_1's rmse: 0.915227\n",
      "[28]\ttraining's rmse: 0.967309\tvalid_1's rmse: 0.915006\n",
      "[29]\ttraining's rmse: 0.965748\tvalid_1's rmse: 0.914417\n",
      "[30]\ttraining's rmse: 0.964173\tvalid_1's rmse: 0.913705\n",
      "[31]\ttraining's rmse: 0.962639\tvalid_1's rmse: 0.91314\n",
      "[32]\ttraining's rmse: 0.961064\tvalid_1's rmse: 0.913539\n",
      "[33]\ttraining's rmse: 0.95992\tvalid_1's rmse: 0.913401\n",
      "[34]\ttraining's rmse: 0.95905\tvalid_1's rmse: 0.913368\n",
      "[35]\ttraining's rmse: 0.957975\tvalid_1's rmse: 0.913172\n",
      "[36]\ttraining's rmse: 0.957187\tvalid_1's rmse: 0.913155\n",
      "[37]\ttraining's rmse: 0.956305\tvalid_1's rmse: 0.912987\n",
      "[38]\ttraining's rmse: 0.955584\tvalid_1's rmse: 0.912972\n",
      "[39]\ttraining's rmse: 0.954727\tvalid_1's rmse: 0.912611\n",
      "[40]\ttraining's rmse: 0.953478\tvalid_1's rmse: 0.912622\n",
      "[41]\ttraining's rmse: 0.952623\tvalid_1's rmse: 0.912344\n",
      "[42]\ttraining's rmse: 0.951859\tvalid_1's rmse: 0.912077\n",
      "[43]\ttraining's rmse: 0.95122\tvalid_1's rmse: 0.911805\n",
      "[44]\ttraining's rmse: 0.950611\tvalid_1's rmse: 0.911857\n",
      "[45]\ttraining's rmse: 0.949879\tvalid_1's rmse: 0.911665\n",
      "[46]\ttraining's rmse: 0.949198\tvalid_1's rmse: 0.911316\n",
      "[47]\ttraining's rmse: 0.948666\tvalid_1's rmse: 0.911255\n",
      "[48]\ttraining's rmse: 0.947662\tvalid_1's rmse: 0.91107\n",
      "[49]\ttraining's rmse: 0.947097\tvalid_1's rmse: 0.911002\n",
      "[50]\ttraining's rmse: 0.946544\tvalid_1's rmse: 0.911061\n",
      "[51]\ttraining's rmse: 0.945854\tvalid_1's rmse: 0.910469\n",
      "[52]\ttraining's rmse: 0.945356\tvalid_1's rmse: 0.910652\n",
      "[53]\ttraining's rmse: 0.944777\tvalid_1's rmse: 0.910664\n",
      "[54]\ttraining's rmse: 0.944113\tvalid_1's rmse: 0.910308\n",
      "[55]\ttraining's rmse: 0.943263\tvalid_1's rmse: 0.909873\n",
      "[56]\ttraining's rmse: 0.942829\tvalid_1's rmse: 0.909853\n",
      "[57]\ttraining's rmse: 0.942281\tvalid_1's rmse: 0.909794\n",
      "[58]\ttraining's rmse: 0.941722\tvalid_1's rmse: 0.909725\n",
      "[59]\ttraining's rmse: 0.941298\tvalid_1's rmse: 0.90967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\ttraining's rmse: 0.940462\tvalid_1's rmse: 0.909842\n",
      "[61]\ttraining's rmse: 0.940051\tvalid_1's rmse: 0.909764\n",
      "[62]\ttraining's rmse: 0.939676\tvalid_1's rmse: 0.90973\n",
      "[63]\ttraining's rmse: 0.939226\tvalid_1's rmse: 0.909489\n",
      "[64]\ttraining's rmse: 0.938829\tvalid_1's rmse: 0.909715\n",
      "[65]\ttraining's rmse: 0.938261\tvalid_1's rmse: 0.90988\n",
      "[66]\ttraining's rmse: 0.937722\tvalid_1's rmse: 0.909822\n",
      "[67]\ttraining's rmse: 0.937377\tvalid_1's rmse: 0.909691\n",
      "[68]\ttraining's rmse: 0.936959\tvalid_1's rmse: 0.90955\n",
      "[69]\ttraining's rmse: 0.93669\tvalid_1's rmse: 0.909537\n",
      "[70]\ttraining's rmse: 0.935919\tvalid_1's rmse: 0.90914\n",
      "[71]\ttraining's rmse: 0.935039\tvalid_1's rmse: 0.908619\n",
      "[72]\ttraining's rmse: 0.934426\tvalid_1's rmse: 0.908284\n",
      "[73]\ttraining's rmse: 0.934067\tvalid_1's rmse: 0.907928\n",
      "[74]\ttraining's rmse: 0.933706\tvalid_1's rmse: 0.908078\n",
      "[75]\ttraining's rmse: 0.93323\tvalid_1's rmse: 0.906719\n",
      "[76]\ttraining's rmse: 0.932945\tvalid_1's rmse: 0.906576\n",
      "[77]\ttraining's rmse: 0.932592\tvalid_1's rmse: 0.906639\n",
      "[78]\ttraining's rmse: 0.932057\tvalid_1's rmse: 0.905441\n",
      "[79]\ttraining's rmse: 0.931329\tvalid_1's rmse: 0.905004\n",
      "[80]\ttraining's rmse: 0.930724\tvalid_1's rmse: 0.904938\n",
      "[81]\ttraining's rmse: 0.930236\tvalid_1's rmse: 0.904752\n",
      "[82]\ttraining's rmse: 0.929785\tvalid_1's rmse: 0.904608\n",
      "[83]\ttraining's rmse: 0.929502\tvalid_1's rmse: 0.904568\n",
      "[84]\ttraining's rmse: 0.928987\tvalid_1's rmse: 0.903442\n",
      "[85]\ttraining's rmse: 0.928786\tvalid_1's rmse: 0.903281\n",
      "[86]\ttraining's rmse: 0.928474\tvalid_1's rmse: 0.903297\n",
      "[87]\ttraining's rmse: 0.928032\tvalid_1's rmse: 0.90315\n",
      "[88]\ttraining's rmse: 0.927698\tvalid_1's rmse: 0.903084\n",
      "[89]\ttraining's rmse: 0.927297\tvalid_1's rmse: 0.903305\n",
      "[90]\ttraining's rmse: 0.926973\tvalid_1's rmse: 0.903093\n",
      "[91]\ttraining's rmse: 0.92667\tvalid_1's rmse: 0.903259\n",
      "[92]\ttraining's rmse: 0.92639\tvalid_1's rmse: 0.903365\n",
      "[93]\ttraining's rmse: 0.926081\tvalid_1's rmse: 0.903022\n",
      "[94]\ttraining's rmse: 0.925805\tvalid_1's rmse: 0.90292\n",
      "[95]\ttraining's rmse: 0.925109\tvalid_1's rmse: 0.903281\n",
      "[96]\ttraining's rmse: 0.924681\tvalid_1's rmse: 0.903158\n",
      "[97]\ttraining's rmse: 0.924146\tvalid_1's rmse: 0.902919\n",
      "[98]\ttraining's rmse: 0.923781\tvalid_1's rmse: 0.903195\n",
      "[99]\ttraining's rmse: 0.923502\tvalid_1's rmse: 0.903202\n",
      "[100]\ttraining's rmse: 0.923325\tvalid_1's rmse: 0.903111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.923325\tvalid_1's rmse: 0.903111\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_5\n",
      "[1]\ttraining's rmse: 1.27972\tvalid_1's rmse: 1.10093\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2349\tvalid_1's rmse: 1.07062\n",
      "[3]\ttraining's rmse: 1.19694\tvalid_1's rmse: 1.04447\n",
      "[4]\ttraining's rmse: 1.16483\tvalid_1's rmse: 1.02354\n",
      "[5]\ttraining's rmse: 1.13785\tvalid_1's rmse: 1.00646\n",
      "[6]\ttraining's rmse: 1.11386\tvalid_1's rmse: 0.990691\n",
      "[7]\ttraining's rmse: 1.09348\tvalid_1's rmse: 0.977188\n",
      "[8]\ttraining's rmse: 1.07672\tvalid_1's rmse: 0.967549\n",
      "[9]\ttraining's rmse: 1.06199\tvalid_1's rmse: 0.958308\n",
      "[10]\ttraining's rmse: 1.05001\tvalid_1's rmse: 0.951178\n",
      "[11]\ttraining's rmse: 1.03895\tvalid_1's rmse: 0.945013\n",
      "[12]\ttraining's rmse: 1.02967\tvalid_1's rmse: 0.939913\n",
      "[13]\ttraining's rmse: 1.02131\tvalid_1's rmse: 0.935894\n",
      "[14]\ttraining's rmse: 1.01483\tvalid_1's rmse: 0.933247\n",
      "[15]\ttraining's rmse: 1.00882\tvalid_1's rmse: 0.930585\n",
      "[16]\ttraining's rmse: 1.00333\tvalid_1's rmse: 0.928091\n",
      "[17]\ttraining's rmse: 0.99888\tvalid_1's rmse: 0.926331\n",
      "[18]\ttraining's rmse: 0.994958\tvalid_1's rmse: 0.924344\n",
      "[19]\ttraining's rmse: 0.991489\tvalid_1's rmse: 0.922904\n",
      "[20]\ttraining's rmse: 0.987773\tvalid_1's rmse: 0.921594\n",
      "[21]\ttraining's rmse: 0.984031\tvalid_1's rmse: 0.919882\n",
      "[22]\ttraining's rmse: 0.980382\tvalid_1's rmse: 0.918473\n",
      "[23]\ttraining's rmse: 0.977834\tvalid_1's rmse: 0.917855\n",
      "[24]\ttraining's rmse: 0.975744\tvalid_1's rmse: 0.917093\n",
      "[25]\ttraining's rmse: 0.973231\tvalid_1's rmse: 0.916454\n",
      "[26]\ttraining's rmse: 0.971555\tvalid_1's rmse: 0.916024\n",
      "[27]\ttraining's rmse: 0.968934\tvalid_1's rmse: 0.915233\n",
      "[28]\ttraining's rmse: 0.967315\tvalid_1's rmse: 0.915014\n",
      "[29]\ttraining's rmse: 0.965754\tvalid_1's rmse: 0.914425\n",
      "[30]\ttraining's rmse: 0.964179\tvalid_1's rmse: 0.913729\n",
      "[31]\ttraining's rmse: 0.962677\tvalid_1's rmse: 0.913226\n",
      "[32]\ttraining's rmse: 0.961102\tvalid_1's rmse: 0.913621\n",
      "[33]\ttraining's rmse: 0.959955\tvalid_1's rmse: 0.913483\n",
      "[34]\ttraining's rmse: 0.958817\tvalid_1's rmse: 0.913244\n",
      "[35]\ttraining's rmse: 0.957979\tvalid_1's rmse: 0.913194\n",
      "[36]\ttraining's rmse: 0.956992\tvalid_1's rmse: 0.913316\n",
      "[37]\ttraining's rmse: 0.956151\tvalid_1's rmse: 0.912981\n",
      "[38]\ttraining's rmse: 0.955152\tvalid_1's rmse: 0.912656\n",
      "[39]\ttraining's rmse: 0.954497\tvalid_1's rmse: 0.912822\n",
      "[40]\ttraining's rmse: 0.953667\tvalid_1's rmse: 0.912673\n",
      "[41]\ttraining's rmse: 0.953078\tvalid_1's rmse: 0.912278\n",
      "[42]\ttraining's rmse: 0.952474\tvalid_1's rmse: 0.912223\n",
      "[43]\ttraining's rmse: 0.951903\tvalid_1's rmse: 0.91191\n",
      "[44]\ttraining's rmse: 0.950564\tvalid_1's rmse: 0.911727\n",
      "[45]\ttraining's rmse: 0.949458\tvalid_1's rmse: 0.911898\n",
      "[46]\ttraining's rmse: 0.948711\tvalid_1's rmse: 0.911818\n",
      "[47]\ttraining's rmse: 0.948118\tvalid_1's rmse: 0.91193\n",
      "[48]\ttraining's rmse: 0.947048\tvalid_1's rmse: 0.911921\n",
      "[49]\ttraining's rmse: 0.946224\tvalid_1's rmse: 0.911688\n",
      "[50]\ttraining's rmse: 0.945285\tvalid_1's rmse: 0.911427\n",
      "[51]\ttraining's rmse: 0.944783\tvalid_1's rmse: 0.911371\n",
      "[52]\ttraining's rmse: 0.944226\tvalid_1's rmse: 0.91156\n",
      "[53]\ttraining's rmse: 0.943718\tvalid_1's rmse: 0.911466\n",
      "[54]\ttraining's rmse: 0.943099\tvalid_1's rmse: 0.911661\n",
      "[55]\ttraining's rmse: 0.942511\tvalid_1's rmse: 0.911406\n",
      "[56]\ttraining's rmse: 0.941874\tvalid_1's rmse: 0.911595\n",
      "[57]\ttraining's rmse: 0.941124\tvalid_1's rmse: 0.909692\n",
      "[58]\ttraining's rmse: 0.940636\tvalid_1's rmse: 0.909561\n",
      "[59]\ttraining's rmse: 0.940164\tvalid_1's rmse: 0.909403\n",
      "[60]\ttraining's rmse: 0.939234\tvalid_1's rmse: 0.90891\n",
      "[61]\ttraining's rmse: 0.9389\tvalid_1's rmse: 0.909239\n",
      "[62]\ttraining's rmse: 0.938286\tvalid_1's rmse: 0.90915\n",
      "[63]\ttraining's rmse: 0.93782\tvalid_1's rmse: 0.909079\n",
      "[64]\ttraining's rmse: 0.936788\tvalid_1's rmse: 0.909027\n",
      "[65]\ttraining's rmse: 0.936503\tvalid_1's rmse: 0.90893\n",
      "[66]\ttraining's rmse: 0.935532\tvalid_1's rmse: 0.908826\n",
      "[67]\ttraining's rmse: 0.935122\tvalid_1's rmse: 0.908805\n",
      "[68]\ttraining's rmse: 0.934617\tvalid_1's rmse: 0.909038\n",
      "[69]\ttraining's rmse: 0.934374\tvalid_1's rmse: 0.909012\n",
      "[70]\ttraining's rmse: 0.93394\tvalid_1's rmse: 0.908968\n",
      "[71]\ttraining's rmse: 0.933602\tvalid_1's rmse: 0.908843\n",
      "[72]\ttraining's rmse: 0.933272\tvalid_1's rmse: 0.90893\n",
      "[73]\ttraining's rmse: 0.932554\tvalid_1's rmse: 0.908825\n",
      "[74]\ttraining's rmse: 0.932168\tvalid_1's rmse: 0.908438\n",
      "[75]\ttraining's rmse: 0.931635\tvalid_1's rmse: 0.908142\n",
      "[76]\ttraining's rmse: 0.931365\tvalid_1's rmse: 0.908371\n",
      "[77]\ttraining's rmse: 0.931041\tvalid_1's rmse: 0.908205\n",
      "[78]\ttraining's rmse: 0.930623\tvalid_1's rmse: 0.908066\n",
      "[79]\ttraining's rmse: 0.930299\tvalid_1's rmse: 0.908268\n",
      "[80]\ttraining's rmse: 0.929858\tvalid_1's rmse: 0.908246\n",
      "[81]\ttraining's rmse: 0.92942\tvalid_1's rmse: 0.908106\n",
      "[82]\ttraining's rmse: 0.929057\tvalid_1's rmse: 0.908233\n",
      "[83]\ttraining's rmse: 0.92876\tvalid_1's rmse: 0.908198\n",
      "[84]\ttraining's rmse: 0.928594\tvalid_1's rmse: 0.908399\n",
      "[85]\ttraining's rmse: 0.928316\tvalid_1's rmse: 0.908304\n",
      "[86]\ttraining's rmse: 0.928028\tvalid_1's rmse: 0.908235\n",
      "[87]\ttraining's rmse: 0.92768\tvalid_1's rmse: 0.908139\n",
      "[88]\ttraining's rmse: 0.927318\tvalid_1's rmse: 0.908131\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's rmse: 0.930623\tvalid_1's rmse: 0.908066\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.7, 'reg_lambda': 0, 'reg_alpha': 5, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 7}\n",
      "model directory : trained_models_dir/lgb\\gs_6\n",
      "[1]\ttraining's rmse: 1.27479\tvalid_1's rmse: 1.09833\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.22544\tvalid_1's rmse: 1.06503\n",
      "[3]\ttraining's rmse: 1.18337\tvalid_1's rmse: 1.03742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttraining's rmse: 1.14764\tvalid_1's rmse: 1.01452\n",
      "[5]\ttraining's rmse: 1.11683\tvalid_1's rmse: 0.996839\n",
      "[6]\ttraining's rmse: 1.09065\tvalid_1's rmse: 0.979593\n",
      "[7]\ttraining's rmse: 1.06902\tvalid_1's rmse: 0.967331\n",
      "[8]\ttraining's rmse: 1.04934\tvalid_1's rmse: 0.95571\n",
      "[9]\ttraining's rmse: 1.0332\tvalid_1's rmse: 0.946977\n",
      "[10]\ttraining's rmse: 1.01918\tvalid_1's rmse: 0.938938\n",
      "[11]\ttraining's rmse: 1.00719\tvalid_1's rmse: 0.932917\n",
      "[12]\ttraining's rmse: 0.996892\tvalid_1's rmse: 0.927882\n",
      "[13]\ttraining's rmse: 0.987001\tvalid_1's rmse: 0.924376\n",
      "[14]\ttraining's rmse: 0.979214\tvalid_1's rmse: 0.921028\n",
      "[15]\ttraining's rmse: 0.972616\tvalid_1's rmse: 0.917882\n",
      "[16]\ttraining's rmse: 0.966387\tvalid_1's rmse: 0.915683\n",
      "[17]\ttraining's rmse: 0.961488\tvalid_1's rmse: 0.913913\n",
      "[18]\ttraining's rmse: 0.956889\tvalid_1's rmse: 0.912733\n",
      "[19]\ttraining's rmse: 0.9527\tvalid_1's rmse: 0.911079\n",
      "[20]\ttraining's rmse: 0.949149\tvalid_1's rmse: 0.909649\n",
      "[21]\ttraining's rmse: 0.945676\tvalid_1's rmse: 0.908839\n",
      "[22]\ttraining's rmse: 0.942411\tvalid_1's rmse: 0.907844\n",
      "[23]\ttraining's rmse: 0.93991\tvalid_1's rmse: 0.907086\n",
      "[24]\ttraining's rmse: 0.937265\tvalid_1's rmse: 0.906128\n",
      "[25]\ttraining's rmse: 0.935036\tvalid_1's rmse: 0.905813\n",
      "[26]\ttraining's rmse: 0.932712\tvalid_1's rmse: 0.904495\n",
      "[27]\ttraining's rmse: 0.931116\tvalid_1's rmse: 0.904279\n",
      "[28]\ttraining's rmse: 0.92909\tvalid_1's rmse: 0.903677\n",
      "[29]\ttraining's rmse: 0.927612\tvalid_1's rmse: 0.903566\n",
      "[30]\ttraining's rmse: 0.925923\tvalid_1's rmse: 0.903327\n",
      "[31]\ttraining's rmse: 0.924387\tvalid_1's rmse: 0.902706\n",
      "[32]\ttraining's rmse: 0.922429\tvalid_1's rmse: 0.902299\n",
      "[33]\ttraining's rmse: 0.921064\tvalid_1's rmse: 0.902301\n",
      "[34]\ttraining's rmse: 0.91961\tvalid_1's rmse: 0.903086\n",
      "[35]\ttraining's rmse: 0.918022\tvalid_1's rmse: 0.902716\n",
      "[36]\ttraining's rmse: 0.916859\tvalid_1's rmse: 0.902476\n",
      "[37]\ttraining's rmse: 0.915848\tvalid_1's rmse: 0.902522\n",
      "[38]\ttraining's rmse: 0.914911\tvalid_1's rmse: 0.902328\n",
      "[39]\ttraining's rmse: 0.914001\tvalid_1's rmse: 0.902114\n",
      "[40]\ttraining's rmse: 0.913092\tvalid_1's rmse: 0.902507\n",
      "[41]\ttraining's rmse: 0.912292\tvalid_1's rmse: 0.902978\n",
      "[42]\ttraining's rmse: 0.911381\tvalid_1's rmse: 0.902944\n",
      "[43]\ttraining's rmse: 0.910617\tvalid_1's rmse: 0.902744\n",
      "[44]\ttraining's rmse: 0.909602\tvalid_1's rmse: 0.903634\n",
      "[45]\ttraining's rmse: 0.908647\tvalid_1's rmse: 0.904123\n",
      "[46]\ttraining's rmse: 0.907622\tvalid_1's rmse: 0.904841\n",
      "[47]\ttraining's rmse: 0.907024\tvalid_1's rmse: 0.904709\n",
      "[48]\ttraining's rmse: 0.906321\tvalid_1's rmse: 0.905106\n",
      "[49]\ttraining's rmse: 0.905587\tvalid_1's rmse: 0.905289\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 0.914001\tvalid_1's rmse: 0.902114\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 2, 'reg_alpha': 0.1, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_7\n",
      "[1]\ttraining's rmse: 1.28981\tvalid_1's rmse: 1.11\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.25362\tvalid_1's rmse: 1.08716\n",
      "[3]\ttraining's rmse: 1.22299\tvalid_1's rmse: 1.06782\n",
      "[4]\ttraining's rmse: 1.19696\tvalid_1's rmse: 1.05164\n",
      "[5]\ttraining's rmse: 1.17487\tvalid_1's rmse: 1.03827\n",
      "[6]\ttraining's rmse: 1.15543\tvalid_1's rmse: 1.02588\n",
      "[7]\ttraining's rmse: 1.13959\tvalid_1's rmse: 1.01633\n",
      "[8]\ttraining's rmse: 1.12565\tvalid_1's rmse: 1.00748\n",
      "[9]\ttraining's rmse: 1.11412\tvalid_1's rmse: 1.00098\n",
      "[10]\ttraining's rmse: 1.10379\tvalid_1's rmse: 0.995247\n",
      "[11]\ttraining's rmse: 1.09545\tvalid_1's rmse: 0.990416\n",
      "[12]\ttraining's rmse: 1.08514\tvalid_1's rmse: 0.983361\n",
      "[13]\ttraining's rmse: 1.07434\tvalid_1's rmse: 0.975219\n",
      "[14]\ttraining's rmse: 1.06869\tvalid_1's rmse: 0.972302\n",
      "[15]\ttraining's rmse: 1.06373\tvalid_1's rmse: 0.969005\n",
      "[16]\ttraining's rmse: 1.05878\tvalid_1's rmse: 0.965695\n",
      "[17]\ttraining's rmse: 1.05473\tvalid_1's rmse: 0.963346\n",
      "[18]\ttraining's rmse: 1.05058\tvalid_1's rmse: 0.960505\n",
      "[19]\ttraining's rmse: 1.04751\tvalid_1's rmse: 0.959487\n",
      "[20]\ttraining's rmse: 1.04441\tvalid_1's rmse: 0.9571\n",
      "[21]\ttraining's rmse: 1.04115\tvalid_1's rmse: 0.955166\n",
      "[22]\ttraining's rmse: 1.03749\tvalid_1's rmse: 0.953122\n",
      "[23]\ttraining's rmse: 1.03494\tvalid_1's rmse: 0.951212\n",
      "[24]\ttraining's rmse: 1.03262\tvalid_1's rmse: 0.949406\n",
      "[25]\ttraining's rmse: 1.03065\tvalid_1's rmse: 0.948634\n",
      "[26]\ttraining's rmse: 1.02859\tvalid_1's rmse: 0.947309\n",
      "[27]\ttraining's rmse: 1.02667\tvalid_1's rmse: 0.945897\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.944913\n",
      "[29]\ttraining's rmse: 1.0212\tvalid_1's rmse: 0.941735\n",
      "[30]\ttraining's rmse: 1.01994\tvalid_1's rmse: 0.941033\n",
      "[31]\ttraining's rmse: 1.01867\tvalid_1's rmse: 0.940681\n",
      "[32]\ttraining's rmse: 1.01765\tvalid_1's rmse: 0.940392\n",
      "[33]\ttraining's rmse: 1.01372\tvalid_1's rmse: 0.937977\n",
      "[34]\ttraining's rmse: 1.0105\tvalid_1's rmse: 0.935672\n",
      "[35]\ttraining's rmse: 1.00808\tvalid_1's rmse: 0.93398\n",
      "[36]\ttraining's rmse: 1.00721\tvalid_1's rmse: 0.933414\n",
      "[37]\ttraining's rmse: 1.00634\tvalid_1's rmse: 0.933313\n",
      "[38]\ttraining's rmse: 1.00521\tvalid_1's rmse: 0.932637\n",
      "[39]\ttraining's rmse: 1.00322\tvalid_1's rmse: 0.931372\n",
      "[40]\ttraining's rmse: 1.00262\tvalid_1's rmse: 0.930943\n",
      "[41]\ttraining's rmse: 1.00206\tvalid_1's rmse: 0.930813\n",
      "[42]\ttraining's rmse: 1.00114\tvalid_1's rmse: 0.930473\n",
      "[43]\ttraining's rmse: 1.00051\tvalid_1's rmse: 0.930372\n",
      "[44]\ttraining's rmse: 0.99989\tvalid_1's rmse: 0.930083\n",
      "[45]\ttraining's rmse: 0.997708\tvalid_1's rmse: 0.928298\n",
      "[46]\ttraining's rmse: 0.997305\tvalid_1's rmse: 0.92824\n",
      "[47]\ttraining's rmse: 0.996677\tvalid_1's rmse: 0.928257\n",
      "[48]\ttraining's rmse: 0.996294\tvalid_1's rmse: 0.927997\n",
      "[49]\ttraining's rmse: 0.994105\tvalid_1's rmse: 0.927027\n",
      "[50]\ttraining's rmse: 0.993283\tvalid_1's rmse: 0.927115\n",
      "[51]\ttraining's rmse: 0.99293\tvalid_1's rmse: 0.926788\n",
      "[52]\ttraining's rmse: 0.992106\tvalid_1's rmse: 0.926521\n",
      "[53]\ttraining's rmse: 0.991179\tvalid_1's rmse: 0.926598\n",
      "[54]\ttraining's rmse: 0.990653\tvalid_1's rmse: 0.92638\n",
      "[55]\ttraining's rmse: 0.990129\tvalid_1's rmse: 0.926249\n",
      "[56]\ttraining's rmse: 0.988921\tvalid_1's rmse: 0.925658\n",
      "[57]\ttraining's rmse: 0.988639\tvalid_1's rmse: 0.92549\n",
      "[58]\ttraining's rmse: 0.988061\tvalid_1's rmse: 0.925629\n",
      "[59]\ttraining's rmse: 0.98745\tvalid_1's rmse: 0.925295\n",
      "[60]\ttraining's rmse: 0.987055\tvalid_1's rmse: 0.925333\n",
      "[61]\ttraining's rmse: 0.986674\tvalid_1's rmse: 0.925314\n",
      "[62]\ttraining's rmse: 0.98617\tvalid_1's rmse: 0.925256\n",
      "[63]\ttraining's rmse: 0.985539\tvalid_1's rmse: 0.925418\n",
      "[64]\ttraining's rmse: 0.985117\tvalid_1's rmse: 0.925665\n",
      "[65]\ttraining's rmse: 0.984256\tvalid_1's rmse: 0.925245\n",
      "[66]\ttraining's rmse: 0.983901\tvalid_1's rmse: 0.925252\n",
      "[67]\ttraining's rmse: 0.983437\tvalid_1's rmse: 0.925381\n",
      "[68]\ttraining's rmse: 0.983075\tvalid_1's rmse: 0.925432\n",
      "[69]\ttraining's rmse: 0.982551\tvalid_1's rmse: 0.924865\n",
      "[70]\ttraining's rmse: 0.982234\tvalid_1's rmse: 0.924589\n",
      "[71]\ttraining's rmse: 0.981963\tvalid_1's rmse: 0.924528\n",
      "[72]\ttraining's rmse: 0.981679\tvalid_1's rmse: 0.924483\n",
      "[73]\ttraining's rmse: 0.981445\tvalid_1's rmse: 0.924427\n",
      "[74]\ttraining's rmse: 0.980985\tvalid_1's rmse: 0.924845\n",
      "[75]\ttraining's rmse: 0.980621\tvalid_1's rmse: 0.924625\n",
      "[76]\ttraining's rmse: 0.980437\tvalid_1's rmse: 0.924615\n",
      "[77]\ttraining's rmse: 0.979679\tvalid_1's rmse: 0.924205\n",
      "[78]\ttraining's rmse: 0.979252\tvalid_1's rmse: 0.924059\n",
      "[79]\ttraining's rmse: 0.97894\tvalid_1's rmse: 0.924066\n",
      "[80]\ttraining's rmse: 0.978642\tvalid_1's rmse: 0.924\n",
      "[81]\ttraining's rmse: 0.978338\tvalid_1's rmse: 0.924312\n",
      "[82]\ttraining's rmse: 0.978056\tvalid_1's rmse: 0.924013\n",
      "[83]\ttraining's rmse: 0.97782\tvalid_1's rmse: 0.92392\n",
      "[84]\ttraining's rmse: 0.977398\tvalid_1's rmse: 0.923709\n",
      "[85]\ttraining's rmse: 0.977237\tvalid_1's rmse: 0.92328\n",
      "[86]\ttraining's rmse: 0.976953\tvalid_1's rmse: 0.923458\n",
      "[87]\ttraining's rmse: 0.976447\tvalid_1's rmse: 0.923175\n",
      "[88]\ttraining's rmse: 0.976198\tvalid_1's rmse: 0.923161\n",
      "[89]\ttraining's rmse: 0.975996\tvalid_1's rmse: 0.923168\n",
      "[90]\ttraining's rmse: 0.975679\tvalid_1's rmse: 0.922899\n",
      "[91]\ttraining's rmse: 0.975223\tvalid_1's rmse: 0.922926\n",
      "[92]\ttraining's rmse: 0.975093\tvalid_1's rmse: 0.922829\n",
      "[93]\ttraining's rmse: 0.974819\tvalid_1's rmse: 0.922651\n",
      "[94]\ttraining's rmse: 0.974614\tvalid_1's rmse: 0.922637\n",
      "[95]\ttraining's rmse: 0.974234\tvalid_1's rmse: 0.922639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttraining's rmse: 0.974006\tvalid_1's rmse: 0.922543\n",
      "[97]\ttraining's rmse: 0.973797\tvalid_1's rmse: 0.922514\n",
      "[98]\ttraining's rmse: 0.9735\tvalid_1's rmse: 0.922398\n",
      "[99]\ttraining's rmse: 0.973279\tvalid_1's rmse: 0.922466\n",
      "[100]\ttraining's rmse: 0.972916\tvalid_1's rmse: 0.922476\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972916\tvalid_1's rmse: 0.922476\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 5, 'reg_alpha': 0.1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 7}\n",
      "model directory : trained_models_dir/lgb\\gs_8\n",
      "[1]\ttraining's rmse: 1.27516\tvalid_1's rmse: 1.09856\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.22606\tvalid_1's rmse: 1.06591\n",
      "[3]\ttraining's rmse: 1.18425\tvalid_1's rmse: 1.03817\n",
      "[4]\ttraining's rmse: 1.14861\tvalid_1's rmse: 1.01586\n",
      "[5]\ttraining's rmse: 1.11782\tvalid_1's rmse: 0.996937\n",
      "[6]\ttraining's rmse: 1.09179\tvalid_1's rmse: 0.980109\n",
      "[7]\ttraining's rmse: 1.07025\tvalid_1's rmse: 0.967861\n",
      "[8]\ttraining's rmse: 1.0506\tvalid_1's rmse: 0.956261\n",
      "[9]\ttraining's rmse: 1.03439\tvalid_1's rmse: 0.947404\n",
      "[10]\ttraining's rmse: 1.02049\tvalid_1's rmse: 0.9396\n",
      "[11]\ttraining's rmse: 1.00858\tvalid_1's rmse: 0.93341\n",
      "[12]\ttraining's rmse: 0.998332\tvalid_1's rmse: 0.928448\n",
      "[13]\ttraining's rmse: 0.988456\tvalid_1's rmse: 0.924917\n",
      "[14]\ttraining's rmse: 0.980721\tvalid_1's rmse: 0.922161\n",
      "[15]\ttraining's rmse: 0.973626\tvalid_1's rmse: 0.918914\n",
      "[16]\ttraining's rmse: 0.967238\tvalid_1's rmse: 0.916423\n",
      "[17]\ttraining's rmse: 0.962264\tvalid_1's rmse: 0.914525\n",
      "[18]\ttraining's rmse: 0.957561\tvalid_1's rmse: 0.912572\n",
      "[19]\ttraining's rmse: 0.953412\tvalid_1's rmse: 0.911192\n",
      "[20]\ttraining's rmse: 0.950003\tvalid_1's rmse: 0.909931\n",
      "[21]\ttraining's rmse: 0.946595\tvalid_1's rmse: 0.908715\n",
      "[22]\ttraining's rmse: 0.943294\tvalid_1's rmse: 0.907555\n",
      "[23]\ttraining's rmse: 0.940566\tvalid_1's rmse: 0.906731\n",
      "[24]\ttraining's rmse: 0.938046\tvalid_1's rmse: 0.906009\n",
      "[25]\ttraining's rmse: 0.93581\tvalid_1's rmse: 0.905112\n",
      "[26]\ttraining's rmse: 0.933538\tvalid_1's rmse: 0.90474\n",
      "[27]\ttraining's rmse: 0.931561\tvalid_1's rmse: 0.904377\n",
      "[28]\ttraining's rmse: 0.929955\tvalid_1's rmse: 0.904213\n",
      "[29]\ttraining's rmse: 0.928052\tvalid_1's rmse: 0.902236\n",
      "[30]\ttraining's rmse: 0.926122\tvalid_1's rmse: 0.901915\n",
      "[31]\ttraining's rmse: 0.92453\tvalid_1's rmse: 0.901571\n",
      "[32]\ttraining's rmse: 0.923262\tvalid_1's rmse: 0.90163\n",
      "[33]\ttraining's rmse: 0.922154\tvalid_1's rmse: 0.901288\n",
      "[34]\ttraining's rmse: 0.920407\tvalid_1's rmse: 0.902289\n",
      "[35]\ttraining's rmse: 0.919276\tvalid_1's rmse: 0.902063\n",
      "[36]\ttraining's rmse: 0.917954\tvalid_1's rmse: 0.90211\n",
      "[37]\ttraining's rmse: 0.91651\tvalid_1's rmse: 0.901629\n",
      "[38]\ttraining's rmse: 0.915618\tvalid_1's rmse: 0.901602\n",
      "[39]\ttraining's rmse: 0.914925\tvalid_1's rmse: 0.901913\n",
      "[40]\ttraining's rmse: 0.914156\tvalid_1's rmse: 0.901742\n",
      "[41]\ttraining's rmse: 0.913034\tvalid_1's rmse: 0.901713\n",
      "[42]\ttraining's rmse: 0.912351\tvalid_1's rmse: 0.901596\n",
      "[43]\ttraining's rmse: 0.911707\tvalid_1's rmse: 0.901856\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.922154\tvalid_1's rmse: 0.901288\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_9\n",
      "[1]\ttraining's rmse: 1.28979\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2536\tvalid_1's rmse: 1.08714\n",
      "[3]\ttraining's rmse: 1.22296\tvalid_1's rmse: 1.06779\n",
      "[4]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.05161\n",
      "[5]\ttraining's rmse: 1.17483\tvalid_1's rmse: 1.03824\n",
      "[6]\ttraining's rmse: 1.15539\tvalid_1's rmse: 1.02585\n",
      "[7]\ttraining's rmse: 1.13955\tvalid_1's rmse: 1.0163\n",
      "[8]\ttraining's rmse: 1.12562\tvalid_1's rmse: 1.00746\n",
      "[9]\ttraining's rmse: 1.11408\tvalid_1's rmse: 1.00096\n",
      "[10]\ttraining's rmse: 1.10376\tvalid_1's rmse: 0.995226\n",
      "[11]\ttraining's rmse: 1.09542\tvalid_1's rmse: 0.990395\n",
      "[12]\ttraining's rmse: 1.08511\tvalid_1's rmse: 0.983343\n",
      "[13]\ttraining's rmse: 1.07432\tvalid_1's rmse: 0.975201\n",
      "[14]\ttraining's rmse: 1.06866\tvalid_1's rmse: 0.972286\n",
      "[15]\ttraining's rmse: 1.0637\tvalid_1's rmse: 0.968991\n",
      "[16]\ttraining's rmse: 1.05876\tvalid_1's rmse: 0.965681\n",
      "[17]\ttraining's rmse: 1.05471\tvalid_1's rmse: 0.963333\n",
      "[18]\ttraining's rmse: 1.05056\tvalid_1's rmse: 0.960493\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959476\n",
      "[20]\ttraining's rmse: 1.04439\tvalid_1's rmse: 0.95709\n",
      "[21]\ttraining's rmse: 1.04114\tvalid_1's rmse: 0.955156\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953113\n",
      "[23]\ttraining's rmse: 1.03492\tvalid_1's rmse: 0.951204\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949399\n",
      "[25]\ttraining's rmse: 1.03063\tvalid_1's rmse: 0.948626\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947303\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945891\n",
      "[28]\ttraining's rmse: 1.02488\tvalid_1's rmse: 0.944907\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.941729\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.941028\n",
      "[31]\ttraining's rmse: 1.01866\tvalid_1's rmse: 0.940675\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940386\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937971\n",
      "[34]\ttraining's rmse: 1.01048\tvalid_1's rmse: 0.935667\n",
      "[35]\ttraining's rmse: 1.00806\tvalid_1's rmse: 0.933975\n",
      "[36]\ttraining's rmse: 1.00719\tvalid_1's rmse: 0.933409\n",
      "[37]\ttraining's rmse: 1.00631\tvalid_1's rmse: 0.933309\n",
      "[38]\ttraining's rmse: 1.00519\tvalid_1's rmse: 0.932635\n",
      "[39]\ttraining's rmse: 1.00319\tvalid_1's rmse: 0.93137\n",
      "[40]\ttraining's rmse: 1.00244\tvalid_1's rmse: 0.931081\n",
      "[41]\ttraining's rmse: 1.00187\tvalid_1's rmse: 0.930934\n",
      "[42]\ttraining's rmse: 1.00141\tvalid_1's rmse: 0.930771\n",
      "[43]\ttraining's rmse: 0.999171\tvalid_1's rmse: 0.928971\n",
      "[44]\ttraining's rmse: 0.998487\tvalid_1's rmse: 0.928968\n",
      "[45]\ttraining's rmse: 0.997752\tvalid_1's rmse: 0.928877\n",
      "[46]\ttraining's rmse: 0.997342\tvalid_1's rmse: 0.928663\n",
      "[47]\ttraining's rmse: 0.996915\tvalid_1's rmse: 0.928582\n",
      "[48]\ttraining's rmse: 0.996094\tvalid_1's rmse: 0.928159\n",
      "[49]\ttraining's rmse: 0.995543\tvalid_1's rmse: 0.927992\n",
      "[50]\ttraining's rmse: 0.994514\tvalid_1's rmse: 0.927969\n",
      "[51]\ttraining's rmse: 0.993931\tvalid_1's rmse: 0.927363\n",
      "[52]\ttraining's rmse: 0.992287\tvalid_1's rmse: 0.92626\n",
      "[53]\ttraining's rmse: 0.991591\tvalid_1's rmse: 0.92608\n",
      "[54]\ttraining's rmse: 0.989976\tvalid_1's rmse: 0.925467\n",
      "[55]\ttraining's rmse: 0.989286\tvalid_1's rmse: 0.924848\n",
      "[56]\ttraining's rmse: 0.988807\tvalid_1's rmse: 0.925257\n",
      "[57]\ttraining's rmse: 0.98828\tvalid_1's rmse: 0.925475\n",
      "[58]\ttraining's rmse: 0.987743\tvalid_1's rmse: 0.925459\n",
      "[59]\ttraining's rmse: 0.987428\tvalid_1's rmse: 0.925365\n",
      "[60]\ttraining's rmse: 0.987128\tvalid_1's rmse: 0.925349\n",
      "[61]\ttraining's rmse: 0.986548\tvalid_1's rmse: 0.925123\n",
      "[62]\ttraining's rmse: 0.986058\tvalid_1's rmse: 0.924911\n",
      "[63]\ttraining's rmse: 0.985572\tvalid_1's rmse: 0.924861\n",
      "[64]\ttraining's rmse: 0.984665\tvalid_1's rmse: 0.924535\n",
      "[65]\ttraining's rmse: 0.984228\tvalid_1's rmse: 0.924426\n",
      "[66]\ttraining's rmse: 0.983828\tvalid_1's rmse: 0.924184\n",
      "[67]\ttraining's rmse: 0.983501\tvalid_1's rmse: 0.923878\n",
      "[68]\ttraining's rmse: 0.983294\tvalid_1's rmse: 0.923757\n",
      "[69]\ttraining's rmse: 0.983019\tvalid_1's rmse: 0.923676\n",
      "[70]\ttraining's rmse: 0.982598\tvalid_1's rmse: 0.923629\n",
      "[71]\ttraining's rmse: 0.982356\tvalid_1's rmse: 0.923638\n",
      "[72]\ttraining's rmse: 0.981478\tvalid_1's rmse: 0.923408\n",
      "[73]\ttraining's rmse: 0.98123\tvalid_1's rmse: 0.923204\n",
      "[74]\ttraining's rmse: 0.980717\tvalid_1's rmse: 0.922666\n",
      "[75]\ttraining's rmse: 0.980444\tvalid_1's rmse: 0.922771\n",
      "[76]\ttraining's rmse: 0.980123\tvalid_1's rmse: 0.922497\n",
      "[77]\ttraining's rmse: 0.979728\tvalid_1's rmse: 0.922357\n",
      "[78]\ttraining's rmse: 0.97951\tvalid_1's rmse: 0.921968\n",
      "[79]\ttraining's rmse: 0.979243\tvalid_1's rmse: 0.92192\n",
      "[80]\ttraining's rmse: 0.978396\tvalid_1's rmse: 0.921714\n",
      "[81]\ttraining's rmse: 0.978096\tvalid_1's rmse: 0.921844\n",
      "[82]\ttraining's rmse: 0.977328\tvalid_1's rmse: 0.921662\n",
      "[83]\ttraining's rmse: 0.977088\tvalid_1's rmse: 0.921533\n",
      "[84]\ttraining's rmse: 0.976753\tvalid_1's rmse: 0.921447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttraining's rmse: 0.976524\tvalid_1's rmse: 0.921383\n",
      "[86]\ttraining's rmse: 0.976327\tvalid_1's rmse: 0.921241\n",
      "[87]\ttraining's rmse: 0.975943\tvalid_1's rmse: 0.920781\n",
      "[88]\ttraining's rmse: 0.975327\tvalid_1's rmse: 0.920586\n",
      "[89]\ttraining's rmse: 0.975013\tvalid_1's rmse: 0.920767\n",
      "[90]\ttraining's rmse: 0.974799\tvalid_1's rmse: 0.920746\n",
      "[91]\ttraining's rmse: 0.974527\tvalid_1's rmse: 0.920619\n",
      "[92]\ttraining's rmse: 0.974154\tvalid_1's rmse: 0.920591\n",
      "[93]\ttraining's rmse: 0.973858\tvalid_1's rmse: 0.920683\n",
      "[94]\ttraining's rmse: 0.973724\tvalid_1's rmse: 0.920582\n",
      "[95]\ttraining's rmse: 0.973511\tvalid_1's rmse: 0.920619\n",
      "[96]\ttraining's rmse: 0.973308\tvalid_1's rmse: 0.920567\n",
      "[97]\ttraining's rmse: 0.973079\tvalid_1's rmse: 0.920476\n",
      "[98]\ttraining's rmse: 0.972721\tvalid_1's rmse: 0.920364\n",
      "[99]\ttraining's rmse: 0.972527\tvalid_1's rmse: 0.920363\n",
      "[100]\ttraining's rmse: 0.972263\tvalid_1's rmse: 0.920245\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972263\tvalid_1's rmse: 0.920245\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha': 1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_10\n",
      "[1]\ttraining's rmse: 1.2898\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.25361\tvalid_1's rmse: 1.08715\n",
      "[3]\ttraining's rmse: 1.22297\tvalid_1's rmse: 1.0678\n",
      "[4]\ttraining's rmse: 1.19695\tvalid_1's rmse: 1.05162\n",
      "[5]\ttraining's rmse: 1.17485\tvalid_1's rmse: 1.03825\n",
      "[6]\ttraining's rmse: 1.15542\tvalid_1's rmse: 1.02586\n",
      "[7]\ttraining's rmse: 1.13957\tvalid_1's rmse: 1.01631\n",
      "[8]\ttraining's rmse: 1.12564\tvalid_1's rmse: 1.00747\n",
      "[9]\ttraining's rmse: 1.1141\tvalid_1's rmse: 1.00097\n",
      "[10]\ttraining's rmse: 1.10377\tvalid_1's rmse: 0.995238\n",
      "[11]\ttraining's rmse: 1.09543\tvalid_1's rmse: 0.990407\n",
      "[12]\ttraining's rmse: 1.08513\tvalid_1's rmse: 0.983353\n",
      "[13]\ttraining's rmse: 1.07433\tvalid_1's rmse: 0.975211\n",
      "[14]\ttraining's rmse: 1.06868\tvalid_1's rmse: 0.972295\n",
      "[15]\ttraining's rmse: 1.06372\tvalid_1's rmse: 0.968999\n",
      "[16]\ttraining's rmse: 1.05877\tvalid_1's rmse: 0.965689\n",
      "[17]\ttraining's rmse: 1.05472\tvalid_1's rmse: 0.96334\n",
      "[18]\ttraining's rmse: 1.05057\tvalid_1's rmse: 0.9605\n",
      "[19]\ttraining's rmse: 1.04751\tvalid_1's rmse: 0.959483\n",
      "[20]\ttraining's rmse: 1.0444\tvalid_1's rmse: 0.957096\n",
      "[21]\ttraining's rmse: 1.04115\tvalid_1's rmse: 0.955161\n",
      "[22]\ttraining's rmse: 1.03749\tvalid_1's rmse: 0.953118\n",
      "[23]\ttraining's rmse: 1.03493\tvalid_1's rmse: 0.951209\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949403\n",
      "[25]\ttraining's rmse: 1.03064\tvalid_1's rmse: 0.948631\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947307\n",
      "[27]\ttraining's rmse: 1.02667\tvalid_1's rmse: 0.945895\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.944911\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.941733\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.941031\n",
      "[31]\ttraining's rmse: 1.01867\tvalid_1's rmse: 0.940679\n",
      "[32]\ttraining's rmse: 1.01765\tvalid_1's rmse: 0.940389\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937975\n",
      "[34]\ttraining's rmse: 1.01049\tvalid_1's rmse: 0.935671\n",
      "[35]\ttraining's rmse: 1.00807\tvalid_1's rmse: 0.933978\n",
      "[36]\ttraining's rmse: 1.0072\tvalid_1's rmse: 0.933412\n",
      "[37]\ttraining's rmse: 1.00633\tvalid_1's rmse: 0.933312\n",
      "[38]\ttraining's rmse: 1.0052\tvalid_1's rmse: 0.932636\n",
      "[39]\ttraining's rmse: 1.00321\tvalid_1's rmse: 0.931371\n",
      "[40]\ttraining's rmse: 1.00261\tvalid_1's rmse: 0.930942\n",
      "[41]\ttraining's rmse: 1.00205\tvalid_1's rmse: 0.93076\n",
      "[42]\ttraining's rmse: 1.00113\tvalid_1's rmse: 0.930424\n",
      "[43]\ttraining's rmse: 1.00057\tvalid_1's rmse: 0.930197\n",
      "[44]\ttraining's rmse: 0.998362\tvalid_1's rmse: 0.928403\n",
      "[45]\ttraining's rmse: 0.997695\tvalid_1's rmse: 0.928411\n",
      "[46]\ttraining's rmse: 0.997222\tvalid_1's rmse: 0.928318\n",
      "[47]\ttraining's rmse: 0.996826\tvalid_1's rmse: 0.928049\n",
      "[48]\ttraining's rmse: 0.99566\tvalid_1's rmse: 0.928003\n",
      "[49]\ttraining's rmse: 0.995138\tvalid_1's rmse: 0.928053\n",
      "[50]\ttraining's rmse: 0.994168\tvalid_1's rmse: 0.928115\n",
      "[51]\ttraining's rmse: 0.993761\tvalid_1's rmse: 0.927983\n",
      "[52]\ttraining's rmse: 0.992857\tvalid_1's rmse: 0.927687\n",
      "[53]\ttraining's rmse: 0.991402\tvalid_1's rmse: 0.926862\n",
      "[54]\ttraining's rmse: 0.990961\tvalid_1's rmse: 0.926566\n",
      "[55]\ttraining's rmse: 0.990549\tvalid_1's rmse: 0.926459\n",
      "[56]\ttraining's rmse: 0.989693\tvalid_1's rmse: 0.926237\n",
      "[57]\ttraining's rmse: 0.989126\tvalid_1's rmse: 0.926261\n",
      "[58]\ttraining's rmse: 0.988118\tvalid_1's rmse: 0.925802\n",
      "[59]\ttraining's rmse: 0.987831\tvalid_1's rmse: 0.925813\n",
      "[60]\ttraining's rmse: 0.987382\tvalid_1's rmse: 0.926189\n",
      "[61]\ttraining's rmse: 0.986781\tvalid_1's rmse: 0.92634\n",
      "[62]\ttraining's rmse: 0.986385\tvalid_1's rmse: 0.926375\n",
      "[63]\ttraining's rmse: 0.986065\tvalid_1's rmse: 0.926005\n",
      "[64]\ttraining's rmse: 0.985601\tvalid_1's rmse: 0.92598\n",
      "[65]\ttraining's rmse: 0.985223\tvalid_1's rmse: 0.926007\n",
      "[66]\ttraining's rmse: 0.984665\tvalid_1's rmse: 0.925432\n",
      "[67]\ttraining's rmse: 0.984263\tvalid_1's rmse: 0.925466\n",
      "[68]\ttraining's rmse: 0.983996\tvalid_1's rmse: 0.925212\n",
      "[69]\ttraining's rmse: 0.983618\tvalid_1's rmse: 0.925049\n",
      "[70]\ttraining's rmse: 0.982672\tvalid_1's rmse: 0.924791\n",
      "[71]\ttraining's rmse: 0.982323\tvalid_1's rmse: 0.924737\n",
      "[72]\ttraining's rmse: 0.982031\tvalid_1's rmse: 0.924618\n",
      "[73]\ttraining's rmse: 0.9818\tvalid_1's rmse: 0.924608\n",
      "[74]\ttraining's rmse: 0.98141\tvalid_1's rmse: 0.924485\n",
      "[75]\ttraining's rmse: 0.981137\tvalid_1's rmse: 0.924425\n",
      "[76]\ttraining's rmse: 0.980757\tvalid_1's rmse: 0.924705\n",
      "[77]\ttraining's rmse: 0.980573\tvalid_1's rmse: 0.924592\n",
      "[78]\ttraining's rmse: 0.9804\tvalid_1's rmse: 0.924074\n",
      "[79]\ttraining's rmse: 0.979979\tvalid_1's rmse: 0.924211\n",
      "[80]\ttraining's rmse: 0.979485\tvalid_1's rmse: 0.92378\n",
      "[81]\ttraining's rmse: 0.979115\tvalid_1's rmse: 0.923806\n",
      "[82]\ttraining's rmse: 0.978727\tvalid_1's rmse: 0.923923\n",
      "[83]\ttraining's rmse: 0.978272\tvalid_1's rmse: 0.923984\n",
      "[84]\ttraining's rmse: 0.978028\tvalid_1's rmse: 0.924035\n",
      "[85]\ttraining's rmse: 0.977816\tvalid_1's rmse: 0.923952\n",
      "[86]\ttraining's rmse: 0.977543\tvalid_1's rmse: 0.924081\n",
      "[87]\ttraining's rmse: 0.977398\tvalid_1's rmse: 0.923941\n",
      "[88]\ttraining's rmse: 0.977141\tvalid_1's rmse: 0.923931\n",
      "[89]\ttraining's rmse: 0.976656\tvalid_1's rmse: 0.9239\n",
      "[90]\ttraining's rmse: 0.976322\tvalid_1's rmse: 0.923798\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's rmse: 0.979485\tvalid_1's rmse: 0.92378\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': None, 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_11\n",
      "[1]\ttraining's rmse: 1.27974\tvalid_1's rmse: 1.10093\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.23495\tvalid_1's rmse: 1.0707\n",
      "[3]\ttraining's rmse: 1.19701\tvalid_1's rmse: 1.04462\n",
      "[4]\ttraining's rmse: 1.1649\tvalid_1's rmse: 1.02367\n",
      "[5]\ttraining's rmse: 1.13792\tvalid_1's rmse: 1.0064\n",
      "[6]\ttraining's rmse: 1.11394\tvalid_1's rmse: 0.990642\n",
      "[7]\ttraining's rmse: 1.09356\tvalid_1's rmse: 0.977131\n",
      "[8]\ttraining's rmse: 1.07679\tvalid_1's rmse: 0.967491\n",
      "[9]\ttraining's rmse: 1.06206\tvalid_1's rmse: 0.958206\n",
      "[10]\ttraining's rmse: 1.05009\tvalid_1's rmse: 0.951086\n",
      "[11]\ttraining's rmse: 1.03904\tvalid_1's rmse: 0.944919\n",
      "[12]\ttraining's rmse: 1.02977\tvalid_1's rmse: 0.939908\n",
      "[13]\ttraining's rmse: 1.02139\tvalid_1's rmse: 0.935867\n",
      "[14]\ttraining's rmse: 1.01488\tvalid_1's rmse: 0.933013\n",
      "[15]\ttraining's rmse: 1.00905\tvalid_1's rmse: 0.930338\n",
      "[16]\ttraining's rmse: 1.00354\tvalid_1's rmse: 0.927848\n",
      "[17]\ttraining's rmse: 0.999053\tvalid_1's rmse: 0.926073\n",
      "[18]\ttraining's rmse: 0.995019\tvalid_1's rmse: 0.924372\n",
      "[19]\ttraining's rmse: 0.990822\tvalid_1's rmse: 0.922962\n",
      "[20]\ttraining's rmse: 0.98711\tvalid_1's rmse: 0.921465\n",
      "[21]\ttraining's rmse: 0.983551\tvalid_1's rmse: 0.92033\n",
      "[22]\ttraining's rmse: 0.980282\tvalid_1's rmse: 0.919141\n",
      "[23]\ttraining's rmse: 0.97765\tvalid_1's rmse: 0.918123\n",
      "[24]\ttraining's rmse: 0.975755\tvalid_1's rmse: 0.917775\n",
      "[25]\ttraining's rmse: 0.973214\tvalid_1's rmse: 0.916619\n",
      "[26]\ttraining's rmse: 0.971076\tvalid_1's rmse: 0.915849\n",
      "[27]\ttraining's rmse: 0.969113\tvalid_1's rmse: 0.91544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttraining's rmse: 0.967351\tvalid_1's rmse: 0.915606\n",
      "[29]\ttraining's rmse: 0.965808\tvalid_1's rmse: 0.915119\n",
      "[30]\ttraining's rmse: 0.964663\tvalid_1's rmse: 0.915051\n",
      "[31]\ttraining's rmse: 0.963221\tvalid_1's rmse: 0.91445\n",
      "[32]\ttraining's rmse: 0.962139\tvalid_1's rmse: 0.914089\n",
      "[33]\ttraining's rmse: 0.96093\tvalid_1's rmse: 0.913661\n",
      "[34]\ttraining's rmse: 0.959781\tvalid_1's rmse: 0.913261\n",
      "[35]\ttraining's rmse: 0.958681\tvalid_1's rmse: 0.913067\n",
      "[36]\ttraining's rmse: 0.957815\tvalid_1's rmse: 0.913149\n",
      "[37]\ttraining's rmse: 0.956994\tvalid_1's rmse: 0.912819\n",
      "[38]\ttraining's rmse: 0.956336\tvalid_1's rmse: 0.912588\n",
      "[39]\ttraining's rmse: 0.955155\tvalid_1's rmse: 0.912194\n",
      "[40]\ttraining's rmse: 0.954055\tvalid_1's rmse: 0.911838\n",
      "[41]\ttraining's rmse: 0.953127\tvalid_1's rmse: 0.911661\n",
      "[42]\ttraining's rmse: 0.952266\tvalid_1's rmse: 0.911539\n",
      "[43]\ttraining's rmse: 0.951648\tvalid_1's rmse: 0.911223\n",
      "[44]\ttraining's rmse: 0.950953\tvalid_1's rmse: 0.911796\n",
      "[45]\ttraining's rmse: 0.950205\tvalid_1's rmse: 0.911479\n",
      "[46]\ttraining's rmse: 0.949281\tvalid_1's rmse: 0.91141\n",
      "[47]\ttraining's rmse: 0.948151\tvalid_1's rmse: 0.911394\n",
      "[48]\ttraining's rmse: 0.947564\tvalid_1's rmse: 0.911665\n",
      "[49]\ttraining's rmse: 0.947122\tvalid_1's rmse: 0.911389\n",
      "[50]\ttraining's rmse: 0.946567\tvalid_1's rmse: 0.911337\n",
      "[51]\ttraining's rmse: 0.945723\tvalid_1's rmse: 0.910975\n",
      "[52]\ttraining's rmse: 0.945131\tvalid_1's rmse: 0.910587\n",
      "[53]\ttraining's rmse: 0.944288\tvalid_1's rmse: 0.91025\n",
      "[54]\ttraining's rmse: 0.943698\tvalid_1's rmse: 0.910085\n",
      "[55]\ttraining's rmse: 0.94331\tvalid_1's rmse: 0.910199\n",
      "[56]\ttraining's rmse: 0.94264\tvalid_1's rmse: 0.910422\n",
      "[57]\ttraining's rmse: 0.941818\tvalid_1's rmse: 0.910423\n",
      "[58]\ttraining's rmse: 0.941107\tvalid_1's rmse: 0.91021\n",
      "[59]\ttraining's rmse: 0.940494\tvalid_1's rmse: 0.909932\n",
      "[60]\ttraining's rmse: 0.939886\tvalid_1's rmse: 0.910599\n",
      "[61]\ttraining's rmse: 0.939275\tvalid_1's rmse: 0.910291\n",
      "[62]\ttraining's rmse: 0.938825\tvalid_1's rmse: 0.910225\n",
      "[63]\ttraining's rmse: 0.938259\tvalid_1's rmse: 0.909707\n",
      "[64]\ttraining's rmse: 0.93804\tvalid_1's rmse: 0.909645\n",
      "[65]\ttraining's rmse: 0.937286\tvalid_1's rmse: 0.909389\n",
      "[66]\ttraining's rmse: 0.936779\tvalid_1's rmse: 0.909458\n",
      "[67]\ttraining's rmse: 0.936397\tvalid_1's rmse: 0.909652\n",
      "[68]\ttraining's rmse: 0.936085\tvalid_1's rmse: 0.909516\n",
      "[69]\ttraining's rmse: 0.93536\tvalid_1's rmse: 0.909273\n",
      "[70]\ttraining's rmse: 0.934794\tvalid_1's rmse: 0.907764\n",
      "[71]\ttraining's rmse: 0.934446\tvalid_1's rmse: 0.907633\n",
      "[72]\ttraining's rmse: 0.933944\tvalid_1's rmse: 0.907379\n",
      "[73]\ttraining's rmse: 0.933397\tvalid_1's rmse: 0.906388\n",
      "[74]\ttraining's rmse: 0.933033\tvalid_1's rmse: 0.906477\n",
      "[75]\ttraining's rmse: 0.93255\tvalid_1's rmse: 0.906478\n",
      "[76]\ttraining's rmse: 0.932126\tvalid_1's rmse: 0.907078\n",
      "[77]\ttraining's rmse: 0.931798\tvalid_1's rmse: 0.907004\n",
      "[78]\ttraining's rmse: 0.93121\tvalid_1's rmse: 0.906744\n",
      "[79]\ttraining's rmse: 0.930886\tvalid_1's rmse: 0.906767\n",
      "[80]\ttraining's rmse: 0.930641\tvalid_1's rmse: 0.906759\n",
      "[81]\ttraining's rmse: 0.930375\tvalid_1's rmse: 0.906781\n",
      "[82]\ttraining's rmse: 0.930034\tvalid_1's rmse: 0.906708\n",
      "[83]\ttraining's rmse: 0.929436\tvalid_1's rmse: 0.906585\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's rmse: 0.933397\tvalid_1's rmse: 0.906388\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha': 0.1, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 7}\n",
      "model directory : trained_models_dir/lgb\\gs_12\n",
      "[1]\ttraining's rmse: 1.27472\tvalid_1's rmse: 1.09821\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.22533\tvalid_1's rmse: 1.06495\n",
      "[3]\ttraining's rmse: 1.18326\tvalid_1's rmse: 1.03753\n",
      "[4]\ttraining's rmse: 1.14742\tvalid_1's rmse: 1.01464\n",
      "[5]\ttraining's rmse: 1.11647\tvalid_1's rmse: 0.996529\n",
      "[6]\ttraining's rmse: 1.09029\tvalid_1's rmse: 0.979231\n",
      "[7]\ttraining's rmse: 1.06843\tvalid_1's rmse: 0.966549\n",
      "[8]\ttraining's rmse: 1.04966\tvalid_1's rmse: 0.9564\n",
      "[9]\ttraining's rmse: 1.03374\tvalid_1's rmse: 0.947823\n",
      "[10]\ttraining's rmse: 1.02032\tvalid_1's rmse: 0.940634\n",
      "[11]\ttraining's rmse: 1.0084\tvalid_1's rmse: 0.93425\n",
      "[12]\ttraining's rmse: 0.997733\tvalid_1's rmse: 0.92996\n",
      "[13]\ttraining's rmse: 0.988792\tvalid_1's rmse: 0.925817\n",
      "[14]\ttraining's rmse: 0.980975\tvalid_1's rmse: 0.922367\n",
      "[15]\ttraining's rmse: 0.974283\tvalid_1's rmse: 0.919464\n",
      "[16]\ttraining's rmse: 0.967803\tvalid_1's rmse: 0.916619\n",
      "[17]\ttraining's rmse: 0.962753\tvalid_1's rmse: 0.914122\n",
      "[18]\ttraining's rmse: 0.958475\tvalid_1's rmse: 0.912758\n",
      "[19]\ttraining's rmse: 0.954244\tvalid_1's rmse: 0.910782\n",
      "[20]\ttraining's rmse: 0.950785\tvalid_1's rmse: 0.909567\n",
      "[21]\ttraining's rmse: 0.947381\tvalid_1's rmse: 0.908824\n",
      "[22]\ttraining's rmse: 0.943811\tvalid_1's rmse: 0.907902\n",
      "[23]\ttraining's rmse: 0.940967\tvalid_1's rmse: 0.907367\n",
      "[24]\ttraining's rmse: 0.938455\tvalid_1's rmse: 0.906709\n",
      "[25]\ttraining's rmse: 0.935971\tvalid_1's rmse: 0.906035\n",
      "[26]\ttraining's rmse: 0.933693\tvalid_1's rmse: 0.905781\n",
      "[27]\ttraining's rmse: 0.931365\tvalid_1's rmse: 0.905166\n",
      "[28]\ttraining's rmse: 0.929372\tvalid_1's rmse: 0.905082\n",
      "[29]\ttraining's rmse: 0.927599\tvalid_1's rmse: 0.903961\n",
      "[30]\ttraining's rmse: 0.925876\tvalid_1's rmse: 0.903847\n",
      "[31]\ttraining's rmse: 0.924202\tvalid_1's rmse: 0.904754\n",
      "[32]\ttraining's rmse: 0.922686\tvalid_1's rmse: 0.904365\n",
      "[33]\ttraining's rmse: 0.92122\tvalid_1's rmse: 0.90304\n",
      "[34]\ttraining's rmse: 0.920157\tvalid_1's rmse: 0.902652\n",
      "[35]\ttraining's rmse: 0.91863\tvalid_1's rmse: 0.902553\n",
      "[36]\ttraining's rmse: 0.917032\tvalid_1's rmse: 0.902851\n",
      "[37]\ttraining's rmse: 0.915832\tvalid_1's rmse: 0.902665\n",
      "[38]\ttraining's rmse: 0.914987\tvalid_1's rmse: 0.90266\n",
      "[39]\ttraining's rmse: 0.914023\tvalid_1's rmse: 0.902384\n",
      "[40]\ttraining's rmse: 0.913278\tvalid_1's rmse: 0.90226\n",
      "[41]\ttraining's rmse: 0.912266\tvalid_1's rmse: 0.902645\n",
      "[42]\ttraining's rmse: 0.911447\tvalid_1's rmse: 0.90277\n",
      "[43]\ttraining's rmse: 0.910383\tvalid_1's rmse: 0.903079\n",
      "[44]\ttraining's rmse: 0.909416\tvalid_1's rmse: 0.90267\n",
      "[45]\ttraining's rmse: 0.90875\tvalid_1's rmse: 0.902509\n",
      "[46]\ttraining's rmse: 0.90789\tvalid_1's rmse: 0.902892\n",
      "[47]\ttraining's rmse: 0.907211\tvalid_1's rmse: 0.902951\n",
      "[48]\ttraining's rmse: 0.906599\tvalid_1's rmse: 0.902967\n",
      "[49]\ttraining's rmse: 0.905894\tvalid_1's rmse: 0.903386\n",
      "[50]\ttraining's rmse: 0.905286\tvalid_1's rmse: 0.903231\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's rmse: 0.913278\tvalid_1's rmse: 0.90226\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.7, 'reg_lambda': 0, 'reg_alpha': 2, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 7}\n",
      "model directory : trained_models_dir/lgb\\gs_13\n",
      "[1]\ttraining's rmse: 1.27474\tvalid_1's rmse: 1.09826\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.22537\tvalid_1's rmse: 1.065\n",
      "[3]\ttraining's rmse: 1.18331\tvalid_1's rmse: 1.03757\n",
      "[4]\ttraining's rmse: 1.14747\tvalid_1's rmse: 1.01458\n",
      "[5]\ttraining's rmse: 1.11654\tvalid_1's rmse: 0.996479\n",
      "[6]\ttraining's rmse: 1.09045\tvalid_1's rmse: 0.979136\n",
      "[7]\ttraining's rmse: 1.06877\tvalid_1's rmse: 0.966313\n",
      "[8]\ttraining's rmse: 1.04903\tvalid_1's rmse: 0.954908\n",
      "[9]\ttraining's rmse: 1.03281\tvalid_1's rmse: 0.94685\n",
      "[10]\ttraining's rmse: 1.01882\tvalid_1's rmse: 0.938834\n",
      "[11]\ttraining's rmse: 1.00692\tvalid_1's rmse: 0.932966\n",
      "[12]\ttraining's rmse: 0.996491\tvalid_1's rmse: 0.928388\n",
      "[13]\ttraining's rmse: 0.987474\tvalid_1's rmse: 0.924757\n",
      "[14]\ttraining's rmse: 0.979736\tvalid_1's rmse: 0.921776\n",
      "[15]\ttraining's rmse: 0.972758\tvalid_1's rmse: 0.918999\n",
      "[16]\ttraining's rmse: 0.966702\tvalid_1's rmse: 0.916785\n",
      "[17]\ttraining's rmse: 0.961493\tvalid_1's rmse: 0.9146\n",
      "[18]\ttraining's rmse: 0.956904\tvalid_1's rmse: 0.913519\n",
      "[19]\ttraining's rmse: 0.952559\tvalid_1's rmse: 0.911835\n",
      "[20]\ttraining's rmse: 0.948812\tvalid_1's rmse: 0.910332\n",
      "[21]\ttraining's rmse: 0.945414\tvalid_1's rmse: 0.909277\n",
      "[22]\ttraining's rmse: 0.942538\tvalid_1's rmse: 0.908521\n",
      "[23]\ttraining's rmse: 0.939735\tvalid_1's rmse: 0.907479\n",
      "[24]\ttraining's rmse: 0.937212\tvalid_1's rmse: 0.906653\n",
      "[25]\ttraining's rmse: 0.934982\tvalid_1's rmse: 0.906073\n",
      "[26]\ttraining's rmse: 0.932634\tvalid_1's rmse: 0.90596\n",
      "[27]\ttraining's rmse: 0.930543\tvalid_1's rmse: 0.904116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttraining's rmse: 0.928758\tvalid_1's rmse: 0.903284\n",
      "[29]\ttraining's rmse: 0.926645\tvalid_1's rmse: 0.902927\n",
      "[30]\ttraining's rmse: 0.924951\tvalid_1's rmse: 0.903682\n",
      "[31]\ttraining's rmse: 0.923143\tvalid_1's rmse: 0.902644\n",
      "[32]\ttraining's rmse: 0.92126\tvalid_1's rmse: 0.903033\n",
      "[33]\ttraining's rmse: 0.920194\tvalid_1's rmse: 0.902948\n",
      "[34]\ttraining's rmse: 0.918543\tvalid_1's rmse: 0.902208\n",
      "[35]\ttraining's rmse: 0.917635\tvalid_1's rmse: 0.902001\n",
      "[36]\ttraining's rmse: 0.916438\tvalid_1's rmse: 0.901773\n",
      "[37]\ttraining's rmse: 0.915523\tvalid_1's rmse: 0.901814\n",
      "[38]\ttraining's rmse: 0.914503\tvalid_1's rmse: 0.901732\n",
      "[39]\ttraining's rmse: 0.91328\tvalid_1's rmse: 0.901498\n",
      "[40]\ttraining's rmse: 0.911997\tvalid_1's rmse: 0.901718\n",
      "[41]\ttraining's rmse: 0.911317\tvalid_1's rmse: 0.901632\n",
      "[42]\ttraining's rmse: 0.910156\tvalid_1's rmse: 0.902193\n",
      "[43]\ttraining's rmse: 0.909557\tvalid_1's rmse: 0.902129\n",
      "[44]\ttraining's rmse: 0.908464\tvalid_1's rmse: 0.902444\n",
      "[45]\ttraining's rmse: 0.907918\tvalid_1's rmse: 0.902348\n",
      "[46]\ttraining's rmse: 0.907034\tvalid_1's rmse: 0.902699\n",
      "[47]\ttraining's rmse: 0.906086\tvalid_1's rmse: 0.902524\n",
      "[48]\ttraining's rmse: 0.905408\tvalid_1's rmse: 0.902602\n",
      "[49]\ttraining's rmse: 0.904938\tvalid_1's rmse: 0.902378\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 0.91328\tvalid_1's rmse: 0.901498\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 2, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_14\n",
      "[1]\ttraining's rmse: 1.28979\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2536\tvalid_1's rmse: 1.08714\n",
      "[3]\ttraining's rmse: 1.22296\tvalid_1's rmse: 1.06779\n",
      "[4]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.05161\n",
      "[5]\ttraining's rmse: 1.17483\tvalid_1's rmse: 1.03824\n",
      "[6]\ttraining's rmse: 1.1554\tvalid_1's rmse: 1.02585\n",
      "[7]\ttraining's rmse: 1.13955\tvalid_1's rmse: 1.0163\n",
      "[8]\ttraining's rmse: 1.12562\tvalid_1's rmse: 1.00746\n",
      "[9]\ttraining's rmse: 1.11409\tvalid_1's rmse: 1.00096\n",
      "[10]\ttraining's rmse: 1.10376\tvalid_1's rmse: 0.995229\n",
      "[11]\ttraining's rmse: 1.09542\tvalid_1's rmse: 0.990398\n",
      "[12]\ttraining's rmse: 1.08512\tvalid_1's rmse: 0.983345\n",
      "[13]\ttraining's rmse: 1.07432\tvalid_1's rmse: 0.975204\n",
      "[14]\ttraining's rmse: 1.06867\tvalid_1's rmse: 0.972289\n",
      "[15]\ttraining's rmse: 1.06371\tvalid_1's rmse: 0.968993\n",
      "[16]\ttraining's rmse: 1.05876\tvalid_1's rmse: 0.965684\n",
      "[17]\ttraining's rmse: 1.05471\tvalid_1's rmse: 0.963336\n",
      "[18]\ttraining's rmse: 1.05056\tvalid_1's rmse: 0.960496\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959479\n",
      "[20]\ttraining's rmse: 1.0444\tvalid_1's rmse: 0.957092\n",
      "[21]\ttraining's rmse: 1.04114\tvalid_1's rmse: 0.955158\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953115\n",
      "[23]\ttraining's rmse: 1.03493\tvalid_1's rmse: 0.951206\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949401\n",
      "[25]\ttraining's rmse: 1.03064\tvalid_1's rmse: 0.948628\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947305\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945893\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.944909\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.941731\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.94103\n",
      "[31]\ttraining's rmse: 1.01867\tvalid_1's rmse: 0.940677\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940388\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937973\n",
      "[34]\ttraining's rmse: 1.01049\tvalid_1's rmse: 0.935669\n",
      "[35]\ttraining's rmse: 1.00807\tvalid_1's rmse: 0.933977\n",
      "[36]\ttraining's rmse: 1.0072\tvalid_1's rmse: 0.93341\n",
      "[37]\ttraining's rmse: 1.00632\tvalid_1's rmse: 0.933311\n",
      "[38]\ttraining's rmse: 1.00519\tvalid_1's rmse: 0.932636\n",
      "[39]\ttraining's rmse: 1.0032\tvalid_1's rmse: 0.931371\n",
      "[40]\ttraining's rmse: 1.00245\tvalid_1's rmse: 0.931082\n",
      "[41]\ttraining's rmse: 1.00188\tvalid_1's rmse: 0.930935\n",
      "[42]\ttraining's rmse: 1.00141\tvalid_1's rmse: 0.930772\n",
      "[43]\ttraining's rmse: 0.999177\tvalid_1's rmse: 0.928973\n",
      "[44]\ttraining's rmse: 0.998494\tvalid_1's rmse: 0.928969\n",
      "[45]\ttraining's rmse: 0.997759\tvalid_1's rmse: 0.928878\n",
      "[46]\ttraining's rmse: 0.997349\tvalid_1's rmse: 0.928663\n",
      "[47]\ttraining's rmse: 0.996921\tvalid_1's rmse: 0.928583\n",
      "[48]\ttraining's rmse: 0.996101\tvalid_1's rmse: 0.928159\n",
      "[49]\ttraining's rmse: 0.995549\tvalid_1's rmse: 0.927992\n",
      "[50]\ttraining's rmse: 0.994521\tvalid_1's rmse: 0.92797\n",
      "[51]\ttraining's rmse: 0.993937\tvalid_1's rmse: 0.927364\n",
      "[52]\ttraining's rmse: 0.992293\tvalid_1's rmse: 0.926261\n",
      "[53]\ttraining's rmse: 0.991598\tvalid_1's rmse: 0.926081\n",
      "[54]\ttraining's rmse: 0.989983\tvalid_1's rmse: 0.925467\n",
      "[55]\ttraining's rmse: 0.989293\tvalid_1's rmse: 0.924849\n",
      "[56]\ttraining's rmse: 0.988814\tvalid_1's rmse: 0.925258\n",
      "[57]\ttraining's rmse: 0.988288\tvalid_1's rmse: 0.925475\n",
      "[58]\ttraining's rmse: 0.987751\tvalid_1's rmse: 0.925459\n",
      "[59]\ttraining's rmse: 0.987436\tvalid_1's rmse: 0.925365\n",
      "[60]\ttraining's rmse: 0.987136\tvalid_1's rmse: 0.925337\n",
      "[61]\ttraining's rmse: 0.986556\tvalid_1's rmse: 0.925111\n",
      "[62]\ttraining's rmse: 0.986066\tvalid_1's rmse: 0.924898\n",
      "[63]\ttraining's rmse: 0.985581\tvalid_1's rmse: 0.924849\n",
      "[64]\ttraining's rmse: 0.984673\tvalid_1's rmse: 0.924523\n",
      "[65]\ttraining's rmse: 0.984237\tvalid_1's rmse: 0.924414\n",
      "[66]\ttraining's rmse: 0.983836\tvalid_1's rmse: 0.924172\n",
      "[67]\ttraining's rmse: 0.98351\tvalid_1's rmse: 0.923866\n",
      "[68]\ttraining's rmse: 0.983302\tvalid_1's rmse: 0.923745\n",
      "[69]\ttraining's rmse: 0.983028\tvalid_1's rmse: 0.923663\n",
      "[70]\ttraining's rmse: 0.982607\tvalid_1's rmse: 0.923616\n",
      "[71]\ttraining's rmse: 0.982366\tvalid_1's rmse: 0.923625\n",
      "[72]\ttraining's rmse: 0.981488\tvalid_1's rmse: 0.923396\n",
      "[73]\ttraining's rmse: 0.98124\tvalid_1's rmse: 0.923191\n",
      "[74]\ttraining's rmse: 0.980727\tvalid_1's rmse: 0.922653\n",
      "[75]\ttraining's rmse: 0.980453\tvalid_1's rmse: 0.922757\n",
      "[76]\ttraining's rmse: 0.980132\tvalid_1's rmse: 0.922484\n",
      "[77]\ttraining's rmse: 0.979737\tvalid_1's rmse: 0.922343\n",
      "[78]\ttraining's rmse: 0.97952\tvalid_1's rmse: 0.921956\n",
      "[79]\ttraining's rmse: 0.979253\tvalid_1's rmse: 0.921908\n",
      "[80]\ttraining's rmse: 0.978406\tvalid_1's rmse: 0.921703\n",
      "[81]\ttraining's rmse: 0.978106\tvalid_1's rmse: 0.921832\n",
      "[82]\ttraining's rmse: 0.977338\tvalid_1's rmse: 0.92165\n",
      "[83]\ttraining's rmse: 0.977098\tvalid_1's rmse: 0.92152\n",
      "[84]\ttraining's rmse: 0.976762\tvalid_1's rmse: 0.921435\n",
      "[85]\ttraining's rmse: 0.976534\tvalid_1's rmse: 0.92137\n",
      "[86]\ttraining's rmse: 0.976337\tvalid_1's rmse: 0.921228\n",
      "[87]\ttraining's rmse: 0.975953\tvalid_1's rmse: 0.920791\n",
      "[88]\ttraining's rmse: 0.975336\tvalid_1's rmse: 0.920596\n",
      "[89]\ttraining's rmse: 0.975117\tvalid_1's rmse: 0.920571\n",
      "[90]\ttraining's rmse: 0.974808\tvalid_1's rmse: 0.920752\n",
      "[91]\ttraining's rmse: 0.974296\tvalid_1's rmse: 0.920585\n",
      "[92]\ttraining's rmse: 0.973953\tvalid_1's rmse: 0.920448\n",
      "[93]\ttraining's rmse: 0.973811\tvalid_1's rmse: 0.92032\n",
      "[94]\ttraining's rmse: 0.973569\tvalid_1's rmse: 0.920313\n",
      "[95]\ttraining's rmse: 0.973365\tvalid_1's rmse: 0.920257\n",
      "[96]\ttraining's rmse: 0.973148\tvalid_1's rmse: 0.920304\n",
      "[97]\ttraining's rmse: 0.972778\tvalid_1's rmse: 0.920213\n",
      "[98]\ttraining's rmse: 0.972644\tvalid_1's rmse: 0.920013\n",
      "[99]\ttraining's rmse: 0.972391\tvalid_1's rmse: 0.920127\n",
      "[100]\ttraining's rmse: 0.972194\tvalid_1's rmse: 0.919936\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972194\tvalid_1's rmse: 0.919936\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha': 0.1, 'objective': None, 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_15\n",
      "[1]\ttraining's rmse: 1.27971\tvalid_1's rmse: 1.10092\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.23489\tvalid_1's rmse: 1.07062\n",
      "[3]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.04446\n",
      "[4]\ttraining's rmse: 1.16498\tvalid_1's rmse: 1.02386\n",
      "[5]\ttraining's rmse: 1.13782\tvalid_1's rmse: 1.00672\n",
      "[6]\ttraining's rmse: 1.11383\tvalid_1's rmse: 0.990867\n",
      "[7]\ttraining's rmse: 1.09437\tvalid_1's rmse: 0.97921\n",
      "[8]\ttraining's rmse: 1.07704\tvalid_1's rmse: 0.968246\n",
      "[9]\ttraining's rmse: 1.06282\tvalid_1's rmse: 0.960219\n",
      "[10]\ttraining's rmse: 1.05088\tvalid_1's rmse: 0.953069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttraining's rmse: 1.04008\tvalid_1's rmse: 0.946935\n",
      "[12]\ttraining's rmse: 1.03105\tvalid_1's rmse: 0.942223\n",
      "[13]\ttraining's rmse: 1.02257\tvalid_1's rmse: 0.937368\n",
      "[14]\ttraining's rmse: 1.01563\tvalid_1's rmse: 0.933998\n",
      "[15]\ttraining's rmse: 1.00947\tvalid_1's rmse: 0.931442\n",
      "[16]\ttraining's rmse: 1.00407\tvalid_1's rmse: 0.929074\n",
      "[17]\ttraining's rmse: 0.999237\tvalid_1's rmse: 0.92676\n",
      "[18]\ttraining's rmse: 0.994822\tvalid_1's rmse: 0.924843\n",
      "[19]\ttraining's rmse: 0.991438\tvalid_1's rmse: 0.923913\n",
      "[20]\ttraining's rmse: 0.988044\tvalid_1's rmse: 0.9223\n",
      "[21]\ttraining's rmse: 0.984782\tvalid_1's rmse: 0.92079\n",
      "[22]\ttraining's rmse: 0.982073\tvalid_1's rmse: 0.919608\n",
      "[23]\ttraining's rmse: 0.979641\tvalid_1's rmse: 0.91895\n",
      "[24]\ttraining's rmse: 0.976575\tvalid_1's rmse: 0.917619\n",
      "[25]\ttraining's rmse: 0.974118\tvalid_1's rmse: 0.916739\n",
      "[26]\ttraining's rmse: 0.972469\tvalid_1's rmse: 0.916629\n",
      "[27]\ttraining's rmse: 0.970266\tvalid_1's rmse: 0.915795\n",
      "[28]\ttraining's rmse: 0.968774\tvalid_1's rmse: 0.915585\n",
      "[29]\ttraining's rmse: 0.967428\tvalid_1's rmse: 0.915267\n",
      "[30]\ttraining's rmse: 0.965748\tvalid_1's rmse: 0.914368\n",
      "[31]\ttraining's rmse: 0.964262\tvalid_1's rmse: 0.914023\n",
      "[32]\ttraining's rmse: 0.963258\tvalid_1's rmse: 0.913972\n",
      "[33]\ttraining's rmse: 0.962267\tvalid_1's rmse: 0.913996\n",
      "[34]\ttraining's rmse: 0.961036\tvalid_1's rmse: 0.913733\n",
      "[35]\ttraining's rmse: 0.959718\tvalid_1's rmse: 0.913538\n",
      "[36]\ttraining's rmse: 0.958704\tvalid_1's rmse: 0.913336\n",
      "[37]\ttraining's rmse: 0.957841\tvalid_1's rmse: 0.91328\n",
      "[38]\ttraining's rmse: 0.956955\tvalid_1's rmse: 0.913002\n",
      "[39]\ttraining's rmse: 0.956273\tvalid_1's rmse: 0.913269\n",
      "[40]\ttraining's rmse: 0.955369\tvalid_1's rmse: 0.913081\n",
      "[41]\ttraining's rmse: 0.954039\tvalid_1's rmse: 0.911235\n",
      "[42]\ttraining's rmse: 0.953131\tvalid_1's rmse: 0.911377\n",
      "[43]\ttraining's rmse: 0.952238\tvalid_1's rmse: 0.910792\n",
      "[44]\ttraining's rmse: 0.951641\tvalid_1's rmse: 0.910626\n",
      "[45]\ttraining's rmse: 0.950419\tvalid_1's rmse: 0.91077\n",
      "[46]\ttraining's rmse: 0.949937\tvalid_1's rmse: 0.910504\n",
      "[47]\ttraining's rmse: 0.948714\tvalid_1's rmse: 0.910432\n",
      "[48]\ttraining's rmse: 0.94799\tvalid_1's rmse: 0.910425\n",
      "[49]\ttraining's rmse: 0.947063\tvalid_1's rmse: 0.910146\n",
      "[50]\ttraining's rmse: 0.946155\tvalid_1's rmse: 0.9099\n",
      "[51]\ttraining's rmse: 0.945742\tvalid_1's rmse: 0.909922\n",
      "[52]\ttraining's rmse: 0.945014\tvalid_1's rmse: 0.909963\n",
      "[53]\ttraining's rmse: 0.944637\tvalid_1's rmse: 0.909879\n",
      "[54]\ttraining's rmse: 0.943694\tvalid_1's rmse: 0.909815\n",
      "[55]\ttraining's rmse: 0.942845\tvalid_1's rmse: 0.9095\n",
      "[56]\ttraining's rmse: 0.942371\tvalid_1's rmse: 0.909386\n",
      "[57]\ttraining's rmse: 0.941877\tvalid_1's rmse: 0.909528\n",
      "[58]\ttraining's rmse: 0.941458\tvalid_1's rmse: 0.909229\n",
      "[59]\ttraining's rmse: 0.940801\tvalid_1's rmse: 0.908867\n",
      "[60]\ttraining's rmse: 0.940325\tvalid_1's rmse: 0.90887\n",
      "[61]\ttraining's rmse: 0.939849\tvalid_1's rmse: 0.90876\n",
      "[62]\ttraining's rmse: 0.939313\tvalid_1's rmse: 0.908593\n",
      "[63]\ttraining's rmse: 0.938899\tvalid_1's rmse: 0.908446\n",
      "[64]\ttraining's rmse: 0.938363\tvalid_1's rmse: 0.908435\n",
      "[65]\ttraining's rmse: 0.937945\tvalid_1's rmse: 0.908557\n",
      "[66]\ttraining's rmse: 0.937565\tvalid_1's rmse: 0.908507\n",
      "[67]\ttraining's rmse: 0.937196\tvalid_1's rmse: 0.90838\n",
      "[68]\ttraining's rmse: 0.936707\tvalid_1's rmse: 0.90834\n",
      "[69]\ttraining's rmse: 0.936219\tvalid_1's rmse: 0.908127\n",
      "[70]\ttraining's rmse: 0.935843\tvalid_1's rmse: 0.908012\n",
      "[71]\ttraining's rmse: 0.935483\tvalid_1's rmse: 0.907777\n",
      "[72]\ttraining's rmse: 0.934463\tvalid_1's rmse: 0.907287\n",
      "[73]\ttraining's rmse: 0.933775\tvalid_1's rmse: 0.907321\n",
      "[74]\ttraining's rmse: 0.933453\tvalid_1's rmse: 0.907312\n",
      "[75]\ttraining's rmse: 0.933109\tvalid_1's rmse: 0.907426\n",
      "[76]\ttraining's rmse: 0.932402\tvalid_1's rmse: 0.907294\n",
      "[77]\ttraining's rmse: 0.932053\tvalid_1's rmse: 0.907012\n",
      "[78]\ttraining's rmse: 0.931785\tvalid_1's rmse: 0.906947\n",
      "[79]\ttraining's rmse: 0.931399\tvalid_1's rmse: 0.906885\n",
      "[80]\ttraining's rmse: 0.9311\tvalid_1's rmse: 0.906829\n",
      "[81]\ttraining's rmse: 0.930779\tvalid_1's rmse: 0.906616\n",
      "[82]\ttraining's rmse: 0.93044\tvalid_1's rmse: 0.906402\n",
      "[83]\ttraining's rmse: 0.930174\tvalid_1's rmse: 0.906404\n",
      "[84]\ttraining's rmse: 0.929831\tvalid_1's rmse: 0.906195\n",
      "[85]\ttraining's rmse: 0.929588\tvalid_1's rmse: 0.906152\n",
      "[86]\ttraining's rmse: 0.928912\tvalid_1's rmse: 0.905859\n",
      "[87]\ttraining's rmse: 0.928455\tvalid_1's rmse: 0.905812\n",
      "[88]\ttraining's rmse: 0.92817\tvalid_1's rmse: 0.905817\n",
      "[89]\ttraining's rmse: 0.927939\tvalid_1's rmse: 0.905698\n",
      "[90]\ttraining's rmse: 0.927505\tvalid_1's rmse: 0.905483\n",
      "[91]\ttraining's rmse: 0.927069\tvalid_1's rmse: 0.905482\n",
      "[92]\ttraining's rmse: 0.926707\tvalid_1's rmse: 0.905308\n",
      "[93]\ttraining's rmse: 0.926429\tvalid_1's rmse: 0.905252\n",
      "[94]\ttraining's rmse: 0.925977\tvalid_1's rmse: 0.904865\n",
      "[95]\ttraining's rmse: 0.925752\tvalid_1's rmse: 0.904788\n",
      "[96]\ttraining's rmse: 0.925436\tvalid_1's rmse: 0.904313\n",
      "[97]\ttraining's rmse: 0.925213\tvalid_1's rmse: 0.904272\n",
      "[98]\ttraining's rmse: 0.924936\tvalid_1's rmse: 0.904219\n",
      "[99]\ttraining's rmse: 0.924666\tvalid_1's rmse: 0.90423\n",
      "[100]\ttraining's rmse: 0.924438\tvalid_1's rmse: 0.90419\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.924438\tvalid_1's rmse: 0.90419\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 0.1, 'reg_alpha': 1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_16\n",
      "[1]\ttraining's rmse: 1.28979\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2536\tvalid_1's rmse: 1.08714\n",
      "[3]\ttraining's rmse: 1.22296\tvalid_1's rmse: 1.06779\n",
      "[4]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.05161\n",
      "[5]\ttraining's rmse: 1.17483\tvalid_1's rmse: 1.03824\n",
      "[6]\ttraining's rmse: 1.1554\tvalid_1's rmse: 1.02585\n",
      "[7]\ttraining's rmse: 1.13955\tvalid_1's rmse: 1.0163\n",
      "[8]\ttraining's rmse: 1.12562\tvalid_1's rmse: 1.00746\n",
      "[9]\ttraining's rmse: 1.11409\tvalid_1's rmse: 1.00096\n",
      "[10]\ttraining's rmse: 1.10376\tvalid_1's rmse: 0.995228\n",
      "[11]\ttraining's rmse: 1.09542\tvalid_1's rmse: 0.990397\n",
      "[12]\ttraining's rmse: 1.08512\tvalid_1's rmse: 0.983344\n",
      "[13]\ttraining's rmse: 1.07432\tvalid_1's rmse: 0.975203\n",
      "[14]\ttraining's rmse: 1.06867\tvalid_1's rmse: 0.972287\n",
      "[15]\ttraining's rmse: 1.06371\tvalid_1's rmse: 0.968992\n",
      "[16]\ttraining's rmse: 1.05876\tvalid_1's rmse: 0.965683\n",
      "[17]\ttraining's rmse: 1.05471\tvalid_1's rmse: 0.963335\n",
      "[18]\ttraining's rmse: 1.05056\tvalid_1's rmse: 0.960495\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959477\n",
      "[20]\ttraining's rmse: 1.04439\tvalid_1's rmse: 0.957091\n",
      "[21]\ttraining's rmse: 1.04114\tvalid_1's rmse: 0.955157\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953114\n",
      "[23]\ttraining's rmse: 1.03492\tvalid_1's rmse: 0.951205\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.9494\n",
      "[25]\ttraining's rmse: 1.03064\tvalid_1's rmse: 0.948627\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947304\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945892\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.944908\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.94173\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.941029\n",
      "[31]\ttraining's rmse: 1.01866\tvalid_1's rmse: 0.940676\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940387\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937972\n",
      "[34]\ttraining's rmse: 1.01049\tvalid_1's rmse: 0.935668\n",
      "[35]\ttraining's rmse: 1.00806\tvalid_1's rmse: 0.933976\n",
      "[36]\ttraining's rmse: 1.00719\tvalid_1's rmse: 0.933409\n",
      "[37]\ttraining's rmse: 1.00632\tvalid_1's rmse: 0.93331\n",
      "[38]\ttraining's rmse: 1.00519\tvalid_1's rmse: 0.932635\n",
      "[39]\ttraining's rmse: 1.0032\tvalid_1's rmse: 0.93137\n",
      "[40]\ttraining's rmse: 1.00245\tvalid_1's rmse: 0.931082\n",
      "[41]\ttraining's rmse: 1.00188\tvalid_1's rmse: 0.930934\n",
      "[42]\ttraining's rmse: 1.00141\tvalid_1's rmse: 0.930772\n",
      "[43]\ttraining's rmse: 0.999174\tvalid_1's rmse: 0.928972\n",
      "[44]\ttraining's rmse: 0.99849\tvalid_1's rmse: 0.928968\n",
      "[45]\ttraining's rmse: 0.997755\tvalid_1's rmse: 0.928878\n",
      "[46]\ttraining's rmse: 0.997346\tvalid_1's rmse: 0.928663\n",
      "[47]\ttraining's rmse: 0.996918\tvalid_1's rmse: 0.928582\n",
      "[48]\ttraining's rmse: 0.996097\tvalid_1's rmse: 0.928159\n",
      "[49]\ttraining's rmse: 0.995546\tvalid_1's rmse: 0.927992\n",
      "[50]\ttraining's rmse: 0.994518\tvalid_1's rmse: 0.927969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\ttraining's rmse: 0.993934\tvalid_1's rmse: 0.927363\n",
      "[52]\ttraining's rmse: 0.99229\tvalid_1's rmse: 0.92626\n",
      "[53]\ttraining's rmse: 0.991594\tvalid_1's rmse: 0.92608\n",
      "[54]\ttraining's rmse: 0.989979\tvalid_1's rmse: 0.925467\n",
      "[55]\ttraining's rmse: 0.989289\tvalid_1's rmse: 0.924849\n",
      "[56]\ttraining's rmse: 0.988811\tvalid_1's rmse: 0.925258\n",
      "[57]\ttraining's rmse: 0.988284\tvalid_1's rmse: 0.925475\n",
      "[58]\ttraining's rmse: 0.987747\tvalid_1's rmse: 0.925459\n",
      "[59]\ttraining's rmse: 0.987431\tvalid_1's rmse: 0.925365\n",
      "[60]\ttraining's rmse: 0.987132\tvalid_1's rmse: 0.925337\n",
      "[61]\ttraining's rmse: 0.986552\tvalid_1's rmse: 0.925111\n",
      "[62]\ttraining's rmse: 0.986062\tvalid_1's rmse: 0.924898\n",
      "[63]\ttraining's rmse: 0.985576\tvalid_1's rmse: 0.924849\n",
      "[64]\ttraining's rmse: 0.984669\tvalid_1's rmse: 0.924522\n",
      "[65]\ttraining's rmse: 0.984232\tvalid_1's rmse: 0.924414\n",
      "[66]\ttraining's rmse: 0.983832\tvalid_1's rmse: 0.924172\n",
      "[67]\ttraining's rmse: 0.983505\tvalid_1's rmse: 0.923866\n",
      "[68]\ttraining's rmse: 0.983297\tvalid_1's rmse: 0.923745\n",
      "[69]\ttraining's rmse: 0.983023\tvalid_1's rmse: 0.923663\n",
      "[70]\ttraining's rmse: 0.982602\tvalid_1's rmse: 0.923616\n",
      "[71]\ttraining's rmse: 0.982361\tvalid_1's rmse: 0.923625\n",
      "[72]\ttraining's rmse: 0.981483\tvalid_1's rmse: 0.923396\n",
      "[73]\ttraining's rmse: 0.981235\tvalid_1's rmse: 0.923191\n",
      "[74]\ttraining's rmse: 0.980722\tvalid_1's rmse: 0.922653\n",
      "[75]\ttraining's rmse: 0.980448\tvalid_1's rmse: 0.922757\n",
      "[76]\ttraining's rmse: 0.980127\tvalid_1's rmse: 0.922484\n",
      "[77]\ttraining's rmse: 0.979732\tvalid_1's rmse: 0.922343\n",
      "[78]\ttraining's rmse: 0.979514\tvalid_1's rmse: 0.921955\n",
      "[79]\ttraining's rmse: 0.979247\tvalid_1's rmse: 0.921907\n",
      "[80]\ttraining's rmse: 0.9784\tvalid_1's rmse: 0.921702\n",
      "[81]\ttraining's rmse: 0.9781\tvalid_1's rmse: 0.921831\n",
      "[82]\ttraining's rmse: 0.977332\tvalid_1's rmse: 0.921649\n",
      "[83]\ttraining's rmse: 0.977092\tvalid_1's rmse: 0.92152\n",
      "[84]\ttraining's rmse: 0.976757\tvalid_1's rmse: 0.921434\n",
      "[85]\ttraining's rmse: 0.976529\tvalid_1's rmse: 0.921369\n",
      "[86]\ttraining's rmse: 0.976331\tvalid_1's rmse: 0.921228\n",
      "[87]\ttraining's rmse: 0.975948\tvalid_1's rmse: 0.920791\n",
      "[88]\ttraining's rmse: 0.97533\tvalid_1's rmse: 0.920596\n",
      "[89]\ttraining's rmse: 0.975111\tvalid_1's rmse: 0.920571\n",
      "[90]\ttraining's rmse: 0.974802\tvalid_1's rmse: 0.920751\n",
      "[91]\ttraining's rmse: 0.974291\tvalid_1's rmse: 0.920585\n",
      "[92]\ttraining's rmse: 0.973947\tvalid_1's rmse: 0.920447\n",
      "[93]\ttraining's rmse: 0.973805\tvalid_1's rmse: 0.92032\n",
      "[94]\ttraining's rmse: 0.973563\tvalid_1's rmse: 0.920313\n",
      "[95]\ttraining's rmse: 0.973359\tvalid_1's rmse: 0.920256\n",
      "[96]\ttraining's rmse: 0.97321\tvalid_1's rmse: 0.920094\n",
      "[97]\ttraining's rmse: 0.972839\tvalid_1's rmse: 0.920003\n",
      "[98]\ttraining's rmse: 0.972598\tvalid_1's rmse: 0.91997\n",
      "[99]\ttraining's rmse: 0.972404\tvalid_1's rmse: 0.91978\n",
      "[100]\ttraining's rmse: 0.972203\tvalid_1's rmse: 0.919776\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972203\tvalid_1's rmse: 0.919776\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_17\n",
      "[1]\ttraining's rmse: 1.28979\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2536\tvalid_1's rmse: 1.08714\n",
      "[3]\ttraining's rmse: 1.22296\tvalid_1's rmse: 1.06779\n",
      "[4]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.05161\n",
      "[5]\ttraining's rmse: 1.17483\tvalid_1's rmse: 1.03824\n",
      "[6]\ttraining's rmse: 1.15539\tvalid_1's rmse: 1.02585\n",
      "[7]\ttraining's rmse: 1.13955\tvalid_1's rmse: 1.0163\n",
      "[8]\ttraining's rmse: 1.12562\tvalid_1's rmse: 1.00746\n",
      "[9]\ttraining's rmse: 1.11408\tvalid_1's rmse: 1.00096\n",
      "[10]\ttraining's rmse: 1.10376\tvalid_1's rmse: 0.995226\n",
      "[11]\ttraining's rmse: 1.09542\tvalid_1's rmse: 0.990395\n",
      "[12]\ttraining's rmse: 1.08511\tvalid_1's rmse: 0.983343\n",
      "[13]\ttraining's rmse: 1.07432\tvalid_1's rmse: 0.975201\n",
      "[14]\ttraining's rmse: 1.06866\tvalid_1's rmse: 0.972286\n",
      "[15]\ttraining's rmse: 1.0637\tvalid_1's rmse: 0.968991\n",
      "[16]\ttraining's rmse: 1.05876\tvalid_1's rmse: 0.965681\n",
      "[17]\ttraining's rmse: 1.05471\tvalid_1's rmse: 0.963333\n",
      "[18]\ttraining's rmse: 1.05056\tvalid_1's rmse: 0.960493\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959476\n",
      "[20]\ttraining's rmse: 1.04439\tvalid_1's rmse: 0.95709\n",
      "[21]\ttraining's rmse: 1.04114\tvalid_1's rmse: 0.955156\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953113\n",
      "[23]\ttraining's rmse: 1.03492\tvalid_1's rmse: 0.951204\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949399\n",
      "[25]\ttraining's rmse: 1.03063\tvalid_1's rmse: 0.948626\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947303\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945891\n",
      "[28]\ttraining's rmse: 1.02488\tvalid_1's rmse: 0.944907\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.941729\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.941028\n",
      "[31]\ttraining's rmse: 1.01866\tvalid_1's rmse: 0.940675\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940386\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937971\n",
      "[34]\ttraining's rmse: 1.01048\tvalid_1's rmse: 0.935667\n",
      "[35]\ttraining's rmse: 1.00806\tvalid_1's rmse: 0.933975\n",
      "[36]\ttraining's rmse: 1.00719\tvalid_1's rmse: 0.933409\n",
      "[37]\ttraining's rmse: 1.00631\tvalid_1's rmse: 0.933309\n",
      "[38]\ttraining's rmse: 1.00519\tvalid_1's rmse: 0.932635\n",
      "[39]\ttraining's rmse: 1.00319\tvalid_1's rmse: 0.93137\n",
      "[40]\ttraining's rmse: 1.00244\tvalid_1's rmse: 0.931081\n",
      "[41]\ttraining's rmse: 1.00187\tvalid_1's rmse: 0.930934\n",
      "[42]\ttraining's rmse: 1.00141\tvalid_1's rmse: 0.930771\n",
      "[43]\ttraining's rmse: 0.999171\tvalid_1's rmse: 0.928971\n",
      "[44]\ttraining's rmse: 0.998487\tvalid_1's rmse: 0.928968\n",
      "[45]\ttraining's rmse: 0.997752\tvalid_1's rmse: 0.928877\n",
      "[46]\ttraining's rmse: 0.997342\tvalid_1's rmse: 0.928663\n",
      "[47]\ttraining's rmse: 0.996915\tvalid_1's rmse: 0.928582\n",
      "[48]\ttraining's rmse: 0.996094\tvalid_1's rmse: 0.928159\n",
      "[49]\ttraining's rmse: 0.995543\tvalid_1's rmse: 0.927992\n",
      "[50]\ttraining's rmse: 0.994514\tvalid_1's rmse: 0.927969\n",
      "[51]\ttraining's rmse: 0.993931\tvalid_1's rmse: 0.927363\n",
      "[52]\ttraining's rmse: 0.992287\tvalid_1's rmse: 0.92626\n",
      "[53]\ttraining's rmse: 0.991591\tvalid_1's rmse: 0.92608\n",
      "[54]\ttraining's rmse: 0.989976\tvalid_1's rmse: 0.925467\n",
      "[55]\ttraining's rmse: 0.989286\tvalid_1's rmse: 0.924848\n",
      "[56]\ttraining's rmse: 0.988807\tvalid_1's rmse: 0.925257\n",
      "[57]\ttraining's rmse: 0.98828\tvalid_1's rmse: 0.925475\n",
      "[58]\ttraining's rmse: 0.987743\tvalid_1's rmse: 0.925459\n",
      "[59]\ttraining's rmse: 0.987428\tvalid_1's rmse: 0.925365\n",
      "[60]\ttraining's rmse: 0.987128\tvalid_1's rmse: 0.925349\n",
      "[61]\ttraining's rmse: 0.986548\tvalid_1's rmse: 0.925123\n",
      "[62]\ttraining's rmse: 0.986058\tvalid_1's rmse: 0.924911\n",
      "[63]\ttraining's rmse: 0.985572\tvalid_1's rmse: 0.924861\n",
      "[64]\ttraining's rmse: 0.984665\tvalid_1's rmse: 0.924535\n",
      "[65]\ttraining's rmse: 0.984228\tvalid_1's rmse: 0.924426\n",
      "[66]\ttraining's rmse: 0.983828\tvalid_1's rmse: 0.924184\n",
      "[67]\ttraining's rmse: 0.983501\tvalid_1's rmse: 0.923878\n",
      "[68]\ttraining's rmse: 0.983294\tvalid_1's rmse: 0.923757\n",
      "[69]\ttraining's rmse: 0.983019\tvalid_1's rmse: 0.923676\n",
      "[70]\ttraining's rmse: 0.982598\tvalid_1's rmse: 0.923629\n",
      "[71]\ttraining's rmse: 0.982356\tvalid_1's rmse: 0.923638\n",
      "[72]\ttraining's rmse: 0.981478\tvalid_1's rmse: 0.923408\n",
      "[73]\ttraining's rmse: 0.98123\tvalid_1's rmse: 0.923204\n",
      "[74]\ttraining's rmse: 0.980717\tvalid_1's rmse: 0.922666\n",
      "[75]\ttraining's rmse: 0.980444\tvalid_1's rmse: 0.922771\n",
      "[76]\ttraining's rmse: 0.980123\tvalid_1's rmse: 0.922497\n",
      "[77]\ttraining's rmse: 0.979728\tvalid_1's rmse: 0.922357\n",
      "[78]\ttraining's rmse: 0.97951\tvalid_1's rmse: 0.921968\n",
      "[79]\ttraining's rmse: 0.979243\tvalid_1's rmse: 0.92192\n",
      "[80]\ttraining's rmse: 0.978396\tvalid_1's rmse: 0.921714\n",
      "[81]\ttraining's rmse: 0.978096\tvalid_1's rmse: 0.921844\n",
      "[82]\ttraining's rmse: 0.977328\tvalid_1's rmse: 0.921662\n",
      "[83]\ttraining's rmse: 0.977088\tvalid_1's rmse: 0.921533\n",
      "[84]\ttraining's rmse: 0.976753\tvalid_1's rmse: 0.921447\n",
      "[85]\ttraining's rmse: 0.976524\tvalid_1's rmse: 0.921383\n",
      "[86]\ttraining's rmse: 0.976327\tvalid_1's rmse: 0.921241\n",
      "[87]\ttraining's rmse: 0.975943\tvalid_1's rmse: 0.920781\n",
      "[88]\ttraining's rmse: 0.975327\tvalid_1's rmse: 0.920586\n",
      "[89]\ttraining's rmse: 0.975013\tvalid_1's rmse: 0.920767\n",
      "[90]\ttraining's rmse: 0.974799\tvalid_1's rmse: 0.920746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91]\ttraining's rmse: 0.974527\tvalid_1's rmse: 0.920619\n",
      "[92]\ttraining's rmse: 0.974154\tvalid_1's rmse: 0.920591\n",
      "[93]\ttraining's rmse: 0.973858\tvalid_1's rmse: 0.920683\n",
      "[94]\ttraining's rmse: 0.973724\tvalid_1's rmse: 0.920582\n",
      "[95]\ttraining's rmse: 0.973511\tvalid_1's rmse: 0.920619\n",
      "[96]\ttraining's rmse: 0.973308\tvalid_1's rmse: 0.920567\n",
      "[97]\ttraining's rmse: 0.973079\tvalid_1's rmse: 0.920476\n",
      "[98]\ttraining's rmse: 0.972721\tvalid_1's rmse: 0.920364\n",
      "[99]\ttraining's rmse: 0.972527\tvalid_1's rmse: 0.920363\n",
      "[100]\ttraining's rmse: 0.972263\tvalid_1's rmse: 0.920245\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972263\tvalid_1's rmse: 0.920245\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 2, 'reg_alpha': 0.1, 'objective': None, 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_18\n",
      "[1]\ttraining's rmse: 1.27977\tvalid_1's rmse: 1.10098\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.235\tvalid_1's rmse: 1.07069\n",
      "[3]\ttraining's rmse: 1.19707\tvalid_1's rmse: 1.04456\n",
      "[4]\ttraining's rmse: 1.16497\tvalid_1's rmse: 1.02364\n",
      "[5]\ttraining's rmse: 1.13799\tvalid_1's rmse: 1.00638\n",
      "[6]\ttraining's rmse: 1.11401\tvalid_1's rmse: 0.990412\n",
      "[7]\ttraining's rmse: 1.09364\tvalid_1's rmse: 0.976917\n",
      "[8]\ttraining's rmse: 1.07687\tvalid_1's rmse: 0.967322\n",
      "[9]\ttraining's rmse: 1.06216\tvalid_1's rmse: 0.9584\n",
      "[10]\ttraining's rmse: 1.05018\tvalid_1's rmse: 0.951275\n",
      "[11]\ttraining's rmse: 1.03912\tvalid_1's rmse: 0.945063\n",
      "[12]\ttraining's rmse: 1.02998\tvalid_1's rmse: 0.940368\n",
      "[13]\ttraining's rmse: 1.02172\tvalid_1's rmse: 0.936187\n",
      "[14]\ttraining's rmse: 1.01515\tvalid_1's rmse: 0.933499\n",
      "[15]\ttraining's rmse: 1.00924\tvalid_1's rmse: 0.930517\n",
      "[16]\ttraining's rmse: 1.0041\tvalid_1's rmse: 0.927854\n",
      "[17]\ttraining's rmse: 0.999237\tvalid_1's rmse: 0.925363\n",
      "[18]\ttraining's rmse: 0.994875\tvalid_1's rmse: 0.923679\n",
      "[19]\ttraining's rmse: 0.990721\tvalid_1's rmse: 0.922502\n",
      "[20]\ttraining's rmse: 0.987232\tvalid_1's rmse: 0.921266\n",
      "[21]\ttraining's rmse: 0.983903\tvalid_1's rmse: 0.919721\n",
      "[22]\ttraining's rmse: 0.981124\tvalid_1's rmse: 0.918446\n",
      "[23]\ttraining's rmse: 0.978684\tvalid_1's rmse: 0.917936\n",
      "[24]\ttraining's rmse: 0.976173\tvalid_1's rmse: 0.916973\n",
      "[25]\ttraining's rmse: 0.973616\tvalid_1's rmse: 0.916539\n",
      "[26]\ttraining's rmse: 0.971515\tvalid_1's rmse: 0.916074\n",
      "[27]\ttraining's rmse: 0.969356\tvalid_1's rmse: 0.915061\n",
      "[28]\ttraining's rmse: 0.967808\tvalid_1's rmse: 0.914544\n",
      "[29]\ttraining's rmse: 0.966554\tvalid_1's rmse: 0.914314\n",
      "[30]\ttraining's rmse: 0.965128\tvalid_1's rmse: 0.914088\n",
      "[31]\ttraining's rmse: 0.963749\tvalid_1's rmse: 0.913852\n",
      "[32]\ttraining's rmse: 0.962533\tvalid_1's rmse: 0.913752\n",
      "[33]\ttraining's rmse: 0.961571\tvalid_1's rmse: 0.9136\n",
      "[34]\ttraining's rmse: 0.960454\tvalid_1's rmse: 0.913169\n",
      "[35]\ttraining's rmse: 0.959588\tvalid_1's rmse: 0.91255\n",
      "[36]\ttraining's rmse: 0.958868\tvalid_1's rmse: 0.912576\n",
      "[37]\ttraining's rmse: 0.957792\tvalid_1's rmse: 0.91226\n",
      "[38]\ttraining's rmse: 0.95644\tvalid_1's rmse: 0.911934\n",
      "[39]\ttraining's rmse: 0.955327\tvalid_1's rmse: 0.911653\n",
      "[40]\ttraining's rmse: 0.954684\tvalid_1's rmse: 0.9114\n",
      "[41]\ttraining's rmse: 0.953816\tvalid_1's rmse: 0.911189\n",
      "[42]\ttraining's rmse: 0.952742\tvalid_1's rmse: 0.910922\n",
      "[43]\ttraining's rmse: 0.95153\tvalid_1's rmse: 0.910924\n",
      "[44]\ttraining's rmse: 0.950868\tvalid_1's rmse: 0.910793\n",
      "[45]\ttraining's rmse: 0.949575\tvalid_1's rmse: 0.910688\n",
      "[46]\ttraining's rmse: 0.948921\tvalid_1's rmse: 0.910648\n",
      "[47]\ttraining's rmse: 0.948314\tvalid_1's rmse: 0.910545\n",
      "[48]\ttraining's rmse: 0.947749\tvalid_1's rmse: 0.910504\n",
      "[49]\ttraining's rmse: 0.946938\tvalid_1's rmse: 0.910201\n",
      "[50]\ttraining's rmse: 0.946334\tvalid_1's rmse: 0.910161\n",
      "[51]\ttraining's rmse: 0.945574\tvalid_1's rmse: 0.910132\n",
      "[52]\ttraining's rmse: 0.94482\tvalid_1's rmse: 0.909453\n",
      "[53]\ttraining's rmse: 0.944052\tvalid_1's rmse: 0.909201\n",
      "[54]\ttraining's rmse: 0.943584\tvalid_1's rmse: 0.90957\n",
      "[55]\ttraining's rmse: 0.94296\tvalid_1's rmse: 0.909207\n",
      "[56]\ttraining's rmse: 0.942306\tvalid_1's rmse: 0.907623\n",
      "[57]\ttraining's rmse: 0.941828\tvalid_1's rmse: 0.90745\n",
      "[58]\ttraining's rmse: 0.941347\tvalid_1's rmse: 0.907383\n",
      "[59]\ttraining's rmse: 0.940903\tvalid_1's rmse: 0.907315\n",
      "[60]\ttraining's rmse: 0.940103\tvalid_1's rmse: 0.907604\n",
      "[61]\ttraining's rmse: 0.939516\tvalid_1's rmse: 0.907587\n",
      "[62]\ttraining's rmse: 0.939136\tvalid_1's rmse: 0.908381\n",
      "[63]\ttraining's rmse: 0.938484\tvalid_1's rmse: 0.908142\n",
      "[64]\ttraining's rmse: 0.938144\tvalid_1's rmse: 0.908225\n",
      "[65]\ttraining's rmse: 0.93765\tvalid_1's rmse: 0.908086\n",
      "[66]\ttraining's rmse: 0.936813\tvalid_1's rmse: 0.907489\n",
      "[67]\ttraining's rmse: 0.936375\tvalid_1's rmse: 0.907334\n",
      "[68]\ttraining's rmse: 0.935781\tvalid_1's rmse: 0.907284\n",
      "[69]\ttraining's rmse: 0.935558\tvalid_1's rmse: 0.907293\n",
      "[70]\ttraining's rmse: 0.935144\tvalid_1's rmse: 0.907008\n",
      "[71]\ttraining's rmse: 0.934721\tvalid_1's rmse: 0.906894\n",
      "[72]\ttraining's rmse: 0.934288\tvalid_1's rmse: 0.906769\n",
      "[73]\ttraining's rmse: 0.933818\tvalid_1's rmse: 0.906663\n",
      "[74]\ttraining's rmse: 0.933299\tvalid_1's rmse: 0.906638\n",
      "[75]\ttraining's rmse: 0.932813\tvalid_1's rmse: 0.90656\n",
      "[76]\ttraining's rmse: 0.932337\tvalid_1's rmse: 0.9061\n",
      "[77]\ttraining's rmse: 0.931988\tvalid_1's rmse: 0.906138\n",
      "[78]\ttraining's rmse: 0.931695\tvalid_1's rmse: 0.906285\n",
      "[79]\ttraining's rmse: 0.93136\tvalid_1's rmse: 0.906277\n",
      "[80]\ttraining's rmse: 0.931082\tvalid_1's rmse: 0.906215\n",
      "[81]\ttraining's rmse: 0.930744\tvalid_1's rmse: 0.905884\n",
      "[82]\ttraining's rmse: 0.930161\tvalid_1's rmse: 0.905715\n",
      "[83]\ttraining's rmse: 0.929717\tvalid_1's rmse: 0.905225\n",
      "[84]\ttraining's rmse: 0.929455\tvalid_1's rmse: 0.90533\n",
      "[85]\ttraining's rmse: 0.928729\tvalid_1's rmse: 0.905259\n",
      "[86]\ttraining's rmse: 0.928241\tvalid_1's rmse: 0.905242\n",
      "[87]\ttraining's rmse: 0.927883\tvalid_1's rmse: 0.905028\n",
      "[88]\ttraining's rmse: 0.927639\tvalid_1's rmse: 0.904999\n",
      "[89]\ttraining's rmse: 0.927156\tvalid_1's rmse: 0.905325\n",
      "[90]\ttraining's rmse: 0.926948\tvalid_1's rmse: 0.905273\n",
      "[91]\ttraining's rmse: 0.926787\tvalid_1's rmse: 0.905484\n",
      "[92]\ttraining's rmse: 0.926513\tvalid_1's rmse: 0.905473\n",
      "[93]\ttraining's rmse: 0.926208\tvalid_1's rmse: 0.905418\n",
      "[94]\ttraining's rmse: 0.925815\tvalid_1's rmse: 0.905228\n",
      "[95]\ttraining's rmse: 0.925592\tvalid_1's rmse: 0.905137\n",
      "[96]\ttraining's rmse: 0.924929\tvalid_1's rmse: 0.905341\n",
      "[97]\ttraining's rmse: 0.924668\tvalid_1's rmse: 0.905327\n",
      "[98]\ttraining's rmse: 0.924421\tvalid_1's rmse: 0.905277\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's rmse: 0.927639\tvalid_1's rmse: 0.904999\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.7, 'reg_lambda': 0, 'reg_alpha': 1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_19\n",
      "[1]\ttraining's rmse: 1.28979\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2536\tvalid_1's rmse: 1.08714\n",
      "[3]\ttraining's rmse: 1.22296\tvalid_1's rmse: 1.06779\n",
      "[4]\ttraining's rmse: 1.19692\tvalid_1's rmse: 1.05161\n",
      "[5]\ttraining's rmse: 1.17483\tvalid_1's rmse: 1.03824\n",
      "[6]\ttraining's rmse: 1.15539\tvalid_1's rmse: 1.02585\n",
      "[7]\ttraining's rmse: 1.13955\tvalid_1's rmse: 1.0163\n",
      "[8]\ttraining's rmse: 1.12562\tvalid_1's rmse: 1.00746\n",
      "[9]\ttraining's rmse: 1.11408\tvalid_1's rmse: 1.00096\n",
      "[10]\ttraining's rmse: 1.10376\tvalid_1's rmse: 0.995227\n",
      "[11]\ttraining's rmse: 1.09542\tvalid_1's rmse: 0.990396\n",
      "[12]\ttraining's rmse: 1.08512\tvalid_1's rmse: 0.983343\n",
      "[13]\ttraining's rmse: 1.07432\tvalid_1's rmse: 0.975202\n",
      "[14]\ttraining's rmse: 1.06867\tvalid_1's rmse: 0.972287\n",
      "[15]\ttraining's rmse: 1.0637\tvalid_1's rmse: 0.968991\n",
      "[16]\ttraining's rmse: 1.05876\tvalid_1's rmse: 0.965682\n",
      "[17]\ttraining's rmse: 1.05471\tvalid_1's rmse: 0.963334\n",
      "[18]\ttraining's rmse: 1.05056\tvalid_1's rmse: 0.960494\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959477\n",
      "[20]\ttraining's rmse: 1.04439\tvalid_1's rmse: 0.95709\n",
      "[21]\ttraining's rmse: 1.04114\tvalid_1's rmse: 0.955156\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953114\n",
      "[23]\ttraining's rmse: 1.03492\tvalid_1's rmse: 0.951204\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\ttraining's rmse: 1.03063\tvalid_1's rmse: 0.948627\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947303\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945891\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.944908\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.94173\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.941028\n",
      "[31]\ttraining's rmse: 1.01866\tvalid_1's rmse: 0.940676\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940386\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937972\n",
      "[34]\ttraining's rmse: 1.01048\tvalid_1's rmse: 0.935668\n",
      "[35]\ttraining's rmse: 1.00806\tvalid_1's rmse: 0.933975\n",
      "[36]\ttraining's rmse: 1.00719\tvalid_1's rmse: 0.933409\n",
      "[37]\ttraining's rmse: 1.00632\tvalid_1's rmse: 0.93331\n",
      "[38]\ttraining's rmse: 1.00519\tvalid_1's rmse: 0.932635\n",
      "[39]\ttraining's rmse: 1.0032\tvalid_1's rmse: 0.93137\n",
      "[40]\ttraining's rmse: 1.00245\tvalid_1's rmse: 0.931082\n",
      "[41]\ttraining's rmse: 1.00188\tvalid_1's rmse: 0.930934\n",
      "[42]\ttraining's rmse: 1.00141\tvalid_1's rmse: 0.930772\n",
      "[43]\ttraining's rmse: 0.999172\tvalid_1's rmse: 0.928972\n",
      "[44]\ttraining's rmse: 0.998488\tvalid_1's rmse: 0.928969\n",
      "[45]\ttraining's rmse: 0.997753\tvalid_1's rmse: 0.928878\n",
      "[46]\ttraining's rmse: 0.997344\tvalid_1's rmse: 0.928663\n",
      "[47]\ttraining's rmse: 0.996916\tvalid_1's rmse: 0.928582\n",
      "[48]\ttraining's rmse: 0.996096\tvalid_1's rmse: 0.928159\n",
      "[49]\ttraining's rmse: 0.995544\tvalid_1's rmse: 0.927992\n",
      "[50]\ttraining's rmse: 0.994516\tvalid_1's rmse: 0.92797\n",
      "[51]\ttraining's rmse: 0.993932\tvalid_1's rmse: 0.927364\n",
      "[52]\ttraining's rmse: 0.992288\tvalid_1's rmse: 0.926261\n",
      "[53]\ttraining's rmse: 0.991593\tvalid_1's rmse: 0.926081\n",
      "[54]\ttraining's rmse: 0.989977\tvalid_1's rmse: 0.925467\n",
      "[55]\ttraining's rmse: 0.989288\tvalid_1's rmse: 0.924849\n",
      "[56]\ttraining's rmse: 0.988809\tvalid_1's rmse: 0.925258\n",
      "[57]\ttraining's rmse: 0.988282\tvalid_1's rmse: 0.925475\n",
      "[58]\ttraining's rmse: 0.987745\tvalid_1's rmse: 0.925459\n",
      "[59]\ttraining's rmse: 0.987429\tvalid_1's rmse: 0.925365\n",
      "[60]\ttraining's rmse: 0.987129\tvalid_1's rmse: 0.925349\n",
      "[61]\ttraining's rmse: 0.986549\tvalid_1's rmse: 0.925123\n",
      "[62]\ttraining's rmse: 0.98606\tvalid_1's rmse: 0.924911\n",
      "[63]\ttraining's rmse: 0.985574\tvalid_1's rmse: 0.924861\n",
      "[64]\ttraining's rmse: 0.984667\tvalid_1's rmse: 0.924535\n",
      "[65]\ttraining's rmse: 0.98423\tvalid_1's rmse: 0.924426\n",
      "[66]\ttraining's rmse: 0.98383\tvalid_1's rmse: 0.924184\n",
      "[67]\ttraining's rmse: 0.983503\tvalid_1's rmse: 0.923878\n",
      "[68]\ttraining's rmse: 0.983296\tvalid_1's rmse: 0.923758\n",
      "[69]\ttraining's rmse: 0.983021\tvalid_1's rmse: 0.923676\n",
      "[70]\ttraining's rmse: 0.9826\tvalid_1's rmse: 0.923629\n",
      "[71]\ttraining's rmse: 0.982358\tvalid_1's rmse: 0.923638\n",
      "[72]\ttraining's rmse: 0.98148\tvalid_1's rmse: 0.923408\n",
      "[73]\ttraining's rmse: 0.981232\tvalid_1's rmse: 0.923204\n",
      "[74]\ttraining's rmse: 0.980719\tvalid_1's rmse: 0.922667\n",
      "[75]\ttraining's rmse: 0.980446\tvalid_1's rmse: 0.922771\n",
      "[76]\ttraining's rmse: 0.980125\tvalid_1's rmse: 0.922498\n",
      "[77]\ttraining's rmse: 0.97973\tvalid_1's rmse: 0.922357\n",
      "[78]\ttraining's rmse: 0.979513\tvalid_1's rmse: 0.921969\n",
      "[79]\ttraining's rmse: 0.979246\tvalid_1's rmse: 0.921921\n",
      "[80]\ttraining's rmse: 0.978398\tvalid_1's rmse: 0.921715\n",
      "[81]\ttraining's rmse: 0.978098\tvalid_1's rmse: 0.921844\n",
      "[82]\ttraining's rmse: 0.97733\tvalid_1's rmse: 0.921662\n",
      "[83]\ttraining's rmse: 0.97709\tvalid_1's rmse: 0.921533\n",
      "[84]\ttraining's rmse: 0.976755\tvalid_1's rmse: 0.921448\n",
      "[85]\ttraining's rmse: 0.976527\tvalid_1's rmse: 0.921383\n",
      "[86]\ttraining's rmse: 0.976329\tvalid_1's rmse: 0.921241\n",
      "[87]\ttraining's rmse: 0.975946\tvalid_1's rmse: 0.920781\n",
      "[88]\ttraining's rmse: 0.97533\tvalid_1's rmse: 0.920586\n",
      "[89]\ttraining's rmse: 0.975016\tvalid_1's rmse: 0.920767\n",
      "[90]\ttraining's rmse: 0.974802\tvalid_1's rmse: 0.920746\n",
      "[91]\ttraining's rmse: 0.97453\tvalid_1's rmse: 0.920619\n",
      "[92]\ttraining's rmse: 0.974157\tvalid_1's rmse: 0.920591\n",
      "[93]\ttraining's rmse: 0.973861\tvalid_1's rmse: 0.920683\n",
      "[94]\ttraining's rmse: 0.973727\tvalid_1's rmse: 0.920582\n",
      "[95]\ttraining's rmse: 0.973513\tvalid_1's rmse: 0.920619\n",
      "[96]\ttraining's rmse: 0.973311\tvalid_1's rmse: 0.920568\n",
      "[97]\ttraining's rmse: 0.973082\tvalid_1's rmse: 0.920476\n",
      "[98]\ttraining's rmse: 0.972724\tvalid_1's rmse: 0.920364\n",
      "[99]\ttraining's rmse: 0.97253\tvalid_1's rmse: 0.920363\n",
      "[100]\ttraining's rmse: 0.972265\tvalid_1's rmse: 0.920245\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972265\tvalid_1's rmse: 0.920245\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 2, 'reg_alpha': 1, 'objective': None, 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_20\n",
      "[1]\ttraining's rmse: 1.28981\tvalid_1's rmse: 1.11\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.25362\tvalid_1's rmse: 1.08716\n",
      "[3]\ttraining's rmse: 1.22299\tvalid_1's rmse: 1.06782\n",
      "[4]\ttraining's rmse: 1.19697\tvalid_1's rmse: 1.05164\n",
      "[5]\ttraining's rmse: 1.17487\tvalid_1's rmse: 1.03827\n",
      "[6]\ttraining's rmse: 1.15544\tvalid_1's rmse: 1.02588\n",
      "[7]\ttraining's rmse: 1.13959\tvalid_1's rmse: 1.01633\n",
      "[8]\ttraining's rmse: 1.12565\tvalid_1's rmse: 1.00748\n",
      "[9]\ttraining's rmse: 1.11412\tvalid_1's rmse: 1.00098\n",
      "[10]\ttraining's rmse: 1.10379\tvalid_1's rmse: 0.995249\n",
      "[11]\ttraining's rmse: 1.09545\tvalid_1's rmse: 0.990417\n",
      "[12]\ttraining's rmse: 1.08515\tvalid_1's rmse: 0.983362\n",
      "[13]\ttraining's rmse: 1.07435\tvalid_1's rmse: 0.97522\n",
      "[14]\ttraining's rmse: 1.06869\tvalid_1's rmse: 0.972303\n",
      "[15]\ttraining's rmse: 1.06373\tvalid_1's rmse: 0.969006\n",
      "[16]\ttraining's rmse: 1.05878\tvalid_1's rmse: 0.965696\n",
      "[17]\ttraining's rmse: 1.05473\tvalid_1's rmse: 0.963347\n",
      "[18]\ttraining's rmse: 1.05058\tvalid_1's rmse: 0.960507\n",
      "[19]\ttraining's rmse: 1.04752\tvalid_1's rmse: 0.959489\n",
      "[20]\ttraining's rmse: 1.04441\tvalid_1's rmse: 0.957101\n",
      "[21]\ttraining's rmse: 1.04116\tvalid_1's rmse: 0.955167\n",
      "[22]\ttraining's rmse: 1.03749\tvalid_1's rmse: 0.953123\n",
      "[23]\ttraining's rmse: 1.03494\tvalid_1's rmse: 0.951213\n",
      "[24]\ttraining's rmse: 1.03262\tvalid_1's rmse: 0.949407\n",
      "[25]\ttraining's rmse: 1.03065\tvalid_1's rmse: 0.948635\n",
      "[26]\ttraining's rmse: 1.02859\tvalid_1's rmse: 0.94731\n",
      "[27]\ttraining's rmse: 1.02667\tvalid_1's rmse: 0.945898\n",
      "[28]\ttraining's rmse: 1.0249\tvalid_1's rmse: 0.944914\n",
      "[29]\ttraining's rmse: 1.0212\tvalid_1's rmse: 0.941736\n",
      "[30]\ttraining's rmse: 1.01994\tvalid_1's rmse: 0.941034\n",
      "[31]\ttraining's rmse: 1.01868\tvalid_1's rmse: 0.940682\n",
      "[32]\ttraining's rmse: 1.01765\tvalid_1's rmse: 0.940393\n",
      "[33]\ttraining's rmse: 1.01372\tvalid_1's rmse: 0.937978\n",
      "[34]\ttraining's rmse: 1.0105\tvalid_1's rmse: 0.935673\n",
      "[35]\ttraining's rmse: 1.00808\tvalid_1's rmse: 0.933981\n",
      "[36]\ttraining's rmse: 1.00721\tvalid_1's rmse: 0.933414\n",
      "[37]\ttraining's rmse: 1.00634\tvalid_1's rmse: 0.933313\n",
      "[38]\ttraining's rmse: 1.00521\tvalid_1's rmse: 0.932638\n",
      "[39]\ttraining's rmse: 1.00322\tvalid_1's rmse: 0.931372\n",
      "[40]\ttraining's rmse: 1.00263\tvalid_1's rmse: 0.930943\n",
      "[41]\ttraining's rmse: 1.00207\tvalid_1's rmse: 0.930813\n",
      "[42]\ttraining's rmse: 1.00115\tvalid_1's rmse: 0.930473\n",
      "[43]\ttraining's rmse: 1.00051\tvalid_1's rmse: 0.930372\n",
      "[44]\ttraining's rmse: 0.999892\tvalid_1's rmse: 0.930084\n",
      "[45]\ttraining's rmse: 0.997711\tvalid_1's rmse: 0.928299\n",
      "[46]\ttraining's rmse: 0.997308\tvalid_1's rmse: 0.92824\n",
      "[47]\ttraining's rmse: 0.99668\tvalid_1's rmse: 0.928257\n",
      "[48]\ttraining's rmse: 0.996297\tvalid_1's rmse: 0.927997\n",
      "[49]\ttraining's rmse: 0.994109\tvalid_1's rmse: 0.927027\n",
      "[50]\ttraining's rmse: 0.993286\tvalid_1's rmse: 0.927115\n",
      "[51]\ttraining's rmse: 0.992934\tvalid_1's rmse: 0.926788\n",
      "[52]\ttraining's rmse: 0.992109\tvalid_1's rmse: 0.926521\n",
      "[53]\ttraining's rmse: 0.991182\tvalid_1's rmse: 0.926598\n",
      "[54]\ttraining's rmse: 0.990657\tvalid_1's rmse: 0.92638\n",
      "[55]\ttraining's rmse: 0.990132\tvalid_1's rmse: 0.926249\n",
      "[56]\ttraining's rmse: 0.988924\tvalid_1's rmse: 0.925658\n",
      "[57]\ttraining's rmse: 0.988643\tvalid_1's rmse: 0.925478\n",
      "[58]\ttraining's rmse: 0.988065\tvalid_1's rmse: 0.925616\n",
      "[59]\ttraining's rmse: 0.987453\tvalid_1's rmse: 0.925282\n",
      "[60]\ttraining's rmse: 0.987059\tvalid_1's rmse: 0.92532\n",
      "[61]\ttraining's rmse: 0.986678\tvalid_1's rmse: 0.925301\n",
      "[62]\ttraining's rmse: 0.986174\tvalid_1's rmse: 0.925244\n",
      "[63]\ttraining's rmse: 0.985543\tvalid_1's rmse: 0.925405\n",
      "[64]\ttraining's rmse: 0.985121\tvalid_1's rmse: 0.925652\n",
      "[65]\ttraining's rmse: 0.98426\tvalid_1's rmse: 0.925232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66]\ttraining's rmse: 0.983904\tvalid_1's rmse: 0.925238\n",
      "[67]\ttraining's rmse: 0.98344\tvalid_1's rmse: 0.925367\n",
      "[68]\ttraining's rmse: 0.983078\tvalid_1's rmse: 0.925417\n",
      "[69]\ttraining's rmse: 0.982554\tvalid_1's rmse: 0.924851\n",
      "[70]\ttraining's rmse: 0.982236\tvalid_1's rmse: 0.924574\n",
      "[71]\ttraining's rmse: 0.981965\tvalid_1's rmse: 0.924513\n",
      "[72]\ttraining's rmse: 0.981681\tvalid_1's rmse: 0.924428\n",
      "[73]\ttraining's rmse: 0.981448\tvalid_1's rmse: 0.924372\n",
      "[74]\ttraining's rmse: 0.980987\tvalid_1's rmse: 0.924791\n",
      "[75]\ttraining's rmse: 0.980623\tvalid_1's rmse: 0.924572\n",
      "[76]\ttraining's rmse: 0.980439\tvalid_1's rmse: 0.924562\n",
      "[77]\ttraining's rmse: 0.97968\tvalid_1's rmse: 0.924152\n",
      "[78]\ttraining's rmse: 0.979252\tvalid_1's rmse: 0.924006\n",
      "[79]\ttraining's rmse: 0.97894\tvalid_1's rmse: 0.924014\n",
      "[80]\ttraining's rmse: 0.978642\tvalid_1's rmse: 0.923949\n",
      "[81]\ttraining's rmse: 0.978258\tvalid_1's rmse: 0.924135\n",
      "[82]\ttraining's rmse: 0.978023\tvalid_1's rmse: 0.924004\n",
      "[83]\ttraining's rmse: 0.977741\tvalid_1's rmse: 0.923702\n",
      "[84]\ttraining's rmse: 0.977314\tvalid_1's rmse: 0.923379\n",
      "[85]\ttraining's rmse: 0.977158\tvalid_1's rmse: 0.923057\n",
      "[86]\ttraining's rmse: 0.976853\tvalid_1's rmse: 0.922997\n",
      "[87]\ttraining's rmse: 0.976556\tvalid_1's rmse: 0.922962\n",
      "[88]\ttraining's rmse: 0.97606\tvalid_1's rmse: 0.922591\n",
      "[89]\ttraining's rmse: 0.975388\tvalid_1's rmse: 0.922337\n",
      "[90]\ttraining's rmse: 0.975061\tvalid_1's rmse: 0.922101\n",
      "[91]\ttraining's rmse: 0.974864\tvalid_1's rmse: 0.922108\n",
      "[92]\ttraining's rmse: 0.974247\tvalid_1's rmse: 0.921779\n",
      "[93]\ttraining's rmse: 0.974105\tvalid_1's rmse: 0.921729\n",
      "[94]\ttraining's rmse: 0.973894\tvalid_1's rmse: 0.921722\n",
      "[95]\ttraining's rmse: 0.973682\tvalid_1's rmse: 0.921637\n",
      "[96]\ttraining's rmse: 0.973267\tvalid_1's rmse: 0.921692\n",
      "[97]\ttraining's rmse: 0.972984\tvalid_1's rmse: 0.921583\n",
      "[98]\ttraining's rmse: 0.972698\tvalid_1's rmse: 0.921959\n",
      "[99]\ttraining's rmse: 0.972448\tvalid_1's rmse: 0.921717\n",
      "[100]\ttraining's rmse: 0.972223\tvalid_1's rmse: 0.921582\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972223\tvalid_1's rmse: 0.921582\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 5, 'reg_alpha': 5, 'objective': None, 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 7}\n",
      "model directory : trained_models_dir/lgb\\gs_21\n",
      "[1]\ttraining's rmse: 1.27823\tvalid_1's rmse: 1.10049\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.23202\tvalid_1's rmse: 1.069\n",
      "[3]\ttraining's rmse: 1.19285\tvalid_1's rmse: 1.04196\n",
      "[4]\ttraining's rmse: 1.15928\tvalid_1's rmse: 1.0212\n",
      "[5]\ttraining's rmse: 1.13102\tvalid_1's rmse: 1.00333\n",
      "[6]\ttraining's rmse: 1.10723\tvalid_1's rmse: 0.987206\n",
      "[7]\ttraining's rmse: 1.08652\tvalid_1's rmse: 0.975013\n",
      "[8]\ttraining's rmse: 1.06842\tvalid_1's rmse: 0.963347\n",
      "[9]\ttraining's rmse: 1.05361\tvalid_1's rmse: 0.955442\n",
      "[10]\ttraining's rmse: 1.04037\tvalid_1's rmse: 0.948106\n",
      "[11]\ttraining's rmse: 1.02955\tvalid_1's rmse: 0.941988\n",
      "[12]\ttraining's rmse: 1.0204\tvalid_1's rmse: 0.937768\n",
      "[13]\ttraining's rmse: 1.01201\tvalid_1's rmse: 0.933257\n",
      "[14]\ttraining's rmse: 1.0049\tvalid_1's rmse: 0.92986\n",
      "[15]\ttraining's rmse: 0.998651\tvalid_1's rmse: 0.927195\n",
      "[16]\ttraining's rmse: 0.993176\tvalid_1's rmse: 0.92547\n",
      "[17]\ttraining's rmse: 0.988377\tvalid_1's rmse: 0.92346\n",
      "[18]\ttraining's rmse: 0.983897\tvalid_1's rmse: 0.921008\n",
      "[19]\ttraining's rmse: 0.979856\tvalid_1's rmse: 0.920079\n",
      "[20]\ttraining's rmse: 0.976497\tvalid_1's rmse: 0.918666\n",
      "[21]\ttraining's rmse: 0.973159\tvalid_1's rmse: 0.917558\n",
      "[22]\ttraining's rmse: 0.970166\tvalid_1's rmse: 0.916296\n",
      "[23]\ttraining's rmse: 0.96754\tvalid_1's rmse: 0.914464\n",
      "[24]\ttraining's rmse: 0.964863\tvalid_1's rmse: 0.913577\n",
      "[25]\ttraining's rmse: 0.962274\tvalid_1's rmse: 0.912388\n",
      "[26]\ttraining's rmse: 0.960027\tvalid_1's rmse: 0.912532\n",
      "[27]\ttraining's rmse: 0.958096\tvalid_1's rmse: 0.912195\n",
      "[28]\ttraining's rmse: 0.956515\tvalid_1's rmse: 0.911486\n",
      "[29]\ttraining's rmse: 0.95476\tvalid_1's rmse: 0.911136\n",
      "[30]\ttraining's rmse: 0.953128\tvalid_1's rmse: 0.910998\n",
      "[31]\ttraining's rmse: 0.951515\tvalid_1's rmse: 0.910829\n",
      "[32]\ttraining's rmse: 0.950422\tvalid_1's rmse: 0.910523\n",
      "[33]\ttraining's rmse: 0.94934\tvalid_1's rmse: 0.91053\n",
      "[34]\ttraining's rmse: 0.948138\tvalid_1's rmse: 0.910644\n",
      "[35]\ttraining's rmse: 0.946759\tvalid_1's rmse: 0.911098\n",
      "[36]\ttraining's rmse: 0.945634\tvalid_1's rmse: 0.910583\n",
      "[37]\ttraining's rmse: 0.944454\tvalid_1's rmse: 0.909586\n",
      "[38]\ttraining's rmse: 0.943438\tvalid_1's rmse: 0.908988\n",
      "[39]\ttraining's rmse: 0.942411\tvalid_1's rmse: 0.908575\n",
      "[40]\ttraining's rmse: 0.941523\tvalid_1's rmse: 0.908236\n",
      "[41]\ttraining's rmse: 0.940617\tvalid_1's rmse: 0.908392\n",
      "[42]\ttraining's rmse: 0.939821\tvalid_1's rmse: 0.908383\n",
      "[43]\ttraining's rmse: 0.938954\tvalid_1's rmse: 0.907917\n",
      "[44]\ttraining's rmse: 0.93802\tvalid_1's rmse: 0.907705\n",
      "[45]\ttraining's rmse: 0.937254\tvalid_1's rmse: 0.907906\n",
      "[46]\ttraining's rmse: 0.936578\tvalid_1's rmse: 0.907712\n",
      "[47]\ttraining's rmse: 0.935859\tvalid_1's rmse: 0.907326\n",
      "[48]\ttraining's rmse: 0.93524\tvalid_1's rmse: 0.906959\n",
      "[49]\ttraining's rmse: 0.934403\tvalid_1's rmse: 0.906336\n",
      "[50]\ttraining's rmse: 0.933507\tvalid_1's rmse: 0.906341\n",
      "[51]\ttraining's rmse: 0.932716\tvalid_1's rmse: 0.90686\n",
      "[52]\ttraining's rmse: 0.931846\tvalid_1's rmse: 0.906938\n",
      "[53]\ttraining's rmse: 0.931334\tvalid_1's rmse: 0.907092\n",
      "[54]\ttraining's rmse: 0.930617\tvalid_1's rmse: 0.907028\n",
      "[55]\ttraining's rmse: 0.929902\tvalid_1's rmse: 0.906971\n",
      "[56]\ttraining's rmse: 0.929349\tvalid_1's rmse: 0.906741\n",
      "[57]\ttraining's rmse: 0.928579\tvalid_1's rmse: 0.906824\n",
      "[58]\ttraining's rmse: 0.928007\tvalid_1's rmse: 0.906613\n",
      "[59]\ttraining's rmse: 0.927375\tvalid_1's rmse: 0.905657\n",
      "[60]\ttraining's rmse: 0.926857\tvalid_1's rmse: 0.906029\n",
      "[61]\ttraining's rmse: 0.926419\tvalid_1's rmse: 0.905778\n",
      "[62]\ttraining's rmse: 0.925994\tvalid_1's rmse: 0.905481\n",
      "[63]\ttraining's rmse: 0.925456\tvalid_1's rmse: 0.905529\n",
      "[64]\ttraining's rmse: 0.925034\tvalid_1's rmse: 0.905308\n",
      "[65]\ttraining's rmse: 0.924597\tvalid_1's rmse: 0.90529\n",
      "[66]\ttraining's rmse: 0.924032\tvalid_1's rmse: 0.905022\n",
      "[67]\ttraining's rmse: 0.923517\tvalid_1's rmse: 0.90539\n",
      "[68]\ttraining's rmse: 0.922941\tvalid_1's rmse: 0.905507\n",
      "[69]\ttraining's rmse: 0.922251\tvalid_1's rmse: 0.905509\n",
      "[70]\ttraining's rmse: 0.921876\tvalid_1's rmse: 0.905524\n",
      "[71]\ttraining's rmse: 0.921385\tvalid_1's rmse: 0.905227\n",
      "[72]\ttraining's rmse: 0.920959\tvalid_1's rmse: 0.905168\n",
      "[73]\ttraining's rmse: 0.920574\tvalid_1's rmse: 0.905064\n",
      "[74]\ttraining's rmse: 0.920194\tvalid_1's rmse: 0.904968\n",
      "[75]\ttraining's rmse: 0.919774\tvalid_1's rmse: 0.904917\n",
      "[76]\ttraining's rmse: 0.919345\tvalid_1's rmse: 0.906115\n",
      "[77]\ttraining's rmse: 0.918821\tvalid_1's rmse: 0.906167\n",
      "[78]\ttraining's rmse: 0.918282\tvalid_1's rmse: 0.906647\n",
      "[79]\ttraining's rmse: 0.917969\tvalid_1's rmse: 0.906578\n",
      "[80]\ttraining's rmse: 0.917422\tvalid_1's rmse: 0.906486\n",
      "[81]\ttraining's rmse: 0.916901\tvalid_1's rmse: 0.906693\n",
      "[82]\ttraining's rmse: 0.916552\tvalid_1's rmse: 0.906834\n",
      "[83]\ttraining's rmse: 0.91599\tvalid_1's rmse: 0.906407\n",
      "[84]\ttraining's rmse: 0.91567\tvalid_1's rmse: 0.906323\n",
      "[85]\ttraining's rmse: 0.915178\tvalid_1's rmse: 0.90636\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's rmse: 0.919774\tvalid_1's rmse: 0.904917\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.9, 'reg_lambda': 1, 'reg_alpha': 2, 'objective': None, 'num_threads': 4, 'num_leaves': 512, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_22\n",
      "[1]\ttraining's rmse: 1.2898\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.25361\tvalid_1's rmse: 1.08715\n",
      "[3]\ttraining's rmse: 1.22298\tvalid_1's rmse: 1.0678\n",
      "[4]\ttraining's rmse: 1.19695\tvalid_1's rmse: 1.05162\n",
      "[5]\ttraining's rmse: 1.17485\tvalid_1's rmse: 1.03825\n",
      "[6]\ttraining's rmse: 1.15542\tvalid_1's rmse: 1.02587\n",
      "[7]\ttraining's rmse: 1.13957\tvalid_1's rmse: 1.01631\n",
      "[8]\ttraining's rmse: 1.12564\tvalid_1's rmse: 1.00747\n",
      "[9]\ttraining's rmse: 1.11411\tvalid_1's rmse: 1.00097\n",
      "[10]\ttraining's rmse: 1.10378\tvalid_1's rmse: 0.995239\n",
      "[11]\ttraining's rmse: 1.09544\tvalid_1's rmse: 0.990408\n",
      "[12]\ttraining's rmse: 1.08513\tvalid_1's rmse: 0.983354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttraining's rmse: 1.07433\tvalid_1's rmse: 0.975212\n",
      "[14]\ttraining's rmse: 1.06868\tvalid_1's rmse: 0.972296\n",
      "[15]\ttraining's rmse: 1.06372\tvalid_1's rmse: 0.969\n",
      "[16]\ttraining's rmse: 1.05877\tvalid_1's rmse: 0.96569\n",
      "[17]\ttraining's rmse: 1.05472\tvalid_1's rmse: 0.963342\n",
      "[18]\ttraining's rmse: 1.05057\tvalid_1's rmse: 0.960502\n",
      "[19]\ttraining's rmse: 1.04751\tvalid_1's rmse: 0.959484\n",
      "[20]\ttraining's rmse: 1.0444\tvalid_1's rmse: 0.957097\n",
      "[21]\ttraining's rmse: 1.04115\tvalid_1's rmse: 0.955163\n",
      "[22]\ttraining's rmse: 1.03749\tvalid_1's rmse: 0.95312\n",
      "[23]\ttraining's rmse: 1.03493\tvalid_1's rmse: 0.95121\n",
      "[24]\ttraining's rmse: 1.03262\tvalid_1's rmse: 0.949404\n",
      "[25]\ttraining's rmse: 1.03064\tvalid_1's rmse: 0.948632\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947308\n",
      "[27]\ttraining's rmse: 1.02667\tvalid_1's rmse: 0.945896\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.944912\n",
      "[29]\ttraining's rmse: 1.0212\tvalid_1's rmse: 0.941734\n",
      "[30]\ttraining's rmse: 1.01994\tvalid_1's rmse: 0.941032\n",
      "[31]\ttraining's rmse: 1.01867\tvalid_1's rmse: 0.94068\n",
      "[32]\ttraining's rmse: 1.01765\tvalid_1's rmse: 0.94039\n",
      "[33]\ttraining's rmse: 1.01372\tvalid_1's rmse: 0.937976\n",
      "[34]\ttraining's rmse: 1.0105\tvalid_1's rmse: 0.935671\n",
      "[35]\ttraining's rmse: 1.00807\tvalid_1's rmse: 0.933979\n",
      "[36]\ttraining's rmse: 1.0072\tvalid_1's rmse: 0.933413\n",
      "[37]\ttraining's rmse: 1.00633\tvalid_1's rmse: 0.933312\n",
      "[38]\ttraining's rmse: 1.0052\tvalid_1's rmse: 0.932637\n",
      "[39]\ttraining's rmse: 1.00321\tvalid_1's rmse: 0.931372\n",
      "[40]\ttraining's rmse: 1.00262\tvalid_1's rmse: 0.930943\n",
      "[41]\ttraining's rmse: 1.00205\tvalid_1's rmse: 0.93076\n",
      "[42]\ttraining's rmse: 1.00114\tvalid_1's rmse: 0.930424\n",
      "[43]\ttraining's rmse: 1.00057\tvalid_1's rmse: 0.930138\n",
      "[44]\ttraining's rmse: 0.998364\tvalid_1's rmse: 0.928343\n",
      "[45]\ttraining's rmse: 0.997855\tvalid_1's rmse: 0.928217\n",
      "[46]\ttraining's rmse: 0.99721\tvalid_1's rmse: 0.928231\n",
      "[47]\ttraining's rmse: 0.996815\tvalid_1's rmse: 0.927957\n",
      "[48]\ttraining's rmse: 0.995649\tvalid_1's rmse: 0.927909\n",
      "[49]\ttraining's rmse: 0.995132\tvalid_1's rmse: 0.92796\n",
      "[50]\ttraining's rmse: 0.994162\tvalid_1's rmse: 0.928022\n",
      "[51]\ttraining's rmse: 0.993619\tvalid_1's rmse: 0.92794\n",
      "[52]\ttraining's rmse: 0.993219\tvalid_1's rmse: 0.927883\n",
      "[53]\ttraining's rmse: 0.9917\tvalid_1's rmse: 0.926982\n",
      "[54]\ttraining's rmse: 0.990913\tvalid_1's rmse: 0.926733\n",
      "[55]\ttraining's rmse: 0.98974\tvalid_1's rmse: 0.925984\n",
      "[56]\ttraining's rmse: 0.98911\tvalid_1's rmse: 0.925892\n",
      "[57]\ttraining's rmse: 0.988834\tvalid_1's rmse: 0.925765\n",
      "[58]\ttraining's rmse: 0.988088\tvalid_1's rmse: 0.925809\n",
      "[59]\ttraining's rmse: 0.987451\tvalid_1's rmse: 0.925472\n",
      "[60]\ttraining's rmse: 0.987012\tvalid_1's rmse: 0.925904\n",
      "[61]\ttraining's rmse: 0.986696\tvalid_1's rmse: 0.925599\n",
      "[62]\ttraining's rmse: 0.986047\tvalid_1's rmse: 0.925079\n",
      "[63]\ttraining's rmse: 0.985814\tvalid_1's rmse: 0.924955\n",
      "[64]\ttraining's rmse: 0.985204\tvalid_1's rmse: 0.925167\n",
      "[65]\ttraining's rmse: 0.984772\tvalid_1's rmse: 0.9252\n",
      "[66]\ttraining's rmse: 0.984457\tvalid_1's rmse: 0.925211\n",
      "[67]\ttraining's rmse: 0.983722\tvalid_1's rmse: 0.925081\n",
      "[68]\ttraining's rmse: 0.983395\tvalid_1's rmse: 0.924727\n",
      "[69]\ttraining's rmse: 0.982904\tvalid_1's rmse: 0.924568\n",
      "[70]\ttraining's rmse: 0.982645\tvalid_1's rmse: 0.924605\n",
      "[71]\ttraining's rmse: 0.981543\tvalid_1's rmse: 0.924366\n",
      "[72]\ttraining's rmse: 0.981267\tvalid_1's rmse: 0.9243\n",
      "[73]\ttraining's rmse: 0.980821\tvalid_1's rmse: 0.9244\n",
      "[74]\ttraining's rmse: 0.980461\tvalid_1's rmse: 0.924177\n",
      "[75]\ttraining's rmse: 0.980058\tvalid_1's rmse: 0.92404\n",
      "[76]\ttraining's rmse: 0.979838\tvalid_1's rmse: 0.923658\n",
      "[77]\ttraining's rmse: 0.979376\tvalid_1's rmse: 0.923344\n",
      "[78]\ttraining's rmse: 0.979099\tvalid_1's rmse: 0.92331\n",
      "[79]\ttraining's rmse: 0.978639\tvalid_1's rmse: 0.92339\n",
      "[80]\ttraining's rmse: 0.978388\tvalid_1's rmse: 0.923157\n",
      "[81]\ttraining's rmse: 0.978076\tvalid_1's rmse: 0.923108\n",
      "[82]\ttraining's rmse: 0.977725\tvalid_1's rmse: 0.923012\n",
      "[83]\ttraining's rmse: 0.977428\tvalid_1's rmse: 0.923054\n",
      "[84]\ttraining's rmse: 0.976696\tvalid_1's rmse: 0.922831\n",
      "[85]\ttraining's rmse: 0.976548\tvalid_1's rmse: 0.922608\n",
      "[86]\ttraining's rmse: 0.976108\tvalid_1's rmse: 0.922543\n",
      "[87]\ttraining's rmse: 0.975721\tvalid_1's rmse: 0.922129\n",
      "[88]\ttraining's rmse: 0.975488\tvalid_1's rmse: 0.922117\n",
      "[89]\ttraining's rmse: 0.97508\tvalid_1's rmse: 0.922188\n",
      "[90]\ttraining's rmse: 0.974859\tvalid_1's rmse: 0.922344\n",
      "[91]\ttraining's rmse: 0.974598\tvalid_1's rmse: 0.922669\n",
      "[92]\ttraining's rmse: 0.974376\tvalid_1's rmse: 0.922438\n",
      "[93]\ttraining's rmse: 0.974248\tvalid_1's rmse: 0.922428\n",
      "[94]\ttraining's rmse: 0.973922\tvalid_1's rmse: 0.92235\n",
      "[95]\ttraining's rmse: 0.973511\tvalid_1's rmse: 0.922207\n",
      "[96]\ttraining's rmse: 0.973272\tvalid_1's rmse: 0.922148\n",
      "[97]\ttraining's rmse: 0.973135\tvalid_1's rmse: 0.921966\n",
      "[98]\ttraining's rmse: 0.972928\tvalid_1's rmse: 0.921966\n",
      "[99]\ttraining's rmse: 0.972565\tvalid_1's rmse: 0.921943\n",
      "[100]\ttraining's rmse: 0.972306\tvalid_1's rmse: 0.921707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.972306\tvalid_1's rmse: 0.921707\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 0, 'objective': None, 'num_threads': 4, 'num_leaves': 32, 'metric': 'rmse', 'max_depth': 5}\n",
      "model directory : trained_models_dir/lgb\\gs_23\n",
      "[1]\ttraining's rmse: 1.27972\tvalid_1's rmse: 1.10092\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.2349\tvalid_1's rmse: 1.07062\n",
      "[3]\ttraining's rmse: 1.19693\tvalid_1's rmse: 1.04446\n",
      "[4]\ttraining's rmse: 1.16482\tvalid_1's rmse: 1.02353\n",
      "[5]\ttraining's rmse: 1.13784\tvalid_1's rmse: 1.00645\n",
      "[6]\ttraining's rmse: 1.11385\tvalid_1's rmse: 0.990684\n",
      "[7]\ttraining's rmse: 1.09347\tvalid_1's rmse: 0.977181\n",
      "[8]\ttraining's rmse: 1.07671\tvalid_1's rmse: 0.967542\n",
      "[9]\ttraining's rmse: 1.06198\tvalid_1's rmse: 0.958301\n",
      "[10]\ttraining's rmse: 1.05\tvalid_1's rmse: 0.95117\n",
      "[11]\ttraining's rmse: 1.03894\tvalid_1's rmse: 0.945006\n",
      "[12]\ttraining's rmse: 1.02965\tvalid_1's rmse: 0.939905\n",
      "[13]\ttraining's rmse: 1.02129\tvalid_1's rmse: 0.935887\n",
      "[14]\ttraining's rmse: 1.01482\tvalid_1's rmse: 0.93324\n",
      "[15]\ttraining's rmse: 1.00881\tvalid_1's rmse: 0.930578\n",
      "[16]\ttraining's rmse: 1.00332\tvalid_1's rmse: 0.928084\n",
      "[17]\ttraining's rmse: 0.998868\tvalid_1's rmse: 0.926324\n",
      "[18]\ttraining's rmse: 0.994946\tvalid_1's rmse: 0.924338\n",
      "[19]\ttraining's rmse: 0.991477\tvalid_1's rmse: 0.922898\n",
      "[20]\ttraining's rmse: 0.987761\tvalid_1's rmse: 0.921587\n",
      "[21]\ttraining's rmse: 0.984019\tvalid_1's rmse: 0.919876\n",
      "[22]\ttraining's rmse: 0.980369\tvalid_1's rmse: 0.918465\n",
      "[23]\ttraining's rmse: 0.97782\tvalid_1's rmse: 0.917847\n",
      "[24]\ttraining's rmse: 0.975731\tvalid_1's rmse: 0.917086\n",
      "[25]\ttraining's rmse: 0.973218\tvalid_1's rmse: 0.916447\n",
      "[26]\ttraining's rmse: 0.971542\tvalid_1's rmse: 0.916017\n",
      "[27]\ttraining's rmse: 0.968921\tvalid_1's rmse: 0.915227\n",
      "[28]\ttraining's rmse: 0.967308\tvalid_1's rmse: 0.915005\n",
      "[29]\ttraining's rmse: 0.965747\tvalid_1's rmse: 0.914417\n",
      "[30]\ttraining's rmse: 0.964172\tvalid_1's rmse: 0.913704\n",
      "[31]\ttraining's rmse: 0.962638\tvalid_1's rmse: 0.91314\n",
      "[32]\ttraining's rmse: 0.961062\tvalid_1's rmse: 0.913538\n",
      "[33]\ttraining's rmse: 0.959918\tvalid_1's rmse: 0.913401\n",
      "[34]\ttraining's rmse: 0.959048\tvalid_1's rmse: 0.913368\n",
      "[35]\ttraining's rmse: 0.957973\tvalid_1's rmse: 0.913171\n",
      "[36]\ttraining's rmse: 0.957186\tvalid_1's rmse: 0.913155\n",
      "[37]\ttraining's rmse: 0.956303\tvalid_1's rmse: 0.912987\n",
      "[38]\ttraining's rmse: 0.955582\tvalid_1's rmse: 0.912971\n",
      "[39]\ttraining's rmse: 0.954725\tvalid_1's rmse: 0.91261\n",
      "[40]\ttraining's rmse: 0.953476\tvalid_1's rmse: 0.912622\n",
      "[41]\ttraining's rmse: 0.952622\tvalid_1's rmse: 0.912343\n",
      "[42]\ttraining's rmse: 0.951857\tvalid_1's rmse: 0.912077\n",
      "[43]\ttraining's rmse: 0.951218\tvalid_1's rmse: 0.911805\n",
      "[44]\ttraining's rmse: 0.950609\tvalid_1's rmse: 0.911857\n",
      "[45]\ttraining's rmse: 0.949877\tvalid_1's rmse: 0.911665\n",
      "[46]\ttraining's rmse: 0.949196\tvalid_1's rmse: 0.911316\n",
      "[47]\ttraining's rmse: 0.948664\tvalid_1's rmse: 0.911255\n",
      "[48]\ttraining's rmse: 0.94766\tvalid_1's rmse: 0.91107\n",
      "[49]\ttraining's rmse: 0.947095\tvalid_1's rmse: 0.911001\n",
      "[50]\ttraining's rmse: 0.946542\tvalid_1's rmse: 0.911061\n",
      "[51]\ttraining's rmse: 0.945852\tvalid_1's rmse: 0.910468\n",
      "[52]\ttraining's rmse: 0.945354\tvalid_1's rmse: 0.910652\n",
      "[53]\ttraining's rmse: 0.944775\tvalid_1's rmse: 0.910664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54]\ttraining's rmse: 0.944111\tvalid_1's rmse: 0.910308\n",
      "[55]\ttraining's rmse: 0.943261\tvalid_1's rmse: 0.909873\n",
      "[56]\ttraining's rmse: 0.942827\tvalid_1's rmse: 0.909852\n",
      "[57]\ttraining's rmse: 0.942279\tvalid_1's rmse: 0.909794\n",
      "[58]\ttraining's rmse: 0.94172\tvalid_1's rmse: 0.909725\n",
      "[59]\ttraining's rmse: 0.941295\tvalid_1's rmse: 0.90967\n",
      "[60]\ttraining's rmse: 0.94046\tvalid_1's rmse: 0.909842\n",
      "[61]\ttraining's rmse: 0.940049\tvalid_1's rmse: 0.909764\n",
      "[62]\ttraining's rmse: 0.939673\tvalid_1's rmse: 0.90973\n",
      "[63]\ttraining's rmse: 0.939223\tvalid_1's rmse: 0.909489\n",
      "[64]\ttraining's rmse: 0.938826\tvalid_1's rmse: 0.909715\n",
      "[65]\ttraining's rmse: 0.938258\tvalid_1's rmse: 0.90988\n",
      "[66]\ttraining's rmse: 0.937719\tvalid_1's rmse: 0.909822\n",
      "[67]\ttraining's rmse: 0.937375\tvalid_1's rmse: 0.909691\n",
      "[68]\ttraining's rmse: 0.936957\tvalid_1's rmse: 0.90955\n",
      "[69]\ttraining's rmse: 0.936688\tvalid_1's rmse: 0.909537\n",
      "[70]\ttraining's rmse: 0.935917\tvalid_1's rmse: 0.90914\n",
      "[71]\ttraining's rmse: 0.935036\tvalid_1's rmse: 0.908619\n",
      "[72]\ttraining's rmse: 0.934424\tvalid_1's rmse: 0.908286\n",
      "[73]\ttraining's rmse: 0.934064\tvalid_1's rmse: 0.90793\n",
      "[74]\ttraining's rmse: 0.933704\tvalid_1's rmse: 0.90808\n",
      "[75]\ttraining's rmse: 0.933227\tvalid_1's rmse: 0.90672\n",
      "[76]\ttraining's rmse: 0.932942\tvalid_1's rmse: 0.906577\n",
      "[77]\ttraining's rmse: 0.932589\tvalid_1's rmse: 0.90664\n",
      "[78]\ttraining's rmse: 0.932055\tvalid_1's rmse: 0.905443\n",
      "[79]\ttraining's rmse: 0.931326\tvalid_1's rmse: 0.905005\n",
      "[80]\ttraining's rmse: 0.930721\tvalid_1's rmse: 0.90494\n",
      "[81]\ttraining's rmse: 0.930233\tvalid_1's rmse: 0.904754\n",
      "[82]\ttraining's rmse: 0.929783\tvalid_1's rmse: 0.904609\n",
      "[83]\ttraining's rmse: 0.929499\tvalid_1's rmse: 0.904566\n",
      "[84]\ttraining's rmse: 0.928984\tvalid_1's rmse: 0.903442\n",
      "[85]\ttraining's rmse: 0.928783\tvalid_1's rmse: 0.90328\n",
      "[86]\ttraining's rmse: 0.928471\tvalid_1's rmse: 0.903296\n",
      "[87]\ttraining's rmse: 0.928029\tvalid_1's rmse: 0.903149\n",
      "[88]\ttraining's rmse: 0.92769\tvalid_1's rmse: 0.903085\n",
      "[89]\ttraining's rmse: 0.92729\tvalid_1's rmse: 0.903307\n",
      "[90]\ttraining's rmse: 0.927022\tvalid_1's rmse: 0.903417\n",
      "[91]\ttraining's rmse: 0.926654\tvalid_1's rmse: 0.903169\n",
      "[92]\ttraining's rmse: 0.926356\tvalid_1's rmse: 0.903145\n",
      "[93]\ttraining's rmse: 0.926036\tvalid_1's rmse: 0.903211\n",
      "[94]\ttraining's rmse: 0.925723\tvalid_1's rmse: 0.902884\n",
      "[95]\ttraining's rmse: 0.925393\tvalid_1's rmse: 0.90267\n",
      "[96]\ttraining's rmse: 0.925091\tvalid_1's rmse: 0.902323\n",
      "[97]\ttraining's rmse: 0.924419\tvalid_1's rmse: 0.90268\n",
      "[98]\ttraining's rmse: 0.924071\tvalid_1's rmse: 0.902926\n",
      "[99]\ttraining's rmse: 0.923374\tvalid_1's rmse: 0.902902\n",
      "[100]\ttraining's rmse: 0.922822\tvalid_1's rmse: 0.902731\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.922822\tvalid_1's rmse: 0.902731\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n",
      "current parameters : {'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha': 0.1, 'objective': 'regression_l2', 'num_threads': 4, 'num_leaves': 128, 'metric': 'rmse', 'max_depth': 3}\n",
      "model directory : trained_models_dir/lgb\\gs_24\n",
      "[1]\ttraining's rmse: 1.2898\tvalid_1's rmse: 1.10999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 1.25361\tvalid_1's rmse: 1.08715\n",
      "[3]\ttraining's rmse: 1.22297\tvalid_1's rmse: 1.0678\n",
      "[4]\ttraining's rmse: 1.19694\tvalid_1's rmse: 1.05162\n",
      "[5]\ttraining's rmse: 1.17485\tvalid_1's rmse: 1.03825\n",
      "[6]\ttraining's rmse: 1.15541\tvalid_1's rmse: 1.02586\n",
      "[7]\ttraining's rmse: 1.13957\tvalid_1's rmse: 1.01631\n",
      "[8]\ttraining's rmse: 1.12563\tvalid_1's rmse: 1.00747\n",
      "[9]\ttraining's rmse: 1.1141\tvalid_1's rmse: 1.00097\n",
      "[10]\ttraining's rmse: 1.10377\tvalid_1's rmse: 0.995236\n",
      "[11]\ttraining's rmse: 1.09543\tvalid_1's rmse: 0.990405\n",
      "[12]\ttraining's rmse: 1.08513\tvalid_1's rmse: 0.983351\n",
      "[13]\ttraining's rmse: 1.07433\tvalid_1's rmse: 0.975209\n",
      "[14]\ttraining's rmse: 1.06868\tvalid_1's rmse: 0.972294\n",
      "[15]\ttraining's rmse: 1.06371\tvalid_1's rmse: 0.968998\n",
      "[16]\ttraining's rmse: 1.05877\tvalid_1's rmse: 0.965688\n",
      "[17]\ttraining's rmse: 1.05472\tvalid_1's rmse: 0.963339\n",
      "[18]\ttraining's rmse: 1.05057\tvalid_1's rmse: 0.960499\n",
      "[19]\ttraining's rmse: 1.0475\tvalid_1's rmse: 0.959481\n",
      "[20]\ttraining's rmse: 1.0444\tvalid_1's rmse: 0.957095\n",
      "[21]\ttraining's rmse: 1.04115\tvalid_1's rmse: 0.95516\n",
      "[22]\ttraining's rmse: 1.03748\tvalid_1's rmse: 0.953117\n",
      "[23]\ttraining's rmse: 1.03493\tvalid_1's rmse: 0.951208\n",
      "[24]\ttraining's rmse: 1.03261\tvalid_1's rmse: 0.949402\n",
      "[25]\ttraining's rmse: 1.03064\tvalid_1's rmse: 0.94863\n",
      "[26]\ttraining's rmse: 1.02858\tvalid_1's rmse: 0.947306\n",
      "[27]\ttraining's rmse: 1.02666\tvalid_1's rmse: 0.945894\n",
      "[28]\ttraining's rmse: 1.02489\tvalid_1's rmse: 0.94491\n",
      "[29]\ttraining's rmse: 1.02119\tvalid_1's rmse: 0.941732\n",
      "[30]\ttraining's rmse: 1.01993\tvalid_1's rmse: 0.94103\n",
      "[31]\ttraining's rmse: 1.01867\tvalid_1's rmse: 0.940678\n",
      "[32]\ttraining's rmse: 1.01764\tvalid_1's rmse: 0.940389\n",
      "[33]\ttraining's rmse: 1.01371\tvalid_1's rmse: 0.937974\n",
      "[34]\ttraining's rmse: 1.01049\tvalid_1's rmse: 0.93567\n",
      "[35]\ttraining's rmse: 1.00807\tvalid_1's rmse: 0.933977\n",
      "[36]\ttraining's rmse: 1.0072\tvalid_1's rmse: 0.933411\n",
      "[37]\ttraining's rmse: 1.00633\tvalid_1's rmse: 0.933311\n",
      "[38]\ttraining's rmse: 1.0052\tvalid_1's rmse: 0.932636\n",
      "[39]\ttraining's rmse: 1.00321\tvalid_1's rmse: 0.931371\n",
      "[40]\ttraining's rmse: 1.00261\tvalid_1's rmse: 0.930942\n",
      "[41]\ttraining's rmse: 1.00205\tvalid_1's rmse: 0.930759\n",
      "[42]\ttraining's rmse: 1.00113\tvalid_1's rmse: 0.930423\n",
      "[43]\ttraining's rmse: 1.00056\tvalid_1's rmse: 0.930197\n",
      "[44]\ttraining's rmse: 0.998358\tvalid_1's rmse: 0.928403\n",
      "[45]\ttraining's rmse: 0.997692\tvalid_1's rmse: 0.928411\n",
      "[46]\ttraining's rmse: 0.997219\tvalid_1's rmse: 0.928318\n",
      "[47]\ttraining's rmse: 0.996823\tvalid_1's rmse: 0.928049\n",
      "[48]\ttraining's rmse: 0.995656\tvalid_1's rmse: 0.928003\n",
      "[49]\ttraining's rmse: 0.995135\tvalid_1's rmse: 0.928053\n",
      "[50]\ttraining's rmse: 0.994165\tvalid_1's rmse: 0.928115\n",
      "[51]\ttraining's rmse: 0.993757\tvalid_1's rmse: 0.927983\n",
      "[52]\ttraining's rmse: 0.992853\tvalid_1's rmse: 0.927687\n",
      "[53]\ttraining's rmse: 0.991398\tvalid_1's rmse: 0.926862\n",
      "[54]\ttraining's rmse: 0.990957\tvalid_1's rmse: 0.926566\n",
      "[55]\ttraining's rmse: 0.990546\tvalid_1's rmse: 0.926459\n",
      "[56]\ttraining's rmse: 0.98969\tvalid_1's rmse: 0.926237\n",
      "[57]\ttraining's rmse: 0.989123\tvalid_1's rmse: 0.926261\n",
      "[58]\ttraining's rmse: 0.988115\tvalid_1's rmse: 0.925802\n",
      "[59]\ttraining's rmse: 0.987827\tvalid_1's rmse: 0.925813\n",
      "[60]\ttraining's rmse: 0.987378\tvalid_1's rmse: 0.926189\n",
      "[61]\ttraining's rmse: 0.986777\tvalid_1's rmse: 0.92634\n",
      "[62]\ttraining's rmse: 0.986381\tvalid_1's rmse: 0.926375\n",
      "[63]\ttraining's rmse: 0.986062\tvalid_1's rmse: 0.926006\n",
      "[64]\ttraining's rmse: 0.985597\tvalid_1's rmse: 0.925981\n",
      "[65]\ttraining's rmse: 0.985219\tvalid_1's rmse: 0.926008\n",
      "[66]\ttraining's rmse: 0.984661\tvalid_1's rmse: 0.925433\n",
      "[67]\ttraining's rmse: 0.98426\tvalid_1's rmse: 0.925466\n",
      "[68]\ttraining's rmse: 0.983993\tvalid_1's rmse: 0.925213\n",
      "[69]\ttraining's rmse: 0.983614\tvalid_1's rmse: 0.925049\n",
      "[70]\ttraining's rmse: 0.982668\tvalid_1's rmse: 0.924791\n",
      "[71]\ttraining's rmse: 0.982319\tvalid_1's rmse: 0.924738\n",
      "[72]\ttraining's rmse: 0.982027\tvalid_1's rmse: 0.924619\n",
      "[73]\ttraining's rmse: 0.981796\tvalid_1's rmse: 0.924608\n",
      "[74]\ttraining's rmse: 0.981406\tvalid_1's rmse: 0.924486\n",
      "[75]\ttraining's rmse: 0.981133\tvalid_1's rmse: 0.924426\n",
      "[76]\ttraining's rmse: 0.980753\tvalid_1's rmse: 0.924705\n",
      "[77]\ttraining's rmse: 0.980569\tvalid_1's rmse: 0.924593\n",
      "[78]\ttraining's rmse: 0.980395\tvalid_1's rmse: 0.924073\n",
      "[79]\ttraining's rmse: 0.979974\tvalid_1's rmse: 0.924211\n",
      "[80]\ttraining's rmse: 0.979481\tvalid_1's rmse: 0.92378\n",
      "[81]\ttraining's rmse: 0.979111\tvalid_1's rmse: 0.923806\n",
      "[82]\ttraining's rmse: 0.978722\tvalid_1's rmse: 0.923923\n",
      "[83]\ttraining's rmse: 0.978268\tvalid_1's rmse: 0.923984\n",
      "[84]\ttraining's rmse: 0.978023\tvalid_1's rmse: 0.924035\n",
      "[85]\ttraining's rmse: 0.977811\tvalid_1's rmse: 0.923953\n",
      "[86]\ttraining's rmse: 0.977538\tvalid_1's rmse: 0.924081\n",
      "[87]\ttraining's rmse: 0.977394\tvalid_1's rmse: 0.923941\n",
      "[88]\ttraining's rmse: 0.977136\tvalid_1's rmse: 0.923931\n",
      "[89]\ttraining's rmse: 0.976651\tvalid_1's rmse: 0.9239\n",
      "[90]\ttraining's rmse: 0.976317\tvalid_1's rmse: 0.923798\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's rmse: 0.979481\tvalid_1's rmse: 0.92378\n",
      "overwrite model parameters file (trained_models_dir/lgb\\search_results.json)\n"
     ]
    }
   ],
   "source": [
    "for params in sampler:\n",
    "        print('current parameters : {}'.format(params))\n",
    "\n",
    "        model_dir, folder_name = __create_model_directory(trained_models_dir)\n",
    "        print('model directory : {}'.format(model_dir))\n",
    "\n",
    "        bst = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data], early_stopping_rounds=early_stopping_rounds)\n",
    "        bst.save_model(os.path.join(model_dir, 'lgb_model_filtered.txt'))\n",
    "        \n",
    "        _train_data = pd.read_pickle('pd_data_train.pkl')\n",
    "        _valid_data = pd.read_pickle('pd_data_valid.pkl')\n",
    "        _test_data = pd.read_pickle('pd_data_test.pkl')\n",
    "        \n",
    "        train_X, train_y = get_X_y(_train_data)\n",
    "        valid_X, valid_y = get_X_y(_valid_data)\n",
    "        test_X, test_y = get_X_y(_test_data)\n",
    "        \n",
    "        del _train_data\n",
    "        del _valid_data\n",
    "        del _test_data\n",
    "        \n",
    "        mean_cv_scores = [\n",
    "            rmse(train_y, bst.predict(train_X)),\n",
    "            rmse(valid_y, bst.predict(valid_X)),\n",
    "            rmse(test_y, bst.predict(test_X)),\n",
    "        ]\n",
    "        \n",
    "        write_message = dict(\n",
    "            params=params,\n",
    "            scores=dict(\n",
    "                train=mean_cv_scores[0],\n",
    "                val=mean_cv_scores[1],\n",
    "                test=mean_cv_scores[2],\n",
    "            ),\n",
    "            model_path=model_dir,\n",
    "        )\n",
    "\n",
    "        search_results.append(write_message)\n",
    "\n",
    "        with open(search_results_file, 'w') as file:\n",
    "            json.dump(search_results, file)\n",
    "            print('overwrite model parameters file ({})'.format(search_results_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(search_results_file, 'r') as file:\n",
    "    search_results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = [record['scores']['val'] for record in search_results]\n",
    "min_index = val_scores.index(min(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'subsample': 0.5,\n",
       "  'reg_lambda': 1,\n",
       "  'reg_alpha': 2,\n",
       "  'objective': None,\n",
       "  'num_threads': 4,\n",
       "  'num_leaves': 128,\n",
       "  'metric': 'rmse',\n",
       "  'max_depth': 7},\n",
       " 'scores': {'train': 1.0427203767267288,\n",
       "  'val': 0.89985226706254,\n",
       "  'test': 0.8557145824524979},\n",
       " 'model_path': 'trained_models_dir/lgb\\\\gs_0'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = search_results[min_index]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.Booster(model_file=os.path.join(best_model['model_path'], 'lgb_model_filtered.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_X_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-afb79018f13a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/ml_data/pd_data_test.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_train_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_valid_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_test_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_X_y' is not defined"
     ]
    }
   ],
   "source": [
    "_train_data = pd.read_pickle('D:/ml_data/pd_data_train.pkl')\n",
    "_valid_data = pd.read_pickle('D:/ml_data/pd_data_valid.pkl')\n",
    "_test_data = pd.read_pickle('D:/ml_data/pd_data_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = get_X_y(_train_data)\n",
    "valid_X, valid_y = get_X_y(_valid_data)\n",
    "test_X, test_y = get_X_y(_test_data)\n",
    "\n",
    "del _train_data\n",
    "del _valid_data\n",
    "del _test_data\n",
    "\n",
    "train_pred = bst.predict(train_X)\n",
    "valid_pred = bst.predict(valid_X)\n",
    "test_pred = bst.predict(test_X)\n",
    "\n",
    "mean_cv_scores = [\n",
    "    rmse(train_y, train_pred),\n",
    "    rmse(valid_y, valid_pred),\n",
    "    rmse(test_y, test_pred),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0427203767267288, 0.89985226706254, 0.8557145824524979]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_name = 'lgb'\n",
    "with open('{}_train_pred.pickle'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(train_pred, f)\n",
    "\n",
    "with open('{}_valid_pred.pickle'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(valid_pred, f)\n",
    "\n",
    "with open('{}_test_pred.pickle'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(test_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}_train.pickle'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(train_y, f)\n",
    "\n",
    "with open('{}_valid.pickle'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(valid_y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from module.data.read_data import *\n",
    "\n",
    "test = test_file_processing().set_index('ID')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pd_data_test.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-de911a0f2615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pd_data_test.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml_project\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(path, compression)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m    144\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;31m# 1) try standard libary Pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml_project\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pd_data_test.pkl'"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_pickle('pd_data_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = get_X_y(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200, 3)\n",
      "(214200,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "Y_test = bst.predict(test_X).clip(0, 20)\n",
    "\n",
    "print(test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test.index, \n",
    "    \"item_cnt_month\": Y_test\n",
    "})\n",
    "\n",
    "submission.to_csv('lgb_submission_filtered.csv', index=False)\n",
    "pickle.dump(Y_test, open('lgb_test_filtered.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.916558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.369198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.303552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.493867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.457535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0        0.916558\n",
       "1   1        0.369198\n",
       "2   2        1.303552\n",
       "3   3        0.493867\n",
       "4   4        4.457535"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                0.0\n",
       "item_cnt_month    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                214199.0000\n",
       "item_cnt_month        19.8314\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
